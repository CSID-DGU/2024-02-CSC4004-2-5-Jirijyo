{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a7c2c1-e765-436d-864b-35983cf7a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDNet_moderate.yaml 파일 작성\n",
    "yaml_content = r\"\"\"\n",
    "train: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\train\\CIDNet_Moderate\n",
    "val: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Moderate\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Human pose estimation']\n",
    "\n",
    "roboflow:\n",
    "  workspace: project-wk4fq\n",
    "  project: cctv-people\n",
    "  version: 1\n",
    "  license: CC BY 4.0\n",
    "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(r'C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\CIDNet_moderate.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5abd1c-0768-4deb-9269-a46a71d297b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDNet_severe.yaml 파일 작성\n",
    "yaml_content = r\"\"\"\n",
    "train: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\train\\CIDNet_Severe\n",
    "val: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Severe\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Human pose estimation']\n",
    "\n",
    "roboflow:\n",
    "  workspace: project-wk4fq\n",
    "  project: cctv-people\n",
    "  version: 1\n",
    "  license: CC BY 4.0\n",
    "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(r'C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\CIDNet_severe.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b9899e-1a4d-4b41-b036-a6b4e30e8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDNet_extreme.yaml 파일 작성\n",
    "yaml_content = r\"\"\"\n",
    "train: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\train\\CIDNet_Extreme\n",
    "val: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Extreme\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Human pose estimation']\n",
    "\n",
    "roboflow:\n",
    "  workspace: project-wk4fq\n",
    "  project: cctv-people\n",
    "  version: 1\n",
    "  license: CC BY 4.0\n",
    "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(r'C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\CIDNet_extreme.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4b40e5-19e7-4eda-8e6d-21286b16dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been organized into 'images/' subdirectories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 저조도 이미지 폴더들\n",
    "low_brightness_folders = [\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Moderate\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Severe\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Extreme\",\n",
    "]\n",
    "\n",
    "# 각 폴더의 이미지를 `images/` 하위로 이동\n",
    "for folder in low_brightness_folders:\n",
    "    images_folder = os.path.join(folder, \"images\")\n",
    "\n",
    "    # `images/` 폴더 생성\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "    # 폴더 내 모든 파일 확인\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".jpg\"):  # 이미지 파일만 이동\n",
    "            src_path = os.path.join(folder, file)\n",
    "            dst_path = os.path.join(images_folder, file)\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Images have been organized into 'images/' subdirectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcd98a7-2283-4dc4-9b3b-55f4886ed974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 원본 라벨 폴더\n",
    "labels_folder = r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\labels\"\n",
    "\n",
    "# 저조도 이미지 폴더들\n",
    "low_brightness_folders = [\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Moderate\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Severe\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Extreme\",\n",
    "]\n",
    "\n",
    "# 각 저조도 폴더에 라벨 복사\n",
    "for folder in low_brightness_folders:\n",
    "    images_folder = os.path.join(folder, \"images\")\n",
    "    labels_output_folder = os.path.join(folder, \"labels\")\n",
    "\n",
    "    # 라벨 저장 폴더가 없으면 생성\n",
    "    os.makedirs(labels_output_folder, exist_ok=True)\n",
    "\n",
    "    # 이미지 파일 이름에 맞는 라벨 복사\n",
    "    for image_file in os.listdir(images_folder):\n",
    "        if image_file.endswith(\".jpg\"):  # 이미지 파일만 처리\n",
    "            label_file = image_file.replace(\".jpg\", \".txt\")  # 라벨 파일 이름\n",
    "            src_label_path = os.path.join(labels_folder, label_file)\n",
    "            dst_label_path = os.path.join(labels_output_folder, label_file)\n",
    "\n",
    "            # 라벨 파일 복사\n",
    "            if os.path.exists(src_label_path):\n",
    "                shutil.copy(src_label_path, dst_label_path)\n",
    "            else:\n",
    "                print(f\"Label not found for {image_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b8c71b1-8839-4a94-b0dd-3074834c9f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n",
      "YOLO11x summary (fused): 464 layers, 56,919,424 parameters, 0 gradients, 194.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|███\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.767      0.634       0.65      0.155\n",
      "                person        175        227      0.767      0.634       0.65      0.155\n",
      "Speed: 3.7ms preprocess, 1485.9ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO(\"yolo11x.pt\")\n",
    "\n",
    "# 평가 실행\n",
    "results_origin = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\origin.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e2625f-8bac-4ca3-9e39-ae205aaaaafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Moderate\\labels... 175 images, 0 backgrounds, 0 corrupt\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Moderate\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.639      0.405      0.404     0.0969\n",
      "                person        175        227      0.639      0.405      0.404     0.0969\n",
      "Speed: 3.4ms preprocess, 1546.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# moderate\n",
    "results_severe = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\CIDNet_moderate.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954e2f56-1633-422f-8445-faae9c2daa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Severe\\labels... 175 images, 0 backgrounds, 0 corrupt: \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Severe\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.491      0.176      0.171     0.0386\n",
      "                person        175        227      0.491      0.176      0.171     0.0386\n",
      "Speed: 5.1ms preprocess, 1481.5ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# severe\n",
    "results_severe = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\CIDNet_severe.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3158ed0a-e81a-45ff-acf3-06f05a508987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Extreme\\labels... 175 images, 0 backgrounds, 0 corrupt:\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\CIDNet_Extreme\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.228     0.0661     0.0458      0.008\n",
      "                person        175        227      0.228     0.0661     0.0458      0.008\n",
      "Speed: 4.7ms preprocess, 1485.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# extreme\n",
    "results_extreme = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\CIDNet_extreme.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17d2003f-6ac2-4187-acc8-f76816b6b98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Condition          Precision (P)             Recall (R)     mAP50  mAP50-95\n",
      "0  Original   [0.6921720491553374]   [0.4801762114537445]  0.478891  0.115051\n",
      "1  Moderate   [0.6372374649857822]  [0.18502202643171806]  0.199861  0.051658\n",
      "2    Severe  [0.24401596836722703]  [0.07048458149779736]  0.065148  0.016493\n",
      "3   Extreme   [0.4047893514473378]  [0.14537444933920704]  0.161142  0.037360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOLO 평가 결과에서 메트릭을 추출합니다.\n",
    "def extract_metrics(result):\n",
    "    metrics = {\n",
    "        \"Precision (P)\": result.box.p,  # 단일 값으로 사용\n",
    "        \"Recall (R)\": result.box.r,     # 단일 값으로 사용\n",
    "        \"mAP50\": result.box.map50,      # 단일 값으로 사용\n",
    "        \"mAP50-95\": result.box.map\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# 각 결과로부터 메트릭을 추출합니다.\n",
    "metrics_original = extract_metrics(results_origin)\n",
    "metrics_moderate = extract_metrics(results_moderate)\n",
    "metrics_severe = extract_metrics(results_severe)\n",
    "metrics_extreme = extract_metrics(results_extreme)\n",
    "\n",
    "# 결과를 데이터프레임에 저장합니다.\n",
    "data = {\n",
    "    \"Condition\": [\"Original\", \"Moderate\", \"Severe\", \"Extreme\"],\n",
    "    \"Precision (P)\": [metrics_original[\"Precision (P)\"], metrics_moderate[\"Precision (P)\"], metrics_severe[\"Precision (P)\"], metrics_extreme[\"Precision (P)\"]],\n",
    "    \"Recall (R)\": [metrics_original[\"Recall (R)\"], metrics_moderate[\"Recall (R)\"], metrics_severe[\"Recall (R)\"], metrics_extreme[\"Recall (R)\"]],\n",
    "    \"mAP50\": [metrics_original[\"mAP50\"], metrics_moderate[\"mAP50\"], metrics_severe[\"mAP50\"], metrics_extreme[\"mAP50\"]],\n",
    "    \"mAP50-95\": [metrics_original[\"mAP50-95\"], metrics_moderate[\"mAP50-95\"], metrics_severe[\"mAP50-95\"], metrics_extreme[\"mAP50-95\"]],\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 출력 (확인용)\n",
    "print(df)\n",
    "\n",
    "# 메트릭 비교를 위한 시각화\n",
    "metrics = [\"Precision (P)\", \"Recall (R)\", \"mAP50\", \"mAP50-95\"]\n",
    "x = df[\"Condition\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 각 메트릭을 플롯으로 그립니다.\n",
    "for metric in metrics:\n",
    "    plt.plot(x, df[metric], marker='o', label=metric)  # 각 메트릭별로 플롯 생성\n",
    "\n",
    "# 라벨 및 제목 설정\n",
    "plt.xlabel(\"Low Brightness Condition\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Comparison of Evaluation Metrics Across Different Low Brightness Conditions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d9c7697-b183-4f53-9f5f-338f0f8309d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 업데이트된 데이터\n",
    "data = {\n",
    "    \"Condition\": [\"Original\", \"Moderate\", \"Severe\", \"Extreme\"],\n",
    "    \"Precision (P)\": [0.6921720491553374, 0.6372374649857822, 0.24401596836722703, 0.4047893514473378],\n",
    "    \"Recall (R)\": [0.4801762114537445, 0.18502202643171806, 0.07048458149779736, 0.14537444933920704],\n",
    "    \"mAP50\": [0.478891, 0.199861, 0.065148, 0.161142],\n",
    "    \"mAP50-95\": [0.115051, 0.051658, 0.016493, 0.037360],\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 시각화\n",
    "metrics = [\"Precision (P)\", \"Recall (R)\", \"mAP50\", \"mAP50-95\"]\n",
    "x = df[\"Condition\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.plot(x, df[metric], marker='o', label=metric)\n",
    "\n",
    "# 그래프 설정\n",
    "plt.xlabel(\"Low Brightness Condition\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Comparison of Evaluation Metrics Across Different Low Brightness Conditions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YOLO_env)",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
