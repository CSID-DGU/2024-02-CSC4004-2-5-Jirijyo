{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "778de2f8-0591-4016-95cf-bd5904832e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_moderate.yaml 파일 작성\n",
    "yaml_content = r\"\"\"\n",
    "train: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\train\\Zero_Moderate\n",
    "val: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Moderate\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Human pose estimation']\n",
    "\n",
    "roboflow:\n",
    "  workspace: project-wk4fq\n",
    "  project: cctv-people\n",
    "  version: 1\n",
    "  license: CC BY 4.0\n",
    "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(r'C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\zero_moderate.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2263c9be-9ef1-47e3-b924-eb0b7447ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_severe.yaml 파일 작성\n",
    "yaml_content = r\"\"\"\n",
    "train: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\train\\Zero_Severe\n",
    "val: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Severe\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Human pose estimation']\n",
    "\n",
    "roboflow:\n",
    "  workspace: project-wk4fq\n",
    "  project: cctv-people\n",
    "  version: 1\n",
    "  license: CC BY 4.0\n",
    "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(r'C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\zero_severe.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10d35dce-1c3f-4c9c-b0c7-e1e544e7a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_extreme.yaml 파일 작성\n",
    "yaml_content = r\"\"\"\n",
    "train: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\train\\Zero_Extreme\n",
    "val: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Extreme\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Human pose estimation']\n",
    "\n",
    "roboflow:\n",
    "  workspace: project-wk4fq\n",
    "  project: cctv-people\n",
    "  version: 1\n",
    "  license: CC BY 4.0\n",
    "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(r'C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\zero_extreme.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ece597-0f15-4f44-8b6e-98496b9e4290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been organized into 'images/' subdirectories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 저조도 이미지 폴더들\n",
    "low_brightness_folders = [\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Moderate\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Severe\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Extreme\",\n",
    "]\n",
    "\n",
    "# 각 폴더의 이미지를 `images/` 하위로 이동\n",
    "for folder in low_brightness_folders:\n",
    "    images_folder = os.path.join(folder, \"images\")\n",
    "\n",
    "    # `images/` 폴더 생성\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "    # 폴더 내 모든 파일 확인\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".jpg\"):  # 이미지 파일만 이동\n",
    "            src_path = os.path.join(folder, file)\n",
    "            dst_path = os.path.join(images_folder, file)\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Images have been organized into 'images/' subdirectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84077ff7-34b3-4952-aefd-4b09559feb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 원본 라벨 폴더\n",
    "labels_folder = r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\labels\"\n",
    "\n",
    "# 저조도 이미지 폴더들\n",
    "low_brightness_folders = [\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Moderate\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Severe\",\n",
    "    r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Extreme\",\n",
    "]\n",
    "\n",
    "# 각 저조도 폴더에 라벨 복사\n",
    "for folder in low_brightness_folders:\n",
    "    images_folder = os.path.join(folder, \"images\")\n",
    "    labels_output_folder = os.path.join(folder, \"labels\")\n",
    "\n",
    "    # 라벨 저장 폴더가 없으면 생성\n",
    "    os.makedirs(labels_output_folder, exist_ok=True)\n",
    "\n",
    "    # 이미지 파일 이름에 맞는 라벨 복사\n",
    "    for image_file in os.listdir(images_folder):\n",
    "        if image_file.endswith(\".jpg\"):  # 이미지 파일만 처리\n",
    "            label_file = image_file.replace(\".jpg\", \".txt\")  # 라벨 파일 이름\n",
    "            src_label_path = os.path.join(labels_folder, label_file)\n",
    "            dst_label_path = os.path.join(labels_output_folder, label_file)\n",
    "\n",
    "            # 라벨 파일 복사\n",
    "            if os.path.exists(src_label_path):\n",
    "                shutil.copy(src_label_path, dst_label_path)\n",
    "            else:\n",
    "                print(f\"Label not found for {image_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c6a9908-8c4c-4641-9d87-b992bcfd79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n",
      "YOLO11x summary (fused): 464 layers, 56,919,424 parameters, 0 gradients, 194.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|███\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.767      0.634       0.65      0.155\n",
      "                person        175        227      0.767      0.634       0.65      0.155\n",
      "Speed: 3.7ms preprocess, 1440.9ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO(\"yolo11x.pt\")\n",
    "\n",
    "# 평가 실행\n",
    "results_origin = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\origin.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad84dd9-0f34-4a6e-874e-5c3571afbab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Moderate\\labels... 175 images, 0 backgrounds, 0 corrupt: \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Moderate\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.649      0.388      0.397     0.0919\n",
      "                person        175        227      0.649      0.388      0.397     0.0919\n",
      "Speed: 4.1ms preprocess, 1420.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# moderate\n",
    "results_moderate = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\zero_moderate.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd57281a-e385-473e-bd7d-a75f6ecd6b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Severe\\labels... 175 images, 0 backgrounds, 0 corrupt: 10\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Severe\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227      0.424      0.194      0.182     0.0444\n",
      "                person        175        227      0.424      0.194      0.182     0.0444\n",
      "Speed: 5.1ms preprocess, 1430.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# severe\n",
    "results_severe = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\zero_severe.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "509248c2-f977-4589-92b0-c0756db33fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31  Python-3.8.18 torch-2.4.1+cpu CPU (Intel Core(TM) i5-7500 3.40GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Extreme\\labels... 175 images, 0 backgrounds, 0 corrupt: 1\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\valid\\Zero_Extreme\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [04:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175        227       0.17     0.0749     0.0567     0.0119\n",
      "                person        175        227       0.17     0.0749     0.0567     0.0119\n",
      "Speed: 4.9ms preprocess, 1419.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# extreme\n",
    "results_extreme = model.val(data=r\"C:\\Users\\yeoch\\CSC4004\\cctv-people-1\\yaml\\zero_extreme.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77cab419-555f-4f5a-9399-80a74d7f4920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Condition          Precision (P)             Recall (R)     mAP50  mAP50-95\n",
      "0  Original   [0.7674737259047942]   [0.6343612334801763]  0.649571  0.155325\n",
      "1  Moderate   [0.6492443394849756]   [0.3876651982378855]  0.396562  0.091943\n",
      "2    Severe   [0.4236589478289546]  [0.19383259911894274]  0.181539  0.044380\n",
      "3   Extreme  [0.16954071096904044]  [0.07488986784140969]  0.056703  0.011902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOLO 평가 결과에서 메트릭을 추출합니다.\n",
    "def extract_metrics(result):\n",
    "    metrics = {\n",
    "        \"Precision (P)\": result.box.p,  # 단일 값으로 사용\n",
    "        \"Recall (R)\": result.box.r,     # 단일 값으로 사용\n",
    "        \"mAP50\": result.box.map50,      # 단일 값으로 사용\n",
    "        \"mAP50-95\": result.box.map\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# 각 결과로부터 메트릭을 추출합니다.\n",
    "metrics_original = extract_metrics(results_origin)\n",
    "metrics_moderate = extract_metrics(results_moderate)\n",
    "metrics_severe = extract_metrics(results_severe)\n",
    "metrics_extreme = extract_metrics(results_extreme)\n",
    "\n",
    "# 결과를 데이터프레임에 저장합니다.\n",
    "data = {\n",
    "    \"Condition\": [\"Original\", \"Moderate\", \"Severe\", \"Extreme\"],\n",
    "    \"Precision (P)\": [metrics_original[\"Precision (P)\"], metrics_moderate[\"Precision (P)\"], metrics_severe[\"Precision (P)\"], metrics_extreme[\"Precision (P)\"]],\n",
    "    \"Recall (R)\": [metrics_original[\"Recall (R)\"], metrics_moderate[\"Recall (R)\"], metrics_severe[\"Recall (R)\"], metrics_extreme[\"Recall (R)\"]],\n",
    "    \"mAP50\": [metrics_original[\"mAP50\"], metrics_moderate[\"mAP50\"], metrics_severe[\"mAP50\"], metrics_extreme[\"mAP50\"]],\n",
    "    \"mAP50-95\": [metrics_original[\"mAP50-95\"], metrics_moderate[\"mAP50-95\"], metrics_severe[\"mAP50-95\"], metrics_extreme[\"mAP50-95\"]],\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 출력 (확인용)\n",
    "print(df)\n",
    "\n",
    "# 메트릭 비교를 위한 시각화\n",
    "metrics = [\"Precision (P)\", \"Recall (R)\", \"mAP50\", \"mAP50-95\"]\n",
    "x = df[\"Condition\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 각 메트릭을 플롯으로 그립니다.\n",
    "for metric in metrics:\n",
    "    plt.plot(x, df[metric], marker='o', label=metric)  # 각 메트릭별로 플롯 생성\n",
    "\n",
    "# 라벨 및 제목 설정\n",
    "plt.xlabel(\"Low Brightness Condition\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Comparison of Evaluation Metrics Across Different Low Brightness Conditions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2036686-f0d0-48de-a6c1-c922732d2b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YOLO_env)",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
