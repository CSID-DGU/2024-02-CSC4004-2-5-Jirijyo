{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **yaml 작성**\n",
        "\n",
        "*   data_origin.yaml\n",
        "*   data_moderate.yaml\n",
        "*   data_severe.yaml\n",
        "*   data_extreme.yaml\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jvEvHmAHs3wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRVAj-8AqGdu",
        "outputId": "b62b2019-ec58-45f1-9ea5-99de61c69c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_origin.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/images\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OGd9gShs98l",
        "outputId": "482d5606-30dd-4e52-90eb-e4f26dc1d5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/images\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_moderate.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_Nkgm65tcjF",
        "outputId": "4c4128b1-f667-4f2b-e199-21c954dbee0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_severe.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaGKZ_-tuuze",
        "outputId": "f2f5fb2d-b5c1-432a-c243-59f305c13933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_extreme.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9wLWLkMu51h",
        "outputId": "6b7ed0c4-9a88-497e-fa03-e4309bb821cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **yolo**"
      ],
      "metadata": {
        "id": "7eXyR016vE7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train**"
      ],
      "metadata": {
        "id": "jO0OY24x7sBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4peng09RqOvL",
        "outputId": "899b4a38-3a45-4f2b-cd97-abef64059591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.39 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.6/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2JLqNPOBKjI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 원본 라벨 폴더\n",
        "labels_folder = \"/content/drive/MyDrive/CCTV-People-Dataset/train/labels\"\n",
        "\n",
        "# 저조도 이미지 폴더들\n",
        "low_brightness_folders = [\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme\",\n",
        "]\n",
        "\n",
        "# 각 저조도 폴더에 라벨 복사\n",
        "for folder in low_brightness_folders:\n",
        "    images_folder = os.path.join(folder, \"images\")\n",
        "    labels_output_folder = os.path.join(folder, \"labels\")\n",
        "\n",
        "    # 라벨 저장 폴더가 없으면 생성\n",
        "    os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일 이름에 맞는 라벨 복사\n",
        "    for image_file in os.listdir(images_folder):\n",
        "        if image_file.endswith(\".jpg\"):  # 이미지 파일만 처리\n",
        "            label_file = image_file.replace(\".jpg\", \".txt\")  # 라벨 파일 이름\n",
        "            src_label_path = os.path.join(labels_folder, label_file)\n",
        "            dst_label_path = os.path.join(labels_output_folder, label_file)\n",
        "\n",
        "            # 라벨 파일 복사\n",
        "            if os.path.exists(src_label_path):\n",
        "                shutil.copy(src_label_path, dst_label_path)\n",
        "            else:\n",
        "                print(f\"Label not found for {image_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw94xq1_Ccju",
        "outputId": "26c1a953-74de-4545-8499-c29c1b394343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 273MB/s]\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=original, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 114MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/labels... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:09<00:00, 57.64it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/train/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:04<00:00, 36.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.58G      2.043      3.027      1.674         26        640: 100% 33/33 [00:20<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.18it/s]\n",
            "                   all        175        227    0.00356      0.824      0.148     0.0581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      1.856      2.518       1.55         21        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.155     0.0132     0.0465     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G       1.94      2.453      1.601         30        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.52it/s]\n",
            "                   all        175        227      0.578      0.145       0.19     0.0684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      1.964      2.291      1.646         29        640: 100% 33/33 [00:17<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.46it/s]\n",
            "                   all        175        227      0.464      0.374      0.335      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      1.946      2.282      1.632         20        640: 100% 33/33 [00:16<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.66it/s]\n",
            "                   all        175        227      0.193      0.163     0.0861     0.0366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.38G      1.907      2.057      1.616         27        640: 100% 33/33 [00:16<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.31it/s]\n",
            "                   all        175        227      0.409      0.379      0.312      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.37G       1.88      1.947      1.593         32        640: 100% 33/33 [00:16<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.16it/s]\n",
            "                   all        175        227       0.51      0.405      0.408      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.37G      1.902      1.945      1.642         22        640: 100% 33/33 [00:15<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.30it/s]\n",
            "                   all        175        227      0.623      0.515      0.563      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.37G      1.838      1.821      1.609         27        640: 100% 33/33 [00:15<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.83it/s]\n",
            "                   all        175        227      0.688      0.515      0.588      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.874      1.836      1.618         29        640: 100% 33/33 [00:19<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.26it/s]\n",
            "                   all        175        227      0.591      0.529      0.544      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.37G      1.787      1.717      1.556         30        640: 100% 33/33 [00:13<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.40it/s]\n",
            "                   all        175        227      0.679      0.559      0.617      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.36G      1.729      1.663      1.527         24        640: 100% 33/33 [00:17<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.43it/s]\n",
            "                   all        175        227      0.744      0.577      0.654      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.804      1.728      1.541         21        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.721       0.58      0.618      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.737      1.573      1.527         27        640: 100% 33/33 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.54it/s]\n",
            "                   all        175        227      0.781      0.661      0.725      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.683      1.513      1.483         20        640: 100% 33/33 [00:17<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "                   all        175        227      0.746      0.582      0.645      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G      1.702      1.543      1.525         24        640: 100% 33/33 [00:17<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.783      0.573      0.679      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G      1.664      1.499      1.472         39        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.97it/s]\n",
            "                   all        175        227      0.708      0.653      0.693      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.39G      1.573      1.393      1.421         36        640: 100% 33/33 [00:15<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.17it/s]\n",
            "                   all        175        227      0.816      0.612      0.692      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.612      1.446      1.417         27        640: 100% 33/33 [00:13<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.83it/s]\n",
            "                   all        175        227      0.738      0.545      0.617      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.37G      1.624       1.41      1.445         22        640: 100% 33/33 [00:14<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "                   all        175        227      0.776      0.639      0.721      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.586      1.369       1.41         26        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.84it/s]\n",
            "                   all        175        227      0.659      0.652      0.684      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.541      1.329      1.428         27        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                   all        175        227      0.754      0.674      0.717      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.583      1.355      1.435         24        640: 100% 33/33 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.68it/s]\n",
            "                   all        175        227      0.775       0.67       0.74      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.555      1.291      1.433         32        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.95it/s]\n",
            "                   all        175        227      0.856      0.628      0.753      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G      1.507      1.261      1.379         25        640: 100% 33/33 [00:18<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227      0.858      0.674      0.775      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.579      1.313      1.418         32        640: 100% 33/33 [00:11<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.37it/s]\n",
            "                   all        175        227      0.793      0.692      0.746      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.481      1.212      1.349         25        640: 100% 33/33 [00:11<00:00,  2.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.91it/s]\n",
            "                   all        175        227       0.85      0.699      0.778      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.464      1.212      1.371         22        640: 100% 33/33 [00:11<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                   all        175        227       0.84      0.665      0.771       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.491      1.199      1.387         25        640: 100% 33/33 [00:12<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.99it/s]\n",
            "                   all        175        227      0.835      0.714      0.791      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.455      1.195      1.369         24        640: 100% 33/33 [00:13<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.91it/s]\n",
            "                   all        175        227      0.824      0.696      0.792      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.458      1.198      1.351         27        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.26it/s]\n",
            "                   all        175        227      0.804      0.705      0.778      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.429      1.138      1.345         30        640: 100% 33/33 [00:14<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.86it/s]\n",
            "                   all        175        227      0.822      0.722       0.79      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.444      1.144      1.336         26        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                   all        175        227      0.796      0.683      0.771      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.433      1.107      1.315         33        640: 100% 33/33 [00:13<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                   all        175        227       0.87       0.71      0.825      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.408      1.095      1.303         39        640: 100% 33/33 [00:13<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.50it/s]\n",
            "                   all        175        227      0.879      0.704      0.819      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.359      1.064      1.303         28        640: 100% 33/33 [00:13<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "                   all        175        227      0.791      0.767      0.825      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.393      1.052      1.285         24        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                   all        175        227      0.774      0.714      0.795      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G       1.34      1.046      1.272         24        640: 100% 33/33 [00:13<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "                   all        175        227      0.836      0.749      0.829      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.279      1.006      1.252         31        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.25it/s]\n",
            "                   all        175        227      0.809      0.748      0.813      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G       1.29      1.014      1.254         22        640: 100% 33/33 [00:13<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.12it/s]\n",
            "                   all        175        227      0.919      0.727      0.841      0.488\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.54G      1.187     0.9048      1.209         16        640: 100% 33/33 [00:23<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.46it/s]\n",
            "                   all        175        227      0.884      0.674       0.79      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G      1.203     0.8535      1.228         17        640: 100% 33/33 [00:16<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.49it/s]\n",
            "                   all        175        227      0.916      0.717      0.844      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.171     0.8304      1.195         14        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.60it/s]\n",
            "                   all        175        227      0.891      0.727       0.85      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.141     0.8231       1.19         17        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.07it/s]\n",
            "                   all        175        227      0.886      0.749       0.85      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G       1.11     0.7853      1.167         18        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.73it/s]\n",
            "                   all        175        227      0.855      0.777      0.852      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G      1.115     0.7643      1.175         17        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.71it/s]\n",
            "                   all        175        227       0.86      0.787      0.857      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G        1.1     0.7644      1.159         16        640: 100% 33/33 [00:16<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.41it/s]\n",
            "                   all        175        227       0.85      0.784       0.86      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.073     0.7458      1.129         17        640: 100% 33/33 [00:14<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.95it/s]\n",
            "                   all        175        227       0.87      0.797      0.866      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.063     0.7363      1.144         18        640: 100% 33/33 [00:11<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "                   all        175        227       0.85      0.789      0.862      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.067     0.7138      1.139         14        640: 100% 33/33 [00:10<00:00,  3.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.86it/s]\n",
            "                   all        175        227      0.857      0.811      0.865      0.511\n",
            "\n",
            "50 epochs completed in 0.279 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.852      0.789      0.862      0.514\n",
            "Speed: 0.4ms preprocess, 4.0ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간 저조도 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=moderate\n",
        "\n",
        "# 심한 저조도 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=severe\n",
        "\n",
        "# 매우 심한 저조도 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=extreme"
      ],
      "metadata": {
        "id": "AlJVgG11Bsy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740b7ad3-5891-4b9d-9bbc-574b3643c12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=moderate, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate/labels... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:07<00:00, 68.56it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:03<00:00, 54.60it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.58G       2.15      3.229      1.762         26        640: 100% 33/33 [00:17<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                   all        175        227     0.0035      0.811      0.132     0.0564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      2.007      2.661      1.657         21        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.703      0.104      0.273      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G      2.062       2.68      1.743         30        640: 100% 33/33 [00:11<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227      0.266      0.304      0.211     0.0764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      2.044      2.503      1.808         29        640: 100% 33/33 [00:12<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "                   all        175        227     0.0506     0.0264    0.00736     0.0031\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      1.971      2.358      1.726         20        640: 100% 33/33 [00:13<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.31it/s]\n",
            "                   all        175        227      0.407      0.381      0.333      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.39G      2.014      2.181        1.8         27        640: 100% 33/33 [00:13<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.82it/s]\n",
            "                   all        175        227      0.486      0.401      0.386      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.36G      1.973      2.072      1.749         32        640: 100% 33/33 [00:13<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.81it/s]\n",
            "                   all        175        227      0.483      0.352      0.392      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.36G      1.952       2.03      1.765         22        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.35it/s]\n",
            "                   all        175        227      0.583      0.432      0.474       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      1.942      1.967      1.733         27        640: 100% 33/33 [00:13<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.71it/s]\n",
            "                   all        175        227      0.714      0.451      0.542      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G       1.92      1.919      1.695         29        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.58it/s]\n",
            "                   all        175        227      0.661      0.467      0.511      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.36G      1.868      1.835      1.644         30        640: 100% 33/33 [00:15<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.29it/s]\n",
            "                   all        175        227      0.654      0.449      0.518      0.238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.36G      1.812      1.746      1.654         24        640: 100% 33/33 [00:15<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.22it/s]\n",
            "                   all        175        227      0.683      0.522      0.565      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.866      1.825      1.644         21        640: 100% 33/33 [00:15<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.19it/s]\n",
            "                   all        175        227       0.74       0.59      0.638       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.798      1.686      1.602         27        640: 100% 33/33 [00:18<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.89it/s]\n",
            "                   all        175        227      0.733      0.432      0.538      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.789      1.648      1.589         20        640: 100% 33/33 [00:21<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.49it/s]\n",
            "                   all        175        227      0.801      0.577      0.671      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G       1.77      1.667      1.658         24        640: 100% 33/33 [00:16<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.30it/s]\n",
            "                   all        175        227      0.687       0.48      0.579      0.291\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G      1.697       1.58      1.582         39        640: 100% 33/33 [00:17<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.74it/s]\n",
            "                   all        175        227      0.701      0.511      0.599      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.38G      1.666      1.546      1.537         36        640: 100% 33/33 [00:20<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.16it/s]\n",
            "                   all        175        227      0.743      0.515      0.618      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.704      1.602      1.554         27        640: 100% 33/33 [00:23<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                   all        175        227      0.766      0.581      0.648      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G      1.672      1.502       1.53         22        640: 100% 33/33 [00:17<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.53it/s]\n",
            "                   all        175        227      0.808       0.59      0.677      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.682      1.448      1.535         26        640: 100% 33/33 [00:19<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.05it/s]\n",
            "                   all        175        227      0.735      0.595       0.62      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.603      1.432       1.53         27        640: 100% 33/33 [00:17<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.65it/s]\n",
            "                   all        175        227      0.749      0.586      0.653      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.678      1.486      1.585         24        640: 100% 33/33 [00:17<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.50it/s]\n",
            "                   all        175        227      0.702       0.59      0.655      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.649      1.411      1.538         32        640: 100% 33/33 [00:17<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.65it/s]\n",
            "                   all        175        227      0.737      0.599      0.667      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G      1.577      1.337      1.484         25        640: 100% 33/33 [00:17<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.34it/s]\n",
            "                   all        175        227      0.825      0.612      0.733      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.677      1.395      1.529         32        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.25it/s]\n",
            "                   all        175        227      0.805      0.619       0.71      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.547      1.316      1.447         25        640: 100% 33/33 [00:15<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.75it/s]\n",
            "                   all        175        227      0.842      0.633      0.741       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.512      1.317      1.469         22        640: 100% 33/33 [00:21<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.37it/s]\n",
            "                   all        175        227      0.756      0.654      0.708      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.546      1.288      1.457         25        640: 100% 33/33 [00:16<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.04it/s]\n",
            "                   all        175        227        0.8      0.617      0.709      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.488      1.255      1.438         24        640: 100% 33/33 [00:16<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.04it/s]\n",
            "                   all        175        227      0.834      0.643      0.751       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.551      1.273      1.465         27        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.92it/s]\n",
            "                   all        175        227      0.868      0.606      0.741      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.502      1.233      1.425         30        640: 100% 33/33 [00:15<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.48it/s]\n",
            "                   all        175        227       0.77      0.709      0.745       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.536      1.277      1.441         26        640: 100% 33/33 [00:15<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.49it/s]\n",
            "                   all        175        227      0.815      0.658      0.755      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.467      1.206      1.404         33        640: 100% 33/33 [00:15<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.77it/s]\n",
            "                   all        175        227      0.823      0.676      0.765      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.489      1.181      1.404         39        640: 100% 33/33 [00:14<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.14it/s]\n",
            "                   all        175        227      0.804      0.612      0.725      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.447       1.17      1.418         28        640: 100% 33/33 [00:12<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227      0.831      0.627      0.736      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.437       1.13      1.381         24        640: 100% 33/33 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.43it/s]\n",
            "                   all        175        227      0.799      0.647      0.722      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G      1.444      1.151        1.4         24        640: 100% 33/33 [00:11<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                   all        175        227      0.837      0.677       0.79      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.389      1.135      1.371         31        640: 100% 33/33 [00:12<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.69it/s]\n",
            "                   all        175        227      0.884      0.626      0.777      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G      1.377      1.113      1.379         22        640: 100% 33/33 [00:12<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.94it/s]\n",
            "                   all        175        227      0.823      0.692      0.773      0.423\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.54G      1.277     0.9929       1.37         16        640: 100% 33/33 [00:16<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.29it/s]\n",
            "                   all        175        227       0.84        0.7      0.776      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G      1.282     0.9348      1.357         17        640: 100% 33/33 [00:11<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                   all        175        227      0.888       0.63      0.761      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.262     0.9038      1.346         14        640: 100% 33/33 [00:15<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "                   all        175        227      0.816      0.683      0.764      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.234     0.8884      1.333         17        640: 100% 33/33 [00:12<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.23it/s]\n",
            "                   all        175        227      0.861      0.696      0.782      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G      1.247     0.8922      1.337         18        640: 100% 33/33 [00:13<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.53it/s]\n",
            "                   all        175        227      0.909      0.683      0.793      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G      1.174     0.8338      1.297         17        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.89it/s]\n",
            "                   all        175        227       0.82        0.7      0.778      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G      1.182     0.8488      1.302         16        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.12it/s]\n",
            "                   all        175        227       0.83      0.709      0.785      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.166     0.8381      1.277         17        640: 100% 33/33 [00:15<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.72it/s]\n",
            "                   all        175        227      0.824      0.727      0.789       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.165     0.8248      1.303         18        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.02it/s]\n",
            "                   all        175        227      0.807       0.74       0.79      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.147     0.7922       1.26         14        640: 100% 33/33 [00:14<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.79it/s]\n",
            "                   all        175        227       0.86      0.705      0.792      0.462\n",
            "\n",
            "50 epochs completed in 0.288 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                   all        175        227      0.807       0.74       0.79      0.462\n",
            "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=severe, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe/labels... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:07<00:00, 71.31it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:03<00:00, 57.75it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.58G      2.137      3.245      1.741         26        640: 100% 33/33 [00:16<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.21it/s]\n",
            "                   all        175        227    0.00381      0.881     0.0775     0.0402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      1.989        2.7      1.661         21        640: 100% 33/33 [00:14<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.34it/s]\n",
            "                   all        175        227      0.467        0.3      0.317      0.114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G       2.05      2.647      1.712         30        640: 100% 33/33 [00:13<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "                   all        175        227     0.0455     0.0969     0.0192    0.00511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      2.031      2.434      1.763         29        640: 100% 33/33 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.30it/s]\n",
            "                   all        175        227      0.517      0.264      0.267      0.109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      1.971      2.343       1.74         20        640: 100% 33/33 [00:12<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "                   all        175        227       0.44      0.183      0.185     0.0793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.38G      1.976      2.193       1.75         27        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.27it/s]\n",
            "                   all        175        227      0.475      0.471      0.435      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.37G      1.949      2.096      1.686         32        640: 100% 33/33 [00:12<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                   all        175        227      0.639      0.432      0.486      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.37G      1.912      2.026      1.682         22        640: 100% 33/33 [00:13<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                   all        175        227       0.64      0.532      0.564      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      1.862      1.883      1.643         27        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.712      0.445      0.505       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.894      1.863      1.646         29        640: 100% 33/33 [00:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                   all        175        227      0.746      0.498      0.602      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.37G      1.853      1.822      1.627         30        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.22it/s]\n",
            "                   all        175        227      0.713      0.604      0.644      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.37G       1.78        1.7      1.587         24        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.20it/s]\n",
            "                   all        175        227      0.539      0.546      0.507      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.847      1.796      1.616         21        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.12it/s]\n",
            "                   all        175        227      0.651      0.471      0.528      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.796      1.676      1.559         27        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.17it/s]\n",
            "                   all        175        227      0.708      0.551      0.615      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.749      1.651      1.538         20        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.13it/s]\n",
            "                   all        175        227      0.667      0.564      0.611       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G      1.766       1.67      1.603         24        640: 100% 33/33 [00:16<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                   all        175        227      0.703      0.551      0.623      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G      1.723      1.606      1.557         39        640: 100% 33/33 [00:16<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.44it/s]\n",
            "                   all        175        227      0.774      0.574      0.651      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.38G      1.651      1.514      1.501         36        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.37it/s]\n",
            "                   all        175        227      0.716      0.581      0.672      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.707      1.587      1.509         27        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.45it/s]\n",
            "                   all        175        227      0.797      0.555      0.648      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G      1.639      1.482      1.479         22        640: 100% 33/33 [00:19<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.25it/s]\n",
            "                   all        175        227      0.778       0.65      0.691      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.613      1.429      1.459         26        640: 100% 33/33 [00:17<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.60it/s]\n",
            "                   all        175        227        0.8      0.608      0.693      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.603      1.387      1.487         27        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.17it/s]\n",
            "                   all        175        227      0.825      0.625      0.712      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.628       1.43      1.488         24        640: 100% 33/33 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.31it/s]\n",
            "                   all        175        227      0.688      0.642      0.688      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G        1.6       1.37       1.46         32        640: 100% 33/33 [00:16<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.46it/s]\n",
            "                   all        175        227      0.827      0.604       0.71        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G      1.535      1.334      1.423         25        640: 100% 33/33 [00:17<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.41it/s]\n",
            "                   all        175        227      0.807      0.645      0.725      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.596      1.373      1.452         32        640: 100% 33/33 [00:17<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.42it/s]\n",
            "                   all        175        227      0.809      0.661      0.748      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.509      1.276      1.386         25        640: 100% 33/33 [00:17<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.29it/s]\n",
            "                   all        175        227      0.783      0.667      0.765      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.507      1.285      1.419         22        640: 100% 33/33 [00:16<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.26it/s]\n",
            "                   all        175        227      0.829       0.63       0.72      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.503      1.251      1.403         25        640: 100% 33/33 [00:17<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.16it/s]\n",
            "                   all        175        227      0.893      0.625      0.767      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.467      1.238      1.378         24        640: 100% 33/33 [00:16<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.796        0.7      0.771      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.503      1.246      1.403         27        640: 100% 33/33 [00:16<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.54it/s]\n",
            "                   all        175        227      0.758      0.665      0.729      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.458      1.219      1.373         30        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.81it/s]\n",
            "                   all        175        227      0.902      0.656      0.782      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.496      1.235      1.376         26        640: 100% 33/33 [00:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227      0.846      0.701       0.77      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.453      1.173      1.339         33        640: 100% 33/33 [00:18<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.62it/s]\n",
            "                   all        175        227      0.859      0.674      0.789      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.404      1.153      1.329         39        640: 100% 33/33 [00:15<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.67it/s]\n",
            "                   all        175        227      0.829      0.683      0.767      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.425      1.129      1.353         28        640: 100% 33/33 [00:15<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.44it/s]\n",
            "                   all        175        227      0.833       0.68      0.763      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.413      1.112      1.321         24        640: 100% 33/33 [00:15<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.62it/s]\n",
            "                   all        175        227       0.85      0.714      0.803      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G      1.416      1.118      1.322         24        640: 100% 33/33 [00:16<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.892       0.67       0.79      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.382      1.096       1.31         31        640: 100% 33/33 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.79it/s]\n",
            "                   all        175        227      0.804      0.742      0.802      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G      1.375      1.071      1.306         22        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.792      0.736        0.8      0.451\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.36G       1.28     0.9808      1.265         16        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.14it/s]\n",
            "                   all        175        227      0.778      0.722      0.773      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G      1.254     0.9192      1.255         17        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.58it/s]\n",
            "                   all        175        227      0.857      0.714      0.808       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.196     0.8932       1.22         14        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.62it/s]\n",
            "                   all        175        227      0.852      0.753       0.82      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.217     0.8607      1.232         17        640: 100% 33/33 [00:15<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.18it/s]\n",
            "                   all        175        227      0.888      0.702      0.813      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G      1.187     0.8402      1.214         18        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.91it/s]\n",
            "                   all        175        227       0.91       0.71      0.828      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G      1.176     0.8263      1.202         17        640: 100% 33/33 [00:13<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227      0.863      0.718      0.825      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G      1.146     0.8114       1.19         16        640: 100% 33/33 [00:11<00:00,  2.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.23it/s]\n",
            "                   all        175        227      0.857      0.715      0.822      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.139     0.8195      1.163         17        640: 100% 33/33 [00:11<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                   all        175        227       0.88      0.736      0.829      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.116      0.794      1.177         18        640: 100% 33/33 [00:16<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                   all        175        227      0.882      0.744      0.832      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.113     0.7752      1.156         14        640: 100% 33/33 [00:12<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.65it/s]\n",
            "                   all        175        227      0.906      0.724      0.832      0.479\n",
            "\n",
            "50 epochs completed in 0.282 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:07<00:00,  1.22s/it]\n",
            "                   all        175        227       0.91      0.709      0.828      0.488\n",
            "Speed: 0.5ms preprocess, 5.5ms inference, 0.0ms loss, 12.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=extreme, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme/labels... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:07<00:00, 71.67it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:04<00:00, 37.33it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.58G      2.143      3.183       1.75         26        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.58it/s]\n",
            "                   all        175        227    0.00318      0.736      0.153     0.0587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      1.973      2.676      1.629         21        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.53it/s]\n",
            "                   all        175        227      0.543      0.286      0.337       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G      2.025      2.578      1.707         30        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.56it/s]\n",
            "                   all        175        227     0.0626      0.123     0.0386     0.0123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      2.005      2.433       1.72         29        640: 100% 33/33 [00:14<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.51it/s]\n",
            "                   all        175        227      0.309      0.282      0.198      0.077\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      1.989      2.341      1.696         20        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.68it/s]\n",
            "                   all        175        227      0.423      0.366      0.327      0.127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.38G       1.98      2.137      1.658         27        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.66it/s]\n",
            "                   all        175        227      0.222      0.273      0.137     0.0376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.36G      1.966      2.036      1.644         32        640: 100% 33/33 [00:15<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.52it/s]\n",
            "                   all        175        227      0.514      0.414      0.441      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.37G      1.913      1.956       1.66         22        640: 100% 33/33 [00:15<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.72it/s]\n",
            "                   all        175        227      0.515      0.427      0.452      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      1.908       1.92      1.669         27        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.56it/s]\n",
            "                   all        175        227      0.588      0.528      0.547      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.903      1.873      1.662         29        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.88it/s]\n",
            "                   all        175        227      0.605      0.486      0.547      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.36G      1.851      1.776      1.595         30        640: 100% 33/33 [00:17<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.14it/s]\n",
            "                   all        175        227      0.721      0.523      0.619      0.293\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.36G      1.802      1.659       1.55         24        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.10it/s]\n",
            "                   all        175        227      0.752      0.502      0.605      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.835       1.73      1.575         21        640: 100% 33/33 [00:14<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.84it/s]\n",
            "                   all        175        227      0.699      0.581       0.64       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.764      1.612      1.517         27        640: 100% 33/33 [00:14<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.66it/s]\n",
            "                   all        175        227      0.752        0.6      0.675      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.732      1.556      1.502         20        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.89it/s]\n",
            "                   all        175        227      0.689      0.568       0.62      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G      1.708      1.593      1.549         24        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.30it/s]\n",
            "                   all        175        227      0.742      0.597      0.688      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G      1.701       1.52      1.539         39        640: 100% 33/33 [00:14<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.35it/s]\n",
            "                   all        175        227      0.868      0.551      0.667      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.38G      1.616      1.435      1.484         36        640: 100% 33/33 [00:14<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "                   all        175        227      0.791      0.586      0.695      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.648      1.486      1.454         27        640: 100% 33/33 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.807      0.577      0.707      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G       1.63      1.436      1.459         22        640: 100% 33/33 [00:12<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "                   all        175        227      0.815       0.62      0.709      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.621      1.403      1.452         26        640: 100% 33/33 [00:11<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.66it/s]\n",
            "                   all        175        227       0.75      0.537      0.633      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.571      1.379      1.468         27        640: 100% 33/33 [00:11<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.25it/s]\n",
            "                   all        175        227      0.845      0.624      0.733      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.603       1.38      1.457         24        640: 100% 33/33 [00:12<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.40it/s]\n",
            "                   all        175        227      0.729       0.63        0.7      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.563      1.316      1.429         32        640: 100% 33/33 [00:14<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.32it/s]\n",
            "                   all        175        227      0.826      0.665      0.778      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G      1.506      1.252      1.391         25        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.38it/s]\n",
            "                   all        175        227      0.836      0.631      0.739      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.578      1.347      1.411         32        640: 100% 33/33 [00:14<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                   all        175        227      0.821      0.705      0.782      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.505      1.253      1.373         25        640: 100% 33/33 [00:19<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.71it/s]\n",
            "                   all        175        227      0.836        0.7      0.789      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.529      1.237        1.4         22        640: 100% 33/33 [00:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.77it/s]\n",
            "                   all        175        227      0.817      0.648      0.758      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.503      1.197       1.38         25        640: 100% 33/33 [00:14<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.34it/s]\n",
            "                   all        175        227      0.777      0.736      0.783      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.492      1.225      1.365         24        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.82it/s]\n",
            "                   all        175        227      0.888      0.678      0.804      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.504      1.213      1.379         27        640: 100% 33/33 [00:15<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.54it/s]\n",
            "                   all        175        227      0.855      0.648      0.762      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.464      1.171      1.362         30        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.78it/s]\n",
            "                   all        175        227      0.807       0.63      0.747      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.482      1.191      1.369         26        640: 100% 33/33 [00:14<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.94it/s]\n",
            "                   all        175        227      0.843      0.648      0.766      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.477      1.158      1.366         33        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.71it/s]\n",
            "                   all        175        227      0.938      0.692        0.8      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.417      1.112      1.324         39        640: 100% 33/33 [00:14<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.72it/s]\n",
            "                   all        175        227      0.885      0.676      0.795      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.395      1.089      1.321         28        640: 100% 33/33 [00:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.88it/s]\n",
            "                   all        175        227      0.848      0.616      0.745      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.406      1.098        1.3         24        640: 100% 33/33 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                   all        175        227      0.759      0.705      0.771      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G      1.363      1.076      1.289         24        640: 100% 33/33 [00:11<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "                   all        175        227      0.825      0.731      0.815      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.351      1.052      1.292         31        640: 100% 33/33 [00:10<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                   all        175        227      0.808      0.758       0.81      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G      1.348      1.061      1.298         22        640: 100% 33/33 [00:11<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.31it/s]\n",
            "                   all        175        227      0.828       0.72       0.79      0.451\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.43G       1.23     0.9382      1.234         16        640: 100% 33/33 [00:15<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.21it/s]\n",
            "                   all        175        227      0.875      0.665      0.788      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G      1.213      0.881      1.224         17        640: 100% 33/33 [00:13<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.82it/s]\n",
            "                   all        175        227      0.853      0.718      0.805       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.156     0.8445      1.199         14        640: 100% 33/33 [00:18<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                   all        175        227      0.874      0.705      0.809      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.183     0.8543      1.214         17        640: 100% 33/33 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.68it/s]\n",
            "                   all        175        227      0.841      0.745       0.81      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G      1.168     0.8026      1.183         18        640: 100% 33/33 [00:13<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.02it/s]\n",
            "                   all        175        227      0.847       0.73      0.815      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G       1.16     0.7934      1.191         17        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.51it/s]\n",
            "                   all        175        227       0.86      0.733      0.818      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G      1.143     0.7776       1.18         16        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.71it/s]\n",
            "                   all        175        227      0.884      0.705      0.828      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.132     0.7817      1.162         17        640: 100% 33/33 [00:13<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.19it/s]\n",
            "                   all        175        227      0.875      0.758      0.831      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.101     0.7768      1.173         18        640: 100% 33/33 [00:11<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                   all        175        227      0.882       0.74      0.834      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.113      0.749      1.156         14        640: 100% 33/33 [00:10<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "                   all        175        227      0.854      0.744      0.831      0.496\n",
            "\n",
            "50 epochs completed in 0.259 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.24it/s]\n",
            "                   all        175        227      0.883       0.74      0.834      0.501\n",
            "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**valid**"
      ],
      "metadata": {
        "id": "ym6XsoM27vGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 원본 라벨 폴더\n",
        "labels_folder = \"/content/drive/MyDrive/CCTV-People-Dataset/valid/labels\"\n",
        "\n",
        "# 저조도 이미지 폴더들\n",
        "low_brightness_folders = [\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme\",\n",
        "]\n",
        "\n",
        "# 각 저조도 폴더에 라벨 복사\n",
        "for folder in low_brightness_folders:\n",
        "    images_folder = os.path.join(folder, \"images\")\n",
        "    labels_output_folder = os.path.join(folder, \"labels\")\n",
        "\n",
        "    # 라벨 저장 폴더가 없으면 생성\n",
        "    os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일 이름에 맞는 라벨 복사\n",
        "    for image_file in os.listdir(images_folder):\n",
        "        if image_file.endswith(\".jpg\"):  # 이미지 파일만 처리\n",
        "            label_file = image_file.replace(\".jpg\", \".txt\")  # 라벨 파일 이름\n",
        "            src_label_path = os.path.join(labels_folder, label_file)\n",
        "            dst_label_path = os.path.join(labels_output_folder, label_file)\n",
        "\n",
        "            # 라벨 파일 복사\n",
        "            if os.path.exists(src_label_path):\n",
        "                shutil.copy(src_label_path, dst_label_path)\n",
        "            else:\n",
        "                print(f\"Label not found for {image_file}\")"
      ],
      "metadata": {
        "id": "8zH0Uzu_0Q_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# 원본 데이터로 훈련된 모델 평가\n",
        "model_original = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/best.pt')\n",
        "results_original = model_original.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHd9NtgV4bjV",
        "outputId": "cf9ee569-67ef-4805-98a8-77ff093a3093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:04<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227      0.853      0.789      0.862      0.513\n",
            "Speed: 3.2ms preprocess, 5.1ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 확인\n",
        "print(\"Classes 적용 여부 확인:\")\n",
        "print(\"Classes:\", results_original.names)  # 모델이 사용 중인 클래스 이름 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D-Iiu2Y2kHI",
        "outputId": "155e7982-6121-4efc-ff50-939352763317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes 적용 여부 확인:\n",
            "Classes: {0: 'Human pose estimation'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간 저조도\n",
        "model_moderate = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/best.pt')\n",
        "results_moderate = model_moderate.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml')\n",
        "\n",
        "# 심한 저조도\n",
        "model_severe = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe/weights/best.pt')\n",
        "results_severe = model_severe.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml')\n",
        "\n",
        "# 매우 심한 저조도\n",
        "model_extreme = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/best.pt')\n",
        "results_extreme = model_extreme.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89f52a0-0ad6-48df-883e-c7e637eeab92",
        "id": "mgL2sQj5U-39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [01:04<00:00,  5.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227      0.807       0.74       0.79      0.463\n",
            "Speed: 9.6ms preprocess, 322.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:57<00:00,  5.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227       0.91       0.71      0.828      0.486\n",
            "Speed: 9.8ms preprocess, 279.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:55<00:00,  5.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227      0.883       0.74      0.834      0.498\n",
            "Speed: 9.3ms preprocess, 270.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**평가 지표**\n",
        "\n",
        "현재 데이터셋에 클래스가 하나('person')만 존재하므로, mAP 값과 AP 값은 동일하게 나타남."
      ],
      "metadata": {
        "id": "4PJoIvBIt30D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "fe503628-cbea-4dbc-97d0-4da73fa3b18b",
        "id": "0StC48yD9MB4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Condition         Precision (P)            Recall (R)     mAP50  mAP50-95\n",
            "0  Original  [0.8534775417660676]   [0.788546255506608]  0.862482  0.512603\n",
            "1  Moderate  [0.8069267395775382]  [0.7400881057268722]  0.790077  0.463489\n",
            "2    Severe  [0.9096853644813435]  [0.7099523935432843]  0.828222  0.486127\n",
            "3   Extreme  [0.8829064541241638]  [0.7400881057268722]  0.834038  0.498265\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAK9CAYAAABYVS0qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAADz+ElEQVR4nOzdd3hUVfoH8O/0SZ303hMEQgk1SEkoCYIFZRUbKyouom5VbNhWcdXVddeyNsD+A7Ggrl2QUCO9GXpJ7wlpkzrJZOb8/riZSYZMIECSmcD38zz3gdy59865U+7MO+ec95UJIQSIiIiIiIiIyOHkjm4AEREREREREUkYpBMRERERERE5CQbpRERERERERE6CQToRERERERGRk2CQTkREREREROQkGKQTEREREREROQkG6UREREREREROgkE6ERERERERkZNgkE5ERERERETkJBikE9F5k8lkeOaZZxzdjAu2YsUKDBo0CCqVCl5eXo5uTie5ubmQyWT46KOPHHL/H330EWQyGXJzcx1y/84oKioKd955p6ObQW3uvPNOREVF2ayrr6/HggULEBQUBJlMhvvvvx8AUFZWhjlz5sDX1xcymQyvvfZan7eXzs+UKVMwZcqU89536NChPdsgOmf2Ps+eeeYZyGSybu3PzyO6VDBIJ7oAWVlZuOeeexATEwOtVgtPT09MnDgRr7/+OpqamhzdPOqGY8eO4c4770RsbCzeffddLF++vMttLV8kulpKS0v7sOU974UXXsA333zj6GbYiIqKgkwmQ2pqqt3b3333Xevjv2fPnnM+/pEjR/DMM8/0my98R48ehUwmg1arRU1NjaOb0ytOf5+5uroiIiICs2bNwocffojm5uZuHeeFF17ARx99hPvuuw8rVqzAvHnzAAAPPPAA1q5di8ceewwrVqzAzJkze/N0Lsjbb799Tj/OyWQy/PnPf+69Bp2n06+Vbm5uiI+Px3PPPYfGxkZHN89GcXExnnnmGfz222+ObkqPqK2txZIlS5CQkAB3d3e4uLhg6NChePTRR1FcXOzo5nXJGT+PiPqS0tENIOqvfvzxR9x4443QaDS4/fbbMXToULS0tODXX3/Fww8/jMOHD58x4LsYNDU1Qans35eRTZs2wWw24/XXX0dcXFy39nnnnXfg7u7eab0z9sKfixdeeAFz5szB7NmzbdbPmzcPt9xyCzQajUPapdVqsXHjRpSWliIoKMjmtk8++QRarRYGg+G8jn3kyBEsWbIEU6ZM6dQTeybHjx+HXN73v3OvXLkSQUFBqK6uxpdffokFCxb0eRv6iuV91tzcjKKiIqxduxZ33XUXXnvtNfzwww8IDw+3bvvuu+/CbDbb7L9hwwZcfvnlePrppzutv+666/DQQw/1yXlciLfffht+fn4XxaiN6dOn4/bbbwcgjXJIT0/HU089hYyMDKxevbpbx/jll196s4kApCB9yZIliIqKwogRI3r9/npTdnY2UlNTkZ+fjxtvvBELFy6EWq3GgQMH8P777+N///sfTpw44ehm4sknn8TixYtt1jnr5xFRX+nf366JHCQnJwe33HILIiMjsWHDBgQHB1tv+9Of/oTMzEz8+OOPDmxh7zGbzWhpaYFWq4VWq3V0cy5YeXk5gHMLsOfMmQM/P79eapHzUSgUUCgUDrv/iRMnYvfu3fj888/xt7/9zbq+sLAQ6enp+N3vfoevvvqq19shhIDBYICLi4tDviAKIbBq1SrMnTsXOTk5+OSTT3osSO/4vnYWp7/P/v73v+OTTz7B7bffjhtvvBE7duyw3qZSqTrtX15ejvj4eLvre/IHtdbWVpjNZqjV6h475sXosssuw2233Wb9+95770VLSwu+/vprGAyGM772Ghsb4erqysf4HLS2tuL6669HWVkZNm3ahEmTJtnc/vzzz+Oll15yUOtsKZXKbv/g7+jPI6K+wuHuROfhX//6F+rr6/H+++/bBOgWcXFxNsFEa2sr/vGPfyA2NhYajQZRUVF4/PHHOw3bjIqKwjXXXINNmzZhzJgxcHFxwbBhw7Bp0yYAwNdff41hw4ZBq9Vi9OjR2L9/v83+d955J9zd3ZGdnY0ZM2bAzc0NISEhePbZZyGEsNn23//+NyZMmABfX1+4uLhg9OjR+PLLLzudi2X45CeffIIhQ4ZAo9FgzZo11ts6zkmvq6vD/fffj6ioKGg0GgQEBGD69OnYt2+fzTFXr16N0aNHw8XFBX5+frjttttQVFRk91yKioowe/ZsuLu7w9/fHw899BBMJlMXz4ytt99+29rmkJAQ/OlPf7IZIhwVFWXtZfP39++ROfZlZWVQKpVYsmRJp9uOHz8OmUyGN998EwBQVVWFhx56CMOGDYO7uzs8PT1x5ZVXIiMj46z309XcTHtzc7vzXMtkMjQ0NODjjz+2Dkm19N51NQfwbI+vpZ1Dhw7FkSNHMHXqVLi6uiI0NBT/+te/znqOFlqtFtdffz1WrVpls/7TTz+Ft7c3ZsyYYXe/Y8eOYc6cOfDx8YFWq8WYMWPw3XffWW//6KOPcOONNwIApk6daj1vy/vN8n5cu3at9f24bNky622n927W1NTggQcesL7+w8LCcPvtt6OiosK6zRtvvIEhQ4bA1dUV3t7eGDNmTKfz6srWrVuRm5uLW265Bbfccgu2bNmCwsLCTttZRoZYrhX+/v6YOXOmzXSAM72v9+/fjyuvvBKenp5wd3dHSkqKTUAMAEajEUuWLMGAAQOg1Wrh6+uLSZMmYd26ddZtSktLMX/+fISFhUGj0SA4OBjXXXfdBU0t+P3vf48FCxZg586dNvfV8XW/adMmyGQy5OTk4Mcff7Q+r5bXsRACb731lnW9RU1NDe6//36Eh4dDo9EgLi4OL730kk0PvWU+7b///W+89tpr1mv6kSNHAJz9NQe0v5+2bt2KRYsWwd/fH25ubvjd736HU6dOWbeLiorC4cOHsXnzZmtbz3c+dkcNDQ148MEHrec5cOBA/Pvf/7b5jLj++usxatQom/1mzZoFmUxmcz47d+6ETCbDzz//fF5tseQL6BigWa4Ze/fuRXJyMlxdXfH4449bbzv9McjLy8O1114LNzc3BAQEWKczdHwvd3Sma9GmTZswduxYAMD8+fNtXjsd29ad61lzczOefvppxMXFQaPRIDw8HI888kinz/1169Zh0qRJ8PLygru7OwYOHGg9X4vzuW589dVXyMjIwBNPPNEpQAcAT09PPP/88zbrevqzuaamBnfeeSd0Oh28vLxwxx132J2mc/qcdGf4PLqQazVRjxBEdM5CQ0NFTExMt7e/4447BAAxZ84c8dZbb4nbb79dABCzZ8+22S4yMlIMHDhQBAcHi2eeeUa8+uqrIjQ0VLi7u4uVK1eKiIgI8eKLL4oXX3xR6HQ6ERcXJ0wmk839aLVaMWDAADFv3jzx5ptvimuuuUYAEE899ZTNfYWFhYk//vGP4s033xSvvPKKSExMFADEDz/8YLMdADF48GDh7+8vlixZIt566y2xf/9+621PP/20ddu5c+cKtVotFi1aJN577z3x0ksviVmzZomVK1dat/nwww8FADF27Fjx6quvisWLFwsXFxcRFRUlqqurO53LkCFDxF133SXeeecdccMNNwgA4u233z7rY/70008LACI1NVW88cYb4s9//rNQKBRi7NixoqWlRQghxP/+9z/xu9/9TgAQ77zzjlixYoXIyMg46zGPHz8uTp06ZbN0bPu0adNEfHx8p/2XLFkiFAqFKC0tFUIIsXv3bhEbGysWL14sli1bJp599lkRGhoqdDqdKCoqsu6Xk5MjAIgPP/zQum7y5Mli8uTJne7jjjvuEJGRkTbruvNcr1ixQmg0GpGUlCRWrFghVqxYIbZt2yaEaH/OcnJyzunxtbQzJCREhIeHi7/97W/i7bffFtOmTRMAxE8//dTlY20RGRkprr76avHLL78IACIzM9N624gRI8Q999xjbd/u3buttx06dEjodDoRHx8vXnrpJfHmm2+K5ORkIZPJxNdffy2EECIrK0v89a9/FQDE448/bj1vy/MTGRkp4uLihLe3t1i8eLFYunSp2Lhxo/W2O+64w3p/dXV1YujQoUKhUIi7775bvPPOO+If//iHGDt2rPX9snz5cut1YNmyZeL1118Xf/jDH8Rf//rXsz4OQghx7733itjYWCGEEI2NjcLd3V3861//6rTdnXfeKQCIK6+8Urz22mvi3//+t7juuuvEG2+8Yd2mq/f1oUOHhJubmwgODhb/+Mc/xIsvviiio6OFRqMRO3bssO7/+OOPC5lMJu6++27x7rvviv/85z/i1ltvFS+++KJ1mwkTJgidTieefPJJ8d5774kXXnhBTJ06VWzevPmM52l5bZ06dcru7enp6QKAeOihh6zrOr7uS0tLxYoVK4Sfn58YMWKE9Xk9dOiQWLFihQAgpk+fbl0vhBANDQ1i+PDhwtfXVzz++ONi6dKl4vbbbxcymUz87W9/s96P5b0YHx8vYmJixIsvviheffVVkZeX163XnBDt76eRI0eKadOmiTfeeEM8+OCDQqFQiJtuusm63f/+9z8RFhYmBg0aZG3rL7/8csbHDoD405/+1OXtZrNZTJs2TchkMrFgwQLx5ptvilmzZgkA4v7777du98orrwi5XC70er11P29vbyGXy20e95dfftlmuzO16w9/+IP1epmbmys++eQT4eHhIebNm2ez7eTJk0VQUJDw9/cXf/nLX8SyZcvEN998Y72t43Wvvr5exMTECBcXF7F48WLx2muvicTERJGQkCAAWN+vln3Pdi0qLS0Vzz77rAAgFi5caH3cs7Kyun0MIYQwmUziiiuuEK6uruL+++8Xy5YtE3/+85+FUqkU1113nXW7Q4cOCbVaLcaMGSNef/11sXTpUvHQQw+J5ORk6zbne92YO3euACDy8/PPuJ1FT382m81mkZycLORyufjjH/8o3njjDTFt2jQxfPjwTp9nlve8haM/jy70Wk3UExikE50jvV4vANh80J7Jb7/9JgCIBQsW2Kx/6KGHBACxYcMG67rIyEgBwPphJIQQa9euFQCEi4uLyMvLs65ftmxZpy8hlh8D/vKXv1jXmc1mcfXVVwu1Wm3zpbexsdGmPS0tLWLo0KFi2rRpNusBCLlcLg4fPtzp3E4P0nU63Rm/ILa0tIiAgAAxdOhQ0dTUZF3/ww8/CADi73//e6dzefbZZ22OMXLkSDF69Ogu70MIIcrLy4VarRZXXHGFzY8Yb775pgAgPvjgA+u6swUEHVm2tbcMHDjQup3luTl48KDN/vHx8TaPr8FgsGmfEFIQoNFobM77QoP07j7Xbm5uNoGnxelfis7l8Z08ebIAIP7v//7Puq65uVkEBQWJG264odN9nc4SpLe2toqgoCDxj3/8QwghxJEjRwQAsXnzZrtBekpKihg2bJgwGAzWdWazWUyYMEEMGDDAum716tWd3kcd7xuAWLNmjd3bOj5Wf//73wUAm2Cs4/0KIcR1110nhgwZctZztqelpUX4+vqKJ554wrpu7ty5IiEhwWa7DRs2CAB2v0xa2iFE1+/r2bNnC7VabQ1KhBCiuLhYeHh42AQOCQkJ4uqrr+6yvdXV1QKAePnll7t9jhZne09ajv273/3Ous7e697y2jmdvUD2H//4h3BzcxMnTpywWb948WKhUCisgY7lvejp6SnKy8tttu3ua87yek1NTbV5Th544AGhUChETU2Ndd2QIUPsvs+7crYg/ZtvvhEAxHPPPWezfs6cOUImk1l/BNu9e7dN4HLgwAEBQNx4441i3Lhx1v2uvfZaMXLkyG61y94ye/Zsm8dLiPZrxtKlSzsd5/Tr3n/+8x8BwBrECyFEU1OTGDRokN0gvTvXIsu5d7zenusxVqxYIeRyuUhPT7fZf+nSpQKA2Lp1qxBCiFdfffWsnz/ne90YOXKk0Ol03dq2Nz6bLa+1jj8ktra2iqSkpLMG6UI49vPoQq7VRD2Fw92JzlFtbS0AwMPDo1vb//TTTwCARYsW2ax/8MEHAaDT3PX4+HiMHz/e+ve4ceMAANOmTUNERESn9dnZ2Z3us2N2X8uw1paWFqSlpVnXu7i4WP9fXV0NvV6PpKSkTkPTAWDy5Ml253aezsvLCzt37uwyY+yePXtQXl6OP/7xjzbzD6+++moMGjTI7jz+e++91+bvpKQku+fcUVpaGlpaWnD//ffbJPe6++674enpecH5Ar766iusW7fOZvnwww+tt19//fVQKpX4/PPPresOHTqEI0eO4Oabb7au02g01vaZTCZUVlZahzvaex7O17k8191xro+vu7u7zVxUtVqNxMTEsz6PHSkUCtx000349NNPAUgJ48LDw5GUlNRp26qqKmzYsAE33XQT6urqUFFRgYqKClRWVmLGjBk4efJkpyGcXYmOju5yOH1HX331FRISEvC73/2u022WYZxeXl4oLCzE7t27u3XfHf3888+orKzErbfeal136623IiMjA4cPH7Zph0wm65QsrWM7LE5/X5tMJvzyyy+YPXs2YmJirOuDg4Mxd+5c/Prrr9brn5eXFw4fPoyTJ0/aba+LiwvUajU2bdqE6urqcz7fM7Ekbayrq+uxY65evRpJSUnw9va2vl4qKiqQmpoKk8mELVu22Gx/ww03wN/f3/r3+bzmFi5caPOcJCUlwWQyIS8vr8fO63Q//fQTFAoF/vrXv9qsf/DBByGEsA5bHzlyJNzd3a3nnZ6ebp2+sW/fPjQ2NkIIgV9//dXue9Ce6667znq9/Pbbb/HYY49hzZo1mDt3bqfpWBqNBvPnzz/rMdesWYPQ0FBce+211nVarRZ333233e174lrUnWOsXr0agwcPxqBBg2xeT9OmTQMAbNy4EUB7LpRvv/22U+JDi/O9btTW1nb7e0pvfDb/9NNPUCqVuO+++6zrFAoF/vKXv5zTeZxNb3weXci1mqinMEgnOkeenp4Auv8FMS8vD3K5vFPm8KCgIHh5eXX6QtYxEAcAnU4HADaZjDuuP/0LsFwut/mCDUgJewDYzOH64YcfcPnll0Or1cLHxwf+/v545513oNfrO51DdHT02U4TgDRX/9ChQwgPD0diYiKeeeYZmw8+y7kOHDiw076DBg3q9FhY5tN25O3tfdYv/V3dj1qtRkxMzAV/CU5OTkZqaqrN0vGHFT8/P6SkpOCLL76wrvv888+hVCpx/fXXW9eZzWa8+uqrGDBgADQaDfz8/ODv748DBw7YfR7O17k8191xro9vWFhYpwCxO8/j6ebOnYsjR44gIyMDq1atwi233GK3tm5mZiaEEHjqqafg7+9vs1iCV0vCwLPp7ms/KyvrrDWYH330Ubi7uyMxMREDBgzAn/70J2zdurVbx1+5ciWio6Oh0WiQmZmJzMxMxMbGwtXVFZ988olNO0JCQuDj43PWY55+bqdOnUJjY6Pd9+fgwYNhNptRUFAAAHj22WdRU1ODyy67DMOGDcPDDz+MAwcOWLfXaDR46aWX8PPPPyMwMBDJycn417/+1SNlCuvr6wF0/4fS7jh58iTWrFnT6fViKf13+uvl9MfufF5zp1/rvb29AXS+pvekvLw8hISEdHrsBg8ebL0dkIKp8ePHIz09HYAUpCclJWHSpEkwmUzYsWMHjhw5gqqqqm4H6WFhYdbr5bXXXosXXngBzz33HL7++mv88MMPNtuGhoZ2K0lcXl4eYmNjO10HuqrU0RPXou4c4+TJkzh8+HCn14Lls9jyWrj55psxceJELFiwAIGBgbjlllvwxRdf2ATs53vd8PT0PKfvKUDPfjbn5eUhODi4UyUUe/dxIXrj8+hCrtVEPYVBOtE58vT0REhICA4dOnRO+9kLJuzpKmtpV+tP74HojvT0dFx77bXQarV4++238dNPP2HdunV2ezQA257YM7npppuQnZ2NN954AyEhIXj55ZcxZMiQ804q1J8zuN5yyy04ceKEtdbuF198gZSUFJts1S+88AIWLVqE5ORkrFy5EmvXrsW6deswZMiQLntVLLp6PZ2euOdcn+ve0FOv3XHjxiE2Nhb3338/cnJyMHfuXLvbWR67hx56qNOIB8vS3XJ73X3td8fgwYNx/PhxfPbZZ5g0aRK++uorTJo0yW6vd0e1tbX4/vvvkZOTgwEDBliX+Ph4NDY2YtWqVef1XF7IuSUnJyMrKwsffPABhg4divfeew+jRo3Ce++9Z93m/vvvx4kTJ/DPf/4TWq0WTz31FAYPHtwp4eW5slx7u/scdofZbMb06dO7fL3ccMMNNtuf/tidz2uuJ6/pvWHSpEnYvXs3DAaDNUj38vLC0KFDkZ6ebg3guxuk25OSkgIAnUYq9OT7rqOeeMy7cwyz2Yxhw4Z1+Vr44x//CEA6zy1btiAtLQ3z5s3DgQMHcPPNN2P69OnWa/n5XjcGDRoEvV5v/WGtJ/Xnz+buPH/n+5gT9SSWYCM6D9dccw2WL1+O7du32/Sg2hMZGQmz2YyTJ09aeysAKQt4TU0NIiMje7RtZrMZ2dnZ1l/sAVjroFqyH3/11VfQarVYu3atTSmpjkO2z1dwcDD++Mc/4o9//CPKy8sxatQoPP/887jyyiut53r8+HHrsD+L48eP99hj0fF+Oo4qaGlpQU5OjrV3rDfNnj0b99xzj3XI+4kTJ/DYY4/ZbPPll19i6tSpeP/9923W19TUnLXEm7e3t90hmqf3GpzLc93dH5Ic+fjeeuuteO655zB48OAuaxhb2qRSqc7alu6e89nExsZ264c7Nzc33Hzzzbj55pvR0tKC66+/Hs8//zwee+yxLktQWUpUvfPOO51eF8ePH8eTTz6JrVu3YtKkSYiNjcXatWtRVVXVrd70jvz9/eHq6orjx493uu3YsWOQy+U2I3p8fHwwf/58zJ8/H/X19UhOTsYzzzxjUxYuNjYWDz74IB588EGcPHkSI0aMwH/+8x+sXLnynNrW0YoVKwCgW9MQuis2Nhb19fXn/do9l9fcueip16dFZGQk0tLSUFdXZ9ObfuzYMevtFklJSWhpacGnn36KoqIiazCenJyM9PR0BAYG4rLLLkNgYOB5t6e1tRVA++iIcxUZGYkjR45ACGHzWGVmZp53m3riMY+NjUVGRgZSUlLOejy5XI6UlBSkpKTglVdewQsvvIAnnngCGzdutL6Wzue6MWvWLHz66adYuXJlp8+e0/XGZ3NkZCTWr1+P+vp6m950e9cXexz9eXQ+jzlRT2JPOtF5eOSRR+Dm5oYFCxagrKys0+1ZWVl4/fXXAQBXXXUVAOC1116z2eaVV14BIM356mmWEl+A9Ovwm2++CZVKZe21UCgUkMlkNr2uubm5+Oabb877Pk0mU6fh0wEBAQgJCbGWnBkzZgwCAgKwdOlSmzI0P//8M44ePdpjj0VqairUajX++9//2vw6/v7770Ov1/fKY346Ly8vzJgxA1988QU+++wzqNVqzJ4922YbhULRqQdn9erV3ZovHRsbi2PHjtmUbMrIyOg0JO9cnms3Nze75XFO58jHd8GCBXj66afxn//8p8ttAgICMGXKFCxbtgwlJSWdbu/4mLm5uQFAt877TG644QZkZGTgf//7X6fbLI9RZWWlzXq1Wo34+HgIIWA0Grs89sqVKxETE4N7770Xc+bMsVkeeughuLu7W4e833DDDRBC2C0BeLbeQoVCgSuuuALffvutzdSYsrIyrFq1CpMmTbJO9zn9XNzd3REXF2d9Xzc2NsJgMNhsExsbCw8Pj04lqM7FqlWr8N5772H8+PHW61lPuOmmm7B9+3asXbu20201NTXWYLIr5/KaOxfdfU9211VXXQWTyWTzGQEAr776KmQyGa688krrunHjxkGlUuGll16Cj48PhgwZAkAK3nfs2IHNmzdfUC86AHz//fcAgISEhPPaf8aMGSgqKrIpC2cwGPDuu++ed5t64ppw0003oaioyG47mpqa0NDQAEDKZXA6y4+PlvfJ+V435syZg2HDhuH555/H9u3bO91eV1eHJ554AkDvfDZfddVVaG1txTvvvGNdZzKZ8MYbb3Rrf0d+Hp3vY07Uk9iTTnQeYmNjsWrVKtx8880YPHgwbr/9dgwdOhQtLS3Ytm0bVq9eba3pmZCQgDvuuAPLly9HTU0NJk+ejF27duHjjz/G7NmzMXXq1B5tm1arxZo1a3DHHXdg3Lhx+Pnnn/Hjjz/i8ccft84hu/rqq/HKK69g5syZmDt3LsrLy/HWW28hLi7OZl7puairq0NYWBjmzJmDhIQEuLu7Iy0tDbt377YGVJYvfPPnz8fkyZNx6623oqysDK+//jqioqLwwAMP9Mhj4O/vj8ceewxLlizBzJkzce211+L48eN4++23MXbsWJukMefjyy+/7DTPDgCmT59u06t0880347bbbsPbb7+NGTNmWJMEWVxzzTV49tlnMX/+fEyYMAEHDx7EJ5980imngD133XUXXnnlFcyYMQN/+MMfUF5ejqVLl2LIkCHW5F7AuT3Xo0ePRlpaGl555RWEhIQgOjramqCwo95+fM8kMjKyW7Xs33rrLUyaNAnDhg3D3XffjZiYGJSVlWH79u0oLCy01qIfMWIEFAoFXnrpJej1emg0GkybNg0BAQHn1K6HH34YX375JW688UbcddddGD16NKqqqvDdd99h6dKlSEhIwBVXXIGgoCBMnDgRgYGBOHr0KN58801cffXVXc6vLi4uxsaNGzsl+rLQaDSYMWMGVq9ejf/+97+YOnUq5s2bh//+9784efIkZs6cCbPZjPT0dEydOtUmqaQ9zz33nLVu8x//+EcolUosW7YMzc3NNrWE4+PjMWXKFIwePRo+Pj7Ys2cPvvzyS+vxT5w4gZSUFNx0002Ij4+HUqnE//73P5SVleGWW27p1mNqeZ+1tLSgqKgIa9euxdatW5GQkIDVq1d36xjd9fDDD+O7777DNddcgzvvvBOjR49GQ0MDDh48iC+//BK5ublnHd3S3dfcuRg9ejTeeecdPPfcc4iLi0NAQECnns7T7dmzB88991yn9VOmTMGsWbMwdepUPPHEE8jNzUVCQgJ++eUXfPvtt7j//vsRGxtr3d7V1RWjR4/Gjh07rDXSAaknvaGhAQ0NDecUpJ84ccI6gqKxsRE7duzAxx9/jLi4OMybN6/bx+nonnvuwZtvvolbb70Vf/vb3xAcHIxPPvnE2tN5Pr3isbGx8PLywtKlS+Hh4QE3NzeMGzeu2/kpAGDevHn44osvcO+992Ljxo2YOHEiTCYTjh07hi+++AJr167FmDFj8Oyzz2LLli24+uqrERkZifLycrz99tsICwuz1jY/n+sGIH3efv3110hNTUVycjJuuukmTJw4ESqVCocPH8aqVavg7e2N559/vlc+m2fNmoWJEydi8eLFyM3NRXx8PL7++utu50Jx5OfR+T7mRD2qr9LIE12MTpw4Ie6++24RFRUl1Gq18PDwEBMnThRvvPGGTVkZo9EolixZIqKjo4VKpRLh4eHiscce61R65lxKBllKAXUscXTHHXcINzc3kZWVZa3RGhgYKJ5++ulOpb7ef/99MWDAAKHRaMSgQYPEhx9+aLcMir377nibpQRbc3OzePjhh0VCQoLw8PAQbm5uIiEhwW5N888//1yMHDlSaDQa4ePjI37/+9+LwsJCm20s53I6e23syptvvikGDRokVCqVCAwMFPfdd59NvdeOx7vQEmywU8artrZWuLi4CAA2teItDAaDePDBB0VwcLBwcXEREydOFNu3b+9UZsheCTYhhFi5cqWIiYkRarVajBgxQqxdu9ZuKaruPtfHjh0TycnJ1jZbyt/Yq0srRPce38mTJ9stZWOvnfZ09Z7oyF4JNiGkOui33367CAoKEiqVSoSGhoprrrlGfPnllzbbvfvuuyImJkYoFAqb5/FM9316CTYhhKisrBR//vOfRWhoqFCr1SIsLEzccccdoqKiQgghleZLTk4Wvr6+QqPRiNjYWPHwww+fsca0pcTU+vXru9zmo48+EgDEt99+K4SQyhy9/PLLYtCgQUKtVgt/f39x5ZVXir1791r3OdP7et++fWLGjBnC3d1duLq6iqlTp9qUhRRCiOeee04kJiYKLy8v4eLiIgYNGiSef/55a03iiooK8ac//UkMGjRIuLm5CZ1OJ8aNGye++OKLLs/D4vT3mVarFWFhYeKaa64RH3zwQafrphAXXoJNCKnW/WOPPSbi4uKEWq0Wfn5+YsKECeLf//639bzsXXc76s5rrqvX68aNGztdR0pLS8XVV18tPDw8BICzlmM70/XJUr6wrq5OPPDAAyIkJESoVCoxYMAA8fLLL9uUg7N4+OGHBQDx0ksv2ayPi4sTAGxK9Z1LuxQKhQgLCxMLFy4UZWVlNtt2dc2w3Hb6Y5CdnS2uvvpq4eLiIvz9/cWDDz4ovvrqKwFA7Nix46zHtffa+fbbb0V8fLxQKpU2195zOUZLS4t46aWXxJAhQ4RGoxHe3t5i9OjRYsmSJdb3/Pr168V1110nQkJChFqtFiEhIeLWW2+1KQV4PteNjqqrq8Xf//53MWzYMOHq6iq0Wq0YOnSoeOyxx0RJSYnNtj392VxZWSnmzZsnPD09hU6nE/PmzRP79+/vVgk2R34eXehjTtQTZEI4SYYSIrpgd955J7788svznt9HRETU37322mt44IEHUFhYiNDQUEc3h4jonHFOOhERERH1S01NTTZ/GwwGLFu2DAMGDGCATkT9FuekExEREVG/dP311yMiIgIjRoyAXq/HypUrcezYMWsyRSKi/ohBOhERERH1SzNmzMB7772HTz75BCaTCfHx8fjss89w8803O7ppRETnjXPSiYiIiIiIiJwE56QTEREREREROQkG6URERERERERO4pKbk242m1FcXAwPDw/IZDJHN4eIiIiIiIguckII1NXVISQkBHL5mfvKL7kgvbi4GOHh4Y5uBhEREREREV1iCgoKEBYWdsZtLrkg3cPDA4D04Hh6ejq4NWdmNBrxyy+/4IorroBKpXJ0c4joIsNrDBH1Nl5niKi39ZfrTG1tLcLDw63x6JlcckG6ZYi7p6dnvwjSXV1d4enp6dQvOCLqn3iNIaLexusMEfW2/nad6c6UayaOIyIiIiIiInISDNKJiIiIiIiInASDdCIiIiIiIiInwSCdiIiIiIiIyEkwSCciIiIiIiJyEgzSiYiIiIiIiJwEg3QiIiIiIiIiJ8EgnYiIiIiIiMhJMEgnIiIiIiIichIM0omIiIiIiIicBIN0IiIiIiIiIifBIJ2IiIiIiIjISTBIJyIiIiIiInISDNKJiIiIiIiInASDdCIiIiIiIiInwSCdiIiIiIiIyEkwSCciIiIiIiJyEgzSiYiIiIiIiJwEg3QiIiIiIiIiJ8EgnYiIiIiIiMhJMEgnIiIioh5nMgvszKnC3goZduZUwWQWjm4SEVG/oHR0A4iIiIjo4rLmUAmWfH8EJXoDAAX+7+QeBOu0eHpWPGYODXZ084iInBp70omIiIiox6w5VIL7Vu5rC9DbleoNuG/lPqw5VOKglhER9Q8M0omIiIioR5jMAku+PwJ7A9st65Z8f4RD34mIzoDD3YmIiIioR+zKqerUg96RAFCiN+DGpdswNFSHUC8XhHi5INTbBaFeLvB310Aul/Vdg4mInBCDdCIiIiK6YEIIbDpR3q1t9+XXYF9+Taf1KoUMwTopYA/1lgL4sA6BfLBOC61K0cMtJyJyLgzSiYiIiOi8tbSa8X1GMZZvycbxsrpu7XPXxChoVQoU1TShuKYJRdVNKK01wGgSyK9qRH5VY5f7+rlrEOqllYJ4XXswH9q2eLmqIJOxN56I+i8G6URERER0zuoMRny6Kx8f/JqL0lppiLuLSg65TIaGFpPdfWQAgnRaPHF1PBSnDWtvNZlRWmtAUXUTivVS4F5UY7AJ5JuMJlTUN6OivhkZhXq79+GqVnQaRt/x70APDZQKpmUiIufFIJ2IiIiIuq1Ub8CHW3Owamc+6ppbAQD+HhrcOSEKt42LxPbsCty3ch8A2CSQs4TkT8/qHKADgFIhR5i3K8K8Xe3erxACNY1GFNU0SUt1W/Be0/5vRX0LGltMOFlej5Pl9XaPo5DLEOSpRYiX1iZ47zi03k3Dr8hE5Di8AhERERHRWR0vrcPyLdn4LqMIRpMUfsf6u2FhcgxmjwyFRinNFZ85NBjv3DaqQ510SdAF1kmXyWTwdlPD202NoaE6u9sYjCbbwN3aG9+I4hoDSvRNMJqENdDfjWq7x/FyVbUH8F62c+RDvVzg567mkHoi6jUM0omIiIjILiEEdmRXYfmWLGw8fsq6fmyUN+5JjsW0QQF2s7HPHBqM6fFB2J5Zjl/Sd+KKpHEYHxdgtwe9J2lVCsT4uyPG393u7SazQEV9MwpP74WvbrIG7nWGVtQ0GlHTaMTh4lq7x1Er5W1BvNZuMB+sc4FaySH1RHR+GKQTERERkY1WkxlrDpdi+ZZsHGib+y2TATPig7BwcgxGRXif9RgKuQzjon1QeVRgXLRPrwfo3aGQyxDoqUWgpxajI+2fQ63BiOIOwXthTROKawwoqpZ648vqDGhpNSOnogE5FQ12jyGTAf7ums4Z6jsMr/fUKtkbT0R2MUgnIiIiIgBAU4sJq/cW4N30bBRUNQEANEo55owOw4KkGET7uTm4hb3PU6uCZ5AKg4I87d7e0mpGWa2hc298h7nyza1mlNc1o7yuGfvtlJoDAHeNsr03vsNQ+rC2/wd4aJ3ihw0i6nsOD9LfeustvPzyyygtLUVCQgLeeOMNJCYm2t3WaDTin//8Jz7++GMUFRVh4MCBeOmllzBz5sw+bjURERHRxaOyvhkfb8/Diu25qG40AgC8XVWYNz4Kt4+PhJ+7xsEtdB5qpRzhPq4I9+k6wV1VQ4s1YC86LZAvrjGgqqEF9c2tOF5W12XZOqVchiCd1u6ceMu/LmrWjCe6GDk0SP/888+xaNEiLF26FOPGjcNrr72GGTNm4Pjx4wgICOi0/ZNPPomVK1fi3XffxaBBg7B27Vr87ne/w7Zt2zBy5EgHnAERERFR/5Vb0YB307Px5d5CNLeaAQDhPi5YMCkGN44Jg6va4f05/Y5MJoOvuwa+7hoMD/Oyu01jS6s0hL7DsPriGsvQ+iaU6g1oNQsUVjehsLqpy/vycVN3mBvv2lZyTvp/iJcWPm5McEfUHzn0yvvKK6/g7rvvxvz58wEAS5cuxY8//ogPPvgAixcv7rT9ihUr8MQTT+Cqq64CANx3331IS0vDf/7zH6xcubJP205ERETUX+3Pr8ayzdlYe6QUoq1O2vAwHRYmx2DmkCDWEe9lrmol4gLcERfQdYK78jpD55746vYh9Q0tJlQ1tKCqoQUHi+zXjNeq5LZJ7U6rHx+k00LF55rI6TgsSG9pacHevXvx2GOPWdfJ5XKkpqZi+/btdvdpbm6GVqu1Wefi4oJff/21y/tpbm5Gc3Oz9e/aWilLp9FohNFovJBT6HWW9jl7O4mof+I1hujSYjYLbDxxCu/9mos9eTXW9ZMv88Pdk6KQGOUNmUwGYTbBaDb1yH3yOnP+/FyV8HP1QEKoR6fbhBCoNUi98cU1TSjWS73yJXoDimoMKNEbUF7XDIPRjOxTDcg+1XWCuwAPDUK9XBCs0yLUS4sQLxeEtP0/WOcCDy1HU5Bz6y/XmXNpn0wIy++nfau4uBihoaHYtm0bxo8fb13/yCOPYPPmzdi5c2enfebOnYuMjAx88803iI2Nxfr163HdddfBZDLZBOIdPfPMM1iyZEmn9atWrYKrq/25REREREQXi1YzsPuUDBtL5ChrkoY+K2QCo/0EpoaYEcKvQxelVjNQ0wJUNctQ3QxUNQPVzTJUd1hnEmcfCu+iEPDWAD4aAW814K3p8LcG8FABzG9HdHaNjY2YO3cu9Ho9PD3tJ6a06Fc/jb3++uu4++67MWjQIMhkMsTGxmL+/Pn44IMPutznsccew6JFi6x/19bWIjw8HFdcccVZHxxHMxqNWLduHaZPnw6VSuXo5hDRRYbXGKKLW22TEZ/uLsTH2/Nwqr4FgJRR/JaxYbhjfASCPLVnOcKF43XGeZnNApUNLSjWd+yNN6CkpsnaG1/TZESTSYamRqC40X4krlLIEORp2wsfYp0nr0WwpxYaFRPcUe/pL9cZy4ju7nBYkO7n5weFQoGysjKb9WVlZQgKCrK7j7+/P7755hsYDAZUVlYiJCQEixcvRkxMTJf3o9FooNF0zkiqUqmc+knsqD+1lYj6H15jiC4uRTVN+ODXHHy2Kx8NLdKw9SBPLe6aFIVbEiPgqe379zuvM84pRKNGiI/9efEAUN/cipIOCe2Kqm2z1Jfom2A0CRRUN6GguglAtd3j+LlrpIR23i4I0dlmqg/1coGXq4oJ7uiCOft15lza5rAgXa1WY/To0Vi/fj1mz54NADCbzVi/fj3+/Oc/n3FfrVaL0NBQGI1GfPXVV7jpppv6oMVEREREzutIcS2Wb8nC9wdKYDJLsxkHBnrg7uQYXJsQArWSCcLo3LhrlBgQ6IEBgZ3nxQNAq8mM0lpDW6b6RhTX2NaPL6puQpPRhIr6ZlTUNyOj0H6CO1e1olNSu45/B3pomMyQLikOHe6+aNEi3HHHHRgzZgwSExPx2muvoaGhwZrt/fbbb0doaCj++c9/AgB27tyJoqIijBgxAkVFRXjmmWdgNpvxyCOPOPI0iIiIiBxCCIGtmZVYtiUL6ScrrOvHx/hi4eQYTLnMnz2U1GuUCjnCvF0R5u0KwKfT7UII1DQaO2WoL9a3Z6qvqG9BY4sJJ8vrcbK83u79KOTSkHppCH178B7i5YKwtr/dNP1qFi/RGTn01XzzzTfj1KlT+Pvf/47S0lKMGDECa9asQWBgIAAgPz8fcnn7r2YGgwFPPvkksrOz4e7ujquuugorVqyAl5eXg86AiIiIqO8ZTWb8dLAEyzZn40iJNM9RLgOuGhaMhckxXdbnJupLMpkM3m5qeLupMTRUZ3cbg9EkzYlv640vqjHYDKu3DKm3BPq7uxhS7+Wqag/gLUuHYfV+7qwZT/2Hw39y+vOf/9zl8PZNmzbZ/D158mQcOXKkD1pFRERE5Hwamlvx2e4CfPBrDopqmgAALioFbhoThj9MikGEL1O1U/+iVSkQ4++OGH/7c+PNZoFT9c3W4fPFHXrlLUPraw2tqGk0oqbRiMPF9pNzqZXytiBeazeYD9a5cEoIOQ2HB+lEREREdGbldQZ8tDUXK3fkodbQCgDwdVPjjglRmHd5JLzd1A5uIVHvkMtlCPTUItBTi1ER3na3qTMY23viq6Xs9B2H15fVGdDSakZORQNyKrquGe/vruk0jL7j8HpPrZK98dQnGKQTEREROanM8nq8l56Nr/cVocVkBgBE+7lhQVI0bhgVBi1LWxHBQ6vCwCAVBgbZT3BnNJlRqjd06o3vOFfeYDSjvK4Z5XXN2J9fY/c47hple2+8d+fe+AAPLRQsGk89gEE6ERERkZPZk1uFpZuzkXa0vVTtyAgv3JMci+nxgQwEiM6BSiFHuI8rwn3sTwcRQqCqoeW0YfTtGeuLappQ1dCC+uZWHC+rw/GyOrvHUcplCNJp7c6Jt/zrouYPa3R2DNKJiIiInIDJLLDuSBmWb8nCvg49eamDA3HP5BiMifTmUFuiXiCTyeDrroGvu6bLpItNLab2IfQdhtJbeuNL9Qa0mgUKq6Ugvys+buoOc+NdEeKlRZi3i/X/Pm5McEcM0omIiIgcymA04at9hXgvPcc6X1atkOP6UaFYkBSDuAD7CbWIqO+4qBWIC3Dv8v1oMguU1xk69cQXWf/fhPrmVlQ1tKCqoQUHi+zXjNeq5LbD6E+rHx+k00LFmvEXPQbpRERERA5Q3dCCFTvy8PG2XFQ2tAAAPLVK3HZ5JO6cEIUAT62DW0hE3aWQyxCsk7LEj47sfLsQArWG1s4Z6jv0ypfXNcNgNCP7VAOyT3Wd4C7Q4/Q58dq2IF7qjffQqnr5bKm3MUgnIiIi6kMFVY14Lz0bX+wpRJPRBAAI9XLBXZOicfPYcLhr+PWM6GIjk8mgc1FB56JCfIin3W2aW002Ce5sh9dL61tazSitNaC01oC9efZrxntqlVKG+tPnxLf1xvu7ayBnXgunxk8BIiIioj5wsFCPZVuy8NPBEpiFtC4+2BP3TI7BVcOCOYSV6BKnUSoQ6euGSF83u7ebzQKVHRLcdZwTbwnmaxqNqDW0ora0DsdK7Se4UymkXv+OwXtYh/8H67SsHOFgDNKJiIiIeokQAptOnMLyzdnYnl1pXZ80wA8Lk2MwKc6PSaKIqFvkchn8PTTw99BgRLiX3W0amlttSsxZgnlLT3xprQFGk0B+VSPyqxq7vC8/d411GH2IzqVTyTkvVxWvXb2IQToRERFRD2tpNeP7jGIs35JtLdekkMswa3gw7k6OwZAQnYNbSEQXIzeNEgMCPTAg0H7N+FaTGWV1zZ3rxXf4u7HFhIr6ZlTUNyOj0H6CO1e1wmYofZi3bc98oIcGyj4YHWQyC+zMqcLeChl8c6owPi7goihRySCdiIiIqIfUGYz4dFc+Pvg1F6W1BgCAm1qBWxIjcNekaIR6uTi4hUR0KVMq5NbecHuEENA3Gdsy1NsOpZeG1xtQUd+MxhYTMsvrkVleb/c4CrkMQZ7atlJz7cF7iFf70Hq3C8y/seZQCZZ8fwQlegMABf7v5B4E67R4elY8Zg4NvqBjOxqDdCIiIqILVKo34MOtOVi1Mx91za0AAH8PDeZPjMLvEyOhc2W2ZSJyfjKZDF6uani5qjE01P6IH4PRhBK9wdr73jFDfbFe+r/RJKy99LthP8Gdl6vKOpTeWnKuw7B6P/eua8avOVSC+1bugzhtfanegPtW7sM7t43q14E6g3QiIiKi83SirA7Lt2Tj29+KYDRJXxdj/d2wMDkGs0eGQqNk8iUiurhoVQpE+7kh2q/rBHcV9c22wbt1aL0BRdWNqDW0oqbRiJpGI46U1No9jlopb+uF79Ab7+WCYE8tnvrmcKcAHQAEABmAJd8fwfT4oH479J1BOhEREdE5EEJgR3YVlm/Jwsbjp6zrE6N8sDA5BtMGBbC8ERFdsuRyGQI8tQjw1GJUhLfdbeoMxrZkdo1tgbvt8PqyWgNaWs3IqWhAToX9mvFdEQBK9AbsyqnC+FjfHjijvscgnYiIiKgbWk1mrDlciuVbsnGgLZmSTAbMiA/CwskxXX4ZJSIiWx5aFQYGqTAwyH6CO6PJbK0Z33EofWF1E46X1qG8rvms91FeZ+jpZvcZBulEREREZ9DUYsLqvQV4Nz0bBVVNAACNUo45o8OwICmmyyGfRER0flQKOcJ9XBHu49rptu1Zlbj13R1nPUaAh7Y3mtYnGKQTERER2VFZ34yPt+dhxfZcVDcaAQDerirMGx+F28dHws9d4+AWEhFdehKjfRCs06JUb7A7L10GIEinRWK0T183rccwSCciIiLqILeiAe+mZ+PLvYVobjUDACJ8XLEgKRpzRofBVc2vT0REjqKQy/D0rHjct3IfZIBNoG7JBvL0rPh+mzQOYJBOREREBADYn1+N5VuyseZwKUTbt77hYTosTI7BzCFBUCrkjm0gEREBAGYODcY7t43qUCddEsQ66URERET9m9kssOFYOZZvycau3Crr+qkD/bEwORaXx/h0WaeXiIgcZ+bQYEyPD8L2zHL8kr4TVySNw/i4gH7dg27BIJ2IiIguOc2tJny7vxjL07ORWV4PAFApZLg2IRQLk2O6zDhMRETOQyGXYVy0DyqPCoyL9rkoAnSAQToRERFdQvRNRnyyMw8fbc21lvDx0Cgxd1wE5k+MRpCu/2YDJiKiiwODdCIiIrroFdU04YNfc/DZrnw0tJgAAEGeWtw1KQq3JEbAU6tycAuJiIgkDNKJiIjoonWkuBbLt2ThhwMlaDVL2eAGBnpgYXIMZiWEQK1kMjgiInIuDNKJiIjooiKEwNbMSizbkoX0kxXW9eNjfLFwcgymXObPZHBEROS0GKQTERHRRaHVZMaPB0uwbHM2jpTUAgDkMuCqYcFYmByD4WFejm0gERFRNzBIJyIion6tobkVn+0uwAe/5qCopgkA4KJS4Oax4fjDpGiE+7g6uIVERETdxyCdiIiI+qXyOgM+3paLlTvyoW8yAgB83dS4Y0IU5l0eCW83tYNbSEREdO4YpBMREVG/kllej/fSs/H1viK0mMwAgGg/NyxIisYNo8KgVSkc3EIiIqLzxyCdiIiI+oU9uVVYujkbaUfLrOtGRXhhYXIspscHQiFnMjgiIur/GKQTERGR0zKZBdYdKcPyLVnYl19jXZ86OBD3To7BmCgfxzWOiIioFzBIJyIiIqdjMJrw1b5CvJeeg5yKBgCAWiHH9aNCsSApBnEB7g5uIRERUe9gkE5EREROo7qhBSt25OHjbbmobGgBAHhqlZg3PhJ3TIhCgIfWwS0kIiLqXQzSiYiIyOEKqhrx/q85+Hx3AZqMJgBAqJcL7poUjZvHhsNdw68sRER0aeAnHhERETnMwUI9lm3Jwk8HS2AW0rr4YE/cMzkGVw0Lhkohd2wDiYiI+hiDdCdlMpuwp2wPMloyEFAWgMSQRCjkLClDRET9nxACm0+cwrLN2dieXWldnzTAD/ckx2JinC9kMmZqJyKiSxODdCeUlpeGF3e9iLJGqcTM6vWrEegaiMWJi5Eamerg1hEREZ2fllYzvs8oxrvp2ThWWgcAUMhlmDU8GHcnx2BIiM7BLSQiInI8BulOJi0vDYs2LYKAsFlf3liORZsW4ZUprzBQJyKifqXOYMSnu/Lxwa+5KK01AADc1ArckhiBuyZFI9TLxcEtJCIich4M0p2IyWzCi7te7BSgA4CAgAwyvLTrJUwNn8qh70RE5PRK9QZ8uDUHq3bmo665FQDg76HB/IlR+H1iJHSuKge3kIiIyPkwSHci+8r3WYe42yMgUNpYin3l+zA2aGwftoyIiKj7TpTVYfmWbHz7WxGMJumH51h/NyxMjsHskaHQKPlDMxERUVcYpDuRU42nurXdvrJ9GBM4hkl1iIjIaQghsCO7Csu3ZGHj8fbPs8QoHyxMjsG0QQGQy/m5RUREdDYM0p2Iv6t/t7Z787c3sfrEaqRGpiI1IhUjA0Zy+DsRETlEq8mMNYdL8e6WbGQU6gEAMhkwc0gQFibHYGSEt4NbSERE1L8wSHciowJGIdA1EOWN5XbnpQOAVqGFDDKUNZbhk6Of4JOjn8BH64NpEdOQGpGKxKBEqBSc40dERL2rqcWE1XsL8F56DvKrGgEAGqUcc0aHYUFSDKL93BzcQiIiov6JQboTUcgVWJy4GIs2LYIMMptAXQZpiOA/k/6JpLAkbC/ejrS8NGws2IgqQxW+PPElvjzxJTzUHpgSNgWpkamYEDIBWqXWUadDREQXocr6Zny8PQ8rtueiutEIAPB2VWHe+CjcPj4Sfu4aB7eQiIiof2OQ7mRSI1PxypRXbOqkA0CgayAeTXzUWn5tSvgUTAmfAqPZiD2le5CWl4b1+etRaajE99nf4/vs7+GidEFSaBKmR05HUlgS3FTs1SAiovOTW9GAd9Oz8eXeQjS3mgEAET6uWJAUjTmjw+Cq5lcKIiKinsBPVCeUGpmKqeFTsat4F9ZtX4fp46cjMSTR7rxzlVyF8SHjMT5kPB4f9zgyTmVgXd46rM9fj5KGEvyS9wt+yfsFarkaE0ImICUyBVPDp0Kn0TngzIiIqL/Zn1+N5VuyseZwKUTbAK/hYTosTI7BzCFBUCrkjm0gERHRRYZButOSw9QYg9baETA1xgA4+5cghVyBUYGjMCpwFB4Z+wiOVB5BWn4a0vLSkFubi02Fm7CpcBMUMgXGBo3F9MjpmBYxDX4ufr1/OkRE1G+YzQIbjpVj+ZZs7Mqtsq6fOtAfC5NjcXmMDyuMEBER9RIG6U5ozaESLPn+CEr0BgAK/N/JPQjWafH0rHjMHBrcrWPIZDIM8RuCIX5D8NeRf0VWTRbW5a9DWl4aTlSfwI6SHdhRsgPP7XgOIwNGIiUiBamRqQhxD+ndkyMiIqfV3GrCt/uLsTw9G5nl9QAAlUKG60aEYmFyDC4L9HBwC4mIiC5+DNKdzJpDJbhv5b5Oud1L9Qbct3If3rltVLcDdQuZTIY47zjEecfhvoT7kF+bj7T8NKzPW48DFQewr3wf9pXvw8t7Xka8bzymR05HakQqonRRPXZeRETkvPRNRnyyMw8fbc1FeV0zAMBDo8TccRGYPzEaQTomISUiIuorDNKdiMkssOT7I3aLrwkAMgBLvj+C6fFBUMjPf5hhhGcE7hp6F+4aehdKG0qxPn890vLSsK98H45UHsGRyiN4fd/riPOKs9Ziv8z7Mg5tJCK6yBTVNOGDX3Pw2a58NLSYAABBnlrcNSkKtyZGwEPLkp5ERER9jUG6E9mVU9U2xN0+AaBEb8CunCqMj/XtkfsMcgvC7wf/Hr8f/HtUNlViY8FGpOWlYWfJTmTWZCKzJhNLM5Yi3CMcqRGpSI1MxVC/oZDLmCiIiKi/OlJci3fTs/F9RjFazdJPwwMDPbAwOQazEkKgVvIaT0RE5CgM0p1IeV3XAXpH72zKRGltE4aHeSHa1w3yC+hV78jXxRdzLpuDOZfNQW1LLTYXbEZaXhq2Fm9FQV0BPjz8IT48/CECXAOsAfuogFF2s84TEZFzEUJga2Yllm3JQvrJCuv68TG+WDg5BlMu8+eIKSIiIifAIN2JBHh0b87flpMV2NL2BctDq8SwUB2Gh3khIUyH4eFeCNFpL/iLlqfaE7NiZ2FW7Cw0Ghvxa9GvSMtLw+bCzShvLMeqY6uw6tgq+Gh9MDV8KlIjUzEuaBxUCg6NJCJyJq0mM348WIJlm7NxpKQWACCXAVcNC8Y9ybEYFsaSnERERM6EQboTSYz2QbBOi1K9we68dADwclHhupEhOFRUi8PFetQZWrEtqxLbsiqt2/i5qzE8zAvDw3RIaPvX111z3u1yVbniiqgrcEXUFWg2NWNH8Q6k5adhY8FGVBmq8NXJr/DVya/gofLA5PDJSI1MxYSQCXBRupz3fRIR0YVpaG7FZ7sL8MGvOSiqaQIAuKgUuHlsOP4wKRrhPq4ObiERERHZwyDdiSjkMjw9Kx73rdwHGWATqFv6xV+8YZg1u3uryYwTZfU4UFiDjEI9MgpqcLysDhX1LdhwrBwbjpVb9w/zdrEG7MPDvDAsTAd3zbk//RqFBpPDJ2Ny+GQYzUbsLduLtLw0rM9fj4qmCvyQ/QN+yP4BLkoXTAqdhNSIVCSHJcNd7X7+DwwREXVbeZ0BH2/Lxcod+dA3GQEAvm5q3DkhCrddHglvN7WDW0hERERnwiDdycwcGox3bhvVoU66JMhOnXSlQo74EE/Eh3jilkRpncFowuHiWhworMGBQj0yCmuQfaoBhdVNKKxuwo8HSwAAMhkQ6+9u09s+ONgTWlX355er5CpcHnw5Lg++HI+PexwZpzKwLm8d1uetR3FDMdblrcO6vHVQyVUYHzIeqRGpmBo+FV5arx55rIiIqF3WqXq8uyUbX+8rQovJDACI9nPDgqRo3DAq7Jyu70REROQ4DNKd0MyhwZgeH4TtmeX4JX0nrkgah/FxAd0qu6ZVKTA60hujI72t62oNRhwq1COjUG8N3otqmpBZXo/M8np8va8IAKBSyDAwyAMJYV5S4B6uQ5y/O5SKs2f5lcvkGBkwEiMDRuLhMQ/jSNURrM9bj3V565Bbm4sthVuwpXALFDIFxgSNQWpEKlIiUuDv6n/+DxQREWFPbhWWbs5G2tEy67pREV5YmByL6fGBF1Syk4iIiPoeg3QnpZDLMC7aB5VHBcZF+1zQlyxPrQoT4vwwIc7Puu5UXTMOFtUgo0DqbT9QqEdVQwsOFdXiUFEtPtmZD0Cavzg01NNmjnukr+sZE9PJZDIM8R2CIb5D8JeRf0G2PlvqYc9fj2NVx7CzZCd2luzECztfwIiAEUiJSEFqZCpC3UPP+xyJiC4lJrPAuiNlWL4lC/vya6zrUwcH4t7JMRgT5eO4xhEREdEFYZB+ifL30GDaoEBMGxQIQCrNU1jdhANtve0ZhTU4VFSL+uZW7M6txu7cauu+OhdV29x2S1Z5LwTp7Geml8lkiPWKRaxXLO5NuBcFtQVYn78e6/LX4cCpA9hfvh/7y/fj33v+jcE+gzE9cjpSIlMQo4vpk8eBiKg/MRhN+GpfId5Lz0FORQMAQK2Q4/pRoViQFIO4AOb/ICIi6u8YpBMAKZgO93FFuI8rrh4uzXs3mwWyK+qRUaC3Jqc7UlILfZMR6ScrbOrsBnhoMDzMCyPCddZedy/XzsmJwj3DcefQO3Hn0DtR2lCKDfkbkJafhr1le3G06iiOVh3Ff/f/F7G6WKREpmB65HQM9B7I2r1EdEmrbmjBih15+HhbLiobWgAAnlol5o2PxB0TorpdwpOIiIicH4N06pJcLkNcgAfiAjxww+gwAEBLqxnHS+vahshLw+RPlNWhvK4ZaUfLbOZERvq6ttdvD/PC0FBPuKrbX3JBbkGYO3gu5g6eiypDFTbmb0Rafhp2lOxAlj4LWQeysPzAcoS5hyE1MhWpkakY5jcMctnZ58gTEV0MCqoa8f6vOfh8dwGajCYAQKiXC+6aFI2bx4afV5UOIiIicm78dKdzolbKMSxMh2FhOgCRAIDGllYcLq5FRkGNdbh8bmUj8tqW7zOKAQByGTAgwEMaJh8uBe+DgjyhVsrho/XBDZfdgBsuuwG1LbXYUrgFaXlp2Fq0FYX1hfjo8Ef46PBHCHANkOawR6RiVOAoKOV8CRPRxedgoR7LtmThp4MlMLfV44wP9sQ9k2Nw1bBgqLqR0JOIiIj6J0Y4dMFc1UqMjfLB2A6JivSNRhwoaisD1xa8l9YacLysDsfL6rB6byEAaS7l4BBPa297QpgOMf4euCbmGlwTcw0ajY3YWrwV6/LWYUvhFpQ3luPTY5/i02OfwlvjjakRU5EakYrLgy+HSqFy1ENARHTBhBDYfOIUlm3OxvbsSuv6pAF+uCc5FhPjfDn1h4iI6BLAIJ16hc5VhaQB/kga0F5irazWYA3YLRnl9U1GZBTUIKOgBkAeAMBNrcDQUB0Swi0Z5SciNSkVRrMRO0p2IC0vDRsLNqK6uRpfn/waX5/8Gu4qd0wOn4zpEdMxIXQCXJQujjlxIqJz1NJqxvcZxXg3PRvHSusASBU+Zg0Pxt3JMRgSonNwC4mIiKgvMUinPhPoqcUVQ4JwxZAgAFKvUX5Vo1S/vS14P1SsR0OLCTtzqrAzp8q6r4+bGsNCdUgIC0Ry2J9w39BHkNd4CGl5adiQvwGnmk7hx+wf8WP2j3BRumBS6CSkRKRgcthkuKuZ7ZiInE+dwYhPd+Xjg19zUVprACD9SHlLYgTumhSNUC/+2EhERHQpYpBODiOTyRDp64ZIXzdcmxACQKr9m1leb5OY7mhJLaoaWrD5xClsPnHKun+ITovhYVfihrCb4KErRkHzTqQXb0RRfRHW5a3Durx1UMlVuDz4ckyPnI4p4VPgrfV21OkSEQGQRhV9sDUHq3bko665FYBUFnP+xCj8PjESOldO3SEiIrqUMUgnp6KQyzAwyAMDgzxw05hwAEBzqwlHS+qkMnBt5eAyT9WjWG9Asb4Uaw6Xtu09FNF+iRgbUgOZ2yEUtOxASWM+0ovSkV6UDoVMgTGBY5ASmYKUiBQEuAY47kSJ6JJzoqwOy7dk49vfimA0SdngYv3dcE9yLK4bGQKNUuHgFhIREZEzYJBOTk+jVGBEuBdGhHsB46V19c2tOFTUXr/9QGENCqqakFPRiJwKNYBRAEZBqS1HYNBJwO0gas252Fm6EztLd+KFnS9ghP8IpEamIiUiBWEeYQ48QyK6WAkhsCO7Csu3ZGHj8faRQIlRPliYHINpgwIglzMZHBEREbVjkE79krtGictjfHF5jK91XVVDi3WI/IHCGvxWoEdFfQCKcgMATIRMVQmlx2GoPQ9D7pKH3079ht9O/YZ/7/k3BvkMwvTI6UiNSEWMV4zjToyILgqtJjPWHC7Fu1uykVGoBwDIZMDMIUFYmByDkRGcekNERET2MUini4aPmxpTBgZgykBpGLsQAiV6Q4fedl8cKAxEXVUyZEo9lB5HoPQ4CIVrDo5VHcOxqmN4Y/8bCNBGYFpECn43YCYG+w5mySMi6ramFhNW7y3Ae+k5yK9qBABolHLMGR2GBUkxiPZzc3ALiYiIyNkxSKeLlkwmQ4iXC0K8XDBzaDAAwGwWyK1saCsDl4ADhVfhcE4xTNpDUHoegsItE+WGfHx24kN8duJDaIQfBnhMQGpEKq4ddDn8PZhtmYg6q6xvxsfb87Biey6qG40AAG9XFeaNj8Lt4yPh565xcAuJiIiov2CQTpcUuVyGGH93xPi7Y/bIUADSsNQTZVfgQGEN9hSUYHfZVpSbd0PhdhzN8gocqv8Oh458h1cyPKFtScBAjwlICk/EiHBfDAvTwV3DtxHRpSq3ogHv/ZqN1XsK0dxqBgBE+LhiQVI0bhwdDhc1k8ERERH1FpPZhD1le5DRkoGAsgAkhiRCIe//n72MLuiSp1TIER/iifgQT9ySGAFgHAxGE/YVlOOHkxuwu3wzylr3Q66qRYsqHQfN6cjIckVrRjxMdUMR6ZqAhDA/JIR5YXiYDoODPaFV9f+LAxF1bX9+NZZvycaaw6UQUqJ2DA/T4Z7kWMwcGgQFk8ERERH1qrS8NLy460WUNZYBAFavX41A10AsTlyM1MhUB7fuwjBIJ7JDq1JgQkwwJsT8HsDv0WJqwYa8rfjm+BrsrUiHQVkHtdcewGsPykwa/FQ6GN+dHILW+oFQyTUYGOSB4WFeSAjTYXiYFwYEuEOpkDv6tIjoApjNAhuOlWP5lmzsyq2yrp860B8Lk2NxeYwPc1gQERH1gbS8NCzatAgCwmZ9eWM5Fm1ahFemvNKvA3UG6UTdoFaoMTNmKmbGTEWruRX7yvZhXd46rMtbj0rDKah0v0Gl+w0wq2CsvwzH6obi0O7BWLVTCwBwUSkwNNQTw9t62xPCvBDp68ov9ET9QHOrCd/uL8by9GxkltcDAFQKGa4bEYqFyTG4LNDDwS0kIiLq/8zCDKPZCKPJiBZzi82/RrMRLaYWtJhb0GxqxpLtSzoF6AAgICCDDC/teglTw6f226HvDNKJzpFSrkRicCISgxPx2LjHcODUAazPX491eetQVF8EledhqDwPQw4FXE2DUVc1GA3VA7E714TdudXW4+hcVBgepmtbvJAQ5oUgndaBZ0ZEHembjPhkZx4+2pqL8rpmAICHRom5l0dg/oRovl+JiKjfEUKgVbR2CnytAbElSDa12N7ett7uPqevN7fvf3rA3WJqQau5tf34beuMZiNaza09c44QKG0sxb7yfRgbNLZHjtnXGKQTXQC5TI4RASMwImAEFo1ehOPVx7Eubx3S8tKQrc9GveIQZP6H4OkvR4TbMOjMI1FTMRAnihXQNxmRfrIC6ScrrMcL8NBgeJgXRoTrrL3uXq5qB54h0aWnqKYJH/yag8925aOhxQQACPLU4q5JUbg1MQIeWpWDW0hERM7OZDZZg9COQay9INcStJ4euNoEsx32sXusbgbRRrPRbg+0M1LKlFApVFAr1FDJVVDL1VAr1GhqbbLOQz+TU42n+qCVvYNBOlEPkclkGOQzCIN8BuEvI/+C7JpspOWnIS0vDUerjiK3IQNABuAGjBk/HMO8JsHDNAr55VocKNTjRFkdyuuakXa0DGlH2y88kb6uNvPbh4Z6wlXNty5RTztSXIt307PxfUYxWs3SF5iBgR5YmByDWQkhUCuZV4KIyJkIIaTg1BKYdghyux3MdmMfe0H02bY1CZOjH55ukcvkUMulIFilUEnBsEItrVOorP9a1luC5W5va7m97finH6OrY6nkKshl9j93d5fuxl1r7zrrufm7+vf0w9Vn+E2fqJfEeMVgoddCLBy+EIV1hVifvx5peWn47dRvOFhxAAcrDgAABvkMwuypKZgUMhVNDf7IKKjBgUI9DhTWILeyEXlty/cZxQAAuQwYEOAhDZMPl4L3QUGeDCCIzoMQAlszK7FsS5bNqJYJsb5YmByDyZf5M3cE0Xm6WEsjXYo69uh21SPccWhzx9vPts/p29odPt3F8Y1mo6Mfmm47U5DbMUBVKpTWoFatUFtvtxv4th3j9G3PGCyftl4p73/h4KiAUQh0DUR5Y7ndUQEyyBDoGohRAaMc0LqeIRNC9I/xDj2ktrYWOp0Oer0enp6ejm7OGRmNRvz000+46qqroFJxeOXForyxHBvyNyAtLw17yvbY/NIarYtGakQqUiNTMdhnMGqbWnGgSAraLcF7aa2h0zHVCjkGB7dllG8L3GP83VkGis7oUr7GtJrM+PFgCZZvycbh4loA0g9gVw0Lxj3JsRgWpnNwC4n6t9NLIwG4aEoj9RZL0qyOPbbWYNVe4NthDrHNPvYC39P26bi+1dx61uObhdnRD0+3KGSKLoNaa0+uXN15/blsa+n9PUsQbRN4y5X8wbeHWbK7A7AJ1GWQHmdnzO5+LnEog3Qndil/gb5UVBuqsalgE9Ly07C9eLvNL8Kh7qFIiUhBamQqEvwTrEN+ymoN1oA9o1D6V9/U+ZdkN7UCQ0N1SAhvzygf5u3CDwmyuhSvMQ3Nrfh8dwHe/zUHRTVNAKTqCzePDccfJkUj3MfVwS0k6v+6Ko3kDF+ehRBoNbeeU5KrswXG3QlyTw+iO/UIm4xoFT2TNKsvWIJXtUIKQM81mD1bANxxvb3j2/Qid7gfjtS4tNj7MTDINQiPJj7qdAE6wCD9jBikk7Oqa6lDemE60vLT8GvRr2hqbbLe5ufiZw3YxwSOsRmaJIRAflUjMgr1ONAWvB8q1qOxpfNcKB83NYaF6qzz24eH6xDgwQzVl6pL6RpTXmfAx9tysXJHvvVHLV83Ne6cEIXbLo+EtxsTNBL1BJPZhBlfzThjUidfrS9enfqqNVjuKjA+Pcg9U49wl9mlO/REW/bpL5RyZac5vWpFh+HKZ5rTay9YPi0APj2Itnd8e0G0UsZeYXIeJrMJu4p3Yd32dZg+frpTT6thkH4GDNKpP2hqbcK2om1Yl78Omws2o95Yb71Np9FhavhUpEakYnzIeKgVnYMLk1kgs7y+raddCtyPltTCaOr8dg/Raa0Be0KYF4aF6eDJ7NWXhEvhGpN1qh7vbsnG1/uK0GKShmtG+7lhQVI0bhgVBq3KOT/IifobszCjuL4YP+f8jP/u/6+jm9NtpyfNOj2LtN1kWuey7RkSb50piFbKlV0mzSIiW/3l+8y5xKH9L1MA0SXARemClMgUpESmwGgyYkfJDqzPX48N+RtQ3VyNbzK/wTeZ38BN5YbksGSkRqRiUugkuKqkoboKuQwDgzwwMMgDN40JBwA0t5pwtKQOBwprkFEgJabLPFWPYr0BxfpSrDlcar3/GD+39vrt4ToMCdExmKF+ZU9uFZZtyca6I+29eaMivLAwORbT4wOZr4HoPAkhUNZYhsyaTGTVZOFk9Ulk1WQhS59lMwLsbLw13tBpdN3KDH3OibHOIYu0s/a4EdGljUE6kZNTKVRICktCUlgSnrz8Sewv3491eeuwPm89ypvK8XPOz/g552doFBpMDJmI1MhUTA6fDE+17S90GqUCI8K9MCLcCxgvratvbsWhIilgz2jLKF9Q1YTsigZkVzTgm9+kjPIKuQyXBXq0D5MP02FgkAdUCv7KT87DZBZYd6QMy7dkYV9+jXX99PhA3JMcgzFRPo5rHFE/I4RApaGyczBek4U6Y53dfVRyFQJdA1FYX3jW4/9nyn8wNmhsTzebiOiiwCCdqB9RypUYGzQWY4PGYnHiYhysOIj1eeuxLm8dCusLsaFgAzYUbIBSrsS44HGYHjEdUyOmwkdrPzhx1yhxeYwvLo/xta6ramixDpE/UFiD3wr0qKhvxtGSWhwtqcVnuwsAABqlHPEhnkho620fHuaFaF83yNlDSX3MYDThq32FeC89BzkVDQCkigfXjwrFgqQYxAW4O7iFRM6txlDTHozXSMF4Zk0mappr7G6vkCkQ6RmJOK84afGOQ6xXLCI8IiCDDDO+mnFRl0YiIuptDNKJ+im5TI4E/wQk+CfggdEP4ET1CazLW4e0vDRk6bOwtWgrthZtxbM7nsXowNFIiUhBSkQKgtyCznhcHzc1pgwMwJSBAQCk3pQSvcGmt/1AoR51hlbsz6/B/g49lh4aJYZZhsm31XEP0WmZYIZ6RXVDC1buyMPH23NRUS8lg/LUKjFvfCTumBDFpIhEp6lvqbcG45k1mdaloqnC7vYyyBDuEY44LykIH+A9ALFesYjyjLKbD8ViceJiLNq0CDLI7JZGejTxUQ4zJyI6AyaOc2L9JQkCOZ9sfTbW561HWn4ajlQesbltuN9wpEamIjUiFeGe4ed1fLNZILeywaYM3OFiPQzGznVU/dzV1iHyCW3/+rprzut+qWf112tMQVUj3v81B5/vLkCTUapiEOrlgj9MisbNY8PhpuHvz3RpazQ2IkefY+0Vt/xb2lDa5T4hbiHWHvEBXlIwHq2LhovS5bza0N9KIxFR/9Vfvs8wu/sZMEinS01RfZE1YP+t/DebXo2B3gOREpmC6RHTEesVe0E93q0mM06U1Vt73DMKanC8rA4mc+dLTKiXC0a01W8f3pZR3p2BVZ/rb9eYg4V6LNuShZ8OlsDysooP9sQ9k2Nw1bBg5kigS06zqRm5+tz2IerVUs94UX2R3aHmABDgEtApGI/1ioWbyq3H29efSiMRUf/VX77PMLs7EVmFuofi9iG34/Yht+NU4ylsyN+AtPw07C7djePVx3G8+jje/u1tRHlGST3skamI94k/54BdqZDmqMeHeOKWRGmdwWjC4eJa6xD5jMIaZJ9qQFFNE4pqmvDjwRIAgEwGxPq72/S2Dw72ZEZ5ghACm0+cwvIt2diWVWldnzTAD/ckx2JinC+nU9BFz2g2Ir82v1Mwnl+XD7PoPIIJAHy0PtZh6pa547FesdBpdH3WboVcgTGBY1CuLseYwDEM0ImIuolBOtElxN/VHzcPuhk3D7oZNYYabCrchLS8NGwr3obc2ly8d/A9vHfwPYS4hSAlMgWpEakYETDivGu1alUKjI70xuhIb+u6WoMRhwr1NvPbi2qakFlej8zyeny9rwgAoFJIZeSs89vDvDAgwB1K9pZeElpazfg+oxjvpmfjWKmUSVohl+HahBDcnRSD+BDnHglFdD5MZhMK6wutQbhlya3NRau51e4+HmoPDPAa0GneeFcJQ4mIyPkxSCe6RHlpvTA7bjZmx81GfUs90ovSsS5vHX4t+hXFDcVYcWQFVhxZAT8XP0wLn4bUyFSMCRoDlfzChhF5alWYEOeHCXF+1nWn6ppxsEiq326Z417V0IJDRbU4VFSLVTul7VxUCgwN9bSZ4x7p68qe1ItIncGIT3fl44Nfc1FaawAAuKkVuCUxAndNikao1/nNjyVyJmZhRnF9sU0Ct6yaLGTrs9Fsara7j6vStT2Tui4Wcd5S77i/iz+vgUREFxkG6UQEd7U7roy+EldGXwlDqwFbi7difd56bCrYhIqmCnxx4gt8ceIL6DQ6TAmbgtTIVIwPGQ+NomcSwPl7aDBtUCCmDQoEIA1xLqxuspaByyiswaGiWtQ3t2J3bjV251Zb99W5qNrmtluyynshSMes3v1NWa0BH2zNwaod+ahrlnoM/T00mD8xCr8fFwmdi/POMSPqihACZY1lttnUqzORpc9CU2uT3X20Ci2iddHWHnHLUPVgt2AG40RElwgG6URkQ6vUWsu1GU1G7CrdhXV567CxYCOqDFX4NutbfJv1LVyVrpgcNhkpkSlICk2Cq8q1x9ogk8kQ7uOKcB9XXD08GICUUT67oh4ZBXprcrojJbXQNxmRfrIC6SfbSwgFeGhsysAlhOng5dp1uSBynBNldVi+JRvf/lYEo0lKdBUX4I6FSTG4bmQINErOYSXnJ4RApaGyczBek4U6Y53dfZRyJaJ10e21xtuWUPdQzt0mIrrEMUgnoi6pFCpMDJ2IiaET8ZT5Kewr34e0vDSk5aehvLEcP+f+jJ9zf4ZGocGEkAmYHjkdyWHJvZKYSC6XIS7AA3EBHrhhdBgAad7y8dK6tiHy0jD5E2V1KK9rRtrRMqQdbS/9E+nrajO/fWioJ1zVvAQ6ghACO7KrsHxLFjYeP2Vdnxjlg3smx2DqwADI5ewxJOekb9Zbg/COQ9Wrm6vtbq+QKRDhGdEpGA/3DL/g6UNERHRx4jdUIuoWhVyBsUFjMTZoLB5NfBSHKg4hLT8NaXlpKKgrwMaCjdhYsBFKmRLjgschJTIF08KnwdfFt9fapFbKMSxMh2FhOgCRAIDGllYcLq5FRkGNdbh8bmUj8tqW7zOKAQByGTAgwEMaJt/W2z4oyBNqJRPT9RaTWWDNoVIs35KFjEI9ACmz/8whQViYHIOREd5nOQJR36lvqUeWPqtTMH6q6ZTd7WWQIcwjzCYQt9QaVys4koeIiLqPQToRnTO5TI7h/sMx3H84Hhj1AE5Un7AG7Jk1mdhavBVbi7fiuR3PYWTASEyPnI6UiBQEuQX1ettc1UqMjfLB2Kj2zMb6RiMOFLWVgWsL3ktrDTheVofjZXVYvbcQAKBWyDE4uC2jfFvgHuPvDgV7dS9IU4sJq/cW4L30HORXNQIANEo5bhwThgWTYhDl1/P1mYm6q6m1Cdn6bOvwdEuZs5KGki73CXELaZ8v3lZzPEYXAxclExsSEdGFY5BORBdEJpNhoM9ADPQZiD+N+BNy9DlYn78eaXlpOFx5GHvL9mJv2V68uOtFDPMbJtVij0hFhGdEn7VR56pC0gB/JA3wt64rqzVYA3ZLRnl9kxEZbeXhVuzIAyBlFh8aqkNCeHtG+TBvFyZw6obK+mZ8vD0PK7bnorrRCADwdlVh3vgo3DE+Er7uPZN4kKg7WkwtyNHnWHvELcF4YV0hBITdfQJcAqRg3Nu2d9xNxR+WiIio9zBIJ6IeFa2LxoJhC7Bg2AIU1xdbA/b95ftxsOIgDlYcxKt7X8Vl3pchNSIVqZGpiPOK6/OgN9BTiyuGBOGKIVLvvhAC+VWNUv32tuD9ULEeDS0m7Mypws6cKuu+Pm5qDAvVWee3Dw/XIcCDGeUtcisa8N6v2Vi9pxDNrWYAQISPKxYkRePG0eFwUTMpFvUeo9mI/Np8myHqmTWZyK/Nh0mY7O7jrfG2CcQtwXhv5NcgIiI6GwbpRNRrQtxDMC9+HubFz0NFUwU25G9AWl4adpXuwonqEzhRfQJvZ7yNSM9Ia8A+xHeIQ3qpZTIZIn3dEOnrhmsTQgBIc6gzy+ttEtMdLalFVUMLNp84hc0n2uemBuu0NmXghoXpLrmyYfvzq7F8SzbWHC6FaOuYTAjTYWFyLGYODeK0AepRJrMJhfWFNpnUT9acRG5tLlrNrXb38VB72AThA7ykMme9mTuDiIjoXDFIJ6I+4efih5sG3oSbBt4EfbMeGws2Yn3eemwr3oa82jy8f+h9vH/ofQS5BVkD9hH+Ixxaikghl2FgkAcGBnngpjHhAIDmVhOOltRJZeDaysFlnqpHid6AEr0Baw+3Z5SP8XNrD9zDdRgSooNWdXH1IpvNAhuPl2PZ5mzsym0fbTB1oD8WJsfi8hgfTg2gC2IWZpQ0lEhBePVJa894tj4bzaZmu/u4Kl2tc8Y7BuMBrgF8PRIRkdNjkE5EfU6n0WF23GzMjpuNBmMD0gvTsS5vHdKL0lHaUIqVR1di5dGV8NX6YlrENKRGpmJs0FinKFekUSowItwLI8K9gPHSuvrmVhwqaq/ffqCwBgVVTciuaEB2RQO++U3KKK+Qy3BZoEf7MPkwHQYGeUCl6H8Z5ZtbTfh2fzGWp2cjs7weAKBSyHDdiFAsTI7BZYEeDm4h9TdCCJQ3ltvMF7cMV29sbbS7j0ahQYwuxprAzRKUB7sFQy7rf+8rIiIigEE6ETmYm8oNM6NnYmb0TBhaDdhWvA3r89djY8FGVBoqsfrEaqw+sRqeak9MCZ+C1IhUTAidAI3CeZKOuWuUuDzGF5fHtA+ZrWposQ6RP1BYg98K9Kiob8bRklocLanFZ7sLAEhZzuNDPJHQ1ts+PMwL0b5uTlsnXN9kxCc78/DR1lyU10m9mB4aJeZeHoH5E6IRpOPcfDq7yqbKTsF4Zk0m6lrq7G6vlCsRrYtGnK49m/oArwEIdQ916GgbIiKi3sAgnYichlapxbSIaZgWMQ1GkxG7S3djXf46bMjfgCpDFb7L+g7fZX0HV6UrksKSkBqZiqTQJKfMtOzjpsaUgQGYMjAAgNRLWKI32PS2HyjUo87Qiv35NdifX2Pd10OjxDDr/HapjnuITuvQYbrFNU344NccfLorHw0tUvKtIE8t7poUhVsTI+ChdfwoB3I++ma9TfI2y/+rDFV2t1fIFIjwjOg0bzzcM9wpRtIQERH1BQbpROSUVAoVJoROwITQCXhy3JPYX77fWou9rLEMa3PXYm3uWqjlakwInYDUiFRMCZ/itNmYZTIZQrxcEOLlgplDgwFI87lzKxtsysAdLtajrrkV27IqsS2r0rq/n7vaOkQ+oe3fvihhdqS4Fu+mZ+P7jGK0mqVscAMDPbAwOQazEkKgVnJIMQENxob20mYd5o2fajpld3sZZAjzCLOZLx7nFYdoXTTUCnUft56IiMi5MEgnIqenkCswJmgMxgSNwaNjH8WhikPWgD2/Lh+bCjZhU8EmKGVKjA0ai9TIVEyLmAY/Fz9HN/2M5HIZYvzdEePvjtkjQwEArSYzTpTVW3vcMwpqcLysDhX1LdhwrBwbjpVb9w/1ckFCuCVolzLKu2u6d1k3mQV25lRhb4UMvjlVGB8XYM2+LoTA1sxKLNuShfSTFdZ9JsT6YmFyDCZf5s/kW5eoptYmZOuzpSC8OtPaO17SUNLlPsFuwbbBuHccYnQxcFG69GHLiYiI+g+ZEJZCOZeG2tpa6HQ66PV6eHp6Oro5Z2Q0GvHTTz/hqquugkrFYX5EpxNC4GTNSaTlpSEtPw0nq09ab5NBhpEBIzE9cjpSIlIQ7B7swJZeGIPRhMPFtdYh8hmFNcg+1dBpO5kMiPV3t+ltHxzs2Smj/JpDJVjy/RGU6A3WdcE6LZ68ejBazQLLt2TjcHEtAEAuA64eHoKFSTEYFuacoxSo57WYWpCjz7EZpp5Zk4nCukII2P/a4O/ib+0RtyRyi9XFwl3t3setJ2fC7zJE1Nv6y3XmXOJQBulOrL+84IicRa4+F+vz1yMtLw2HKg/Z3DbUdyhSIlMwPXI6Ij0jHdTCnlNrMOJQod5mfntRTVOn7VQKqYycZX57naEVz/94tIswq52LSoGbx4bjD5OiEe7j2jsnQQ5nNBtRUFtgE4hn1mQivzYfJmGyu4+Xxqs9EO+QVd1Zp5qQY/G7DBH1tv5ynTmXOJTD3YnoohGli8Ifhv0Bfxj2B5TUl2B9/nqsy1uH/eX7cajyEA5VHsLr+15HnFccpkdOR2pkKgZ4DeiXQ7c9tSpMiPPDhLj2If2n6ppxsEiq326Z417V0IJDRbU4VFSLVTvPfly5DPhbygDcPj4K3m6cG3yxMJlNKKov6hSM5+pzYTQb7e7jofKwZlLvmMjNV+vbL98zRERE/QWDdCK6KAW7B+O2+NtwW/xtqGiqwIb8DVifvx67SnZZA5R3Mt5BhEcEUiNTkRqRiqF+Q/t18OHvocG0QYGYNigQgDQdoLC6yVoGbsvJUzhaYr/ElYVZAInRvgzQ+ykhBEoaSmwyqZ+sPokcfQ4MJoPdfVyULtYAvGMPeYBrQL9+PxAREfVXDNKJ6KLn5+KHmwbehJsG3gR9sx6bCjYhLT8N24q2Ib8uHx8c+gAfHPoAQW5BSIlIQWpEKkYGjOz39ZdlMhnCfVwR7uOKq4cHI/43T/zts9/Oul95nf1gjpyHEAKnmk7ZJG+zzB9vbG20u49arkasV2yneePBbsGQy5iln4iIyFkwSCeiS4pOo8N1cdfhurjr0GBsQHpROtLy0rClcAtKG0rxydFP8MnRT+Cj9cG0iGmYHjEdY4PHXhQ1mgM8tD26HfWNKkNVp2D8ZM1J1LXYHxWhlCsR5RnVad54mHtYv//hiYiI6FLAIJ2ILlluKjfMjJqJmVEzYWg1YHvxdqTlp2FTwSZUGarw5Ykv8eWJL+Gh9sDU8KlIiUjBhJAJ0Cr7ZxCbGO2DYJ0WpXqD3cRxMgBBOi0So336umkEQN+st8mmbvl/laHK7vZymRwRHhHtmdTbypxFeEZcFD8qERERXaoYpBMRAdAqtZgaMRVTI6bCaDZid+lupOWlYX3+elQZqvBd1nf4Lus7uChdkBSahOmR05EUlgQ3lZujm95tCrkMT8+Kx30r90EG2ATqlpnHT8+Kt9ZLp97RYGxAVk2WtUfcUnO8vKm8y33C3MM6BeNRuihoFJo+bDkRERH1BYcH6W+99RZefvlllJaWIiEhAW+88QYSExO73P61117DO++8g/z8fPj5+WHOnDn45z//Ca22f/ZsEZHzUclVmBAyARNCJuCJcU/gt1O/WWuxlzaU4pe8X/BL3i9Qy9WYEDIBKZEpmBo+tV+UoJo5NBjv3DaqU530IJ0WT8+Kx8yh/beevLMxtBqQrc/uFIwXNxR3uU+QW5BNJvUBXgMQrYuGq4pl8IiIiC4VDg3SP//8cyxatAhLly7FuHHj8Nprr2HGjBk4fvw4AgICOm2/atUqLF68GB988AEmTJiAEydO4M4774RMJsMrr7zigDMgooudQq7A6MDRGB04Go+MfQSHKw9bA/a82jxsKtyETYWboJQpMTZoLFIjUzEtYhr8XPzOfnAHmTk0GNPjg7A9sxy/pO/EFUnjMD4ugD3o58loMiKnNsc6b9wyTL2grgCii4r0fi5+NnPGLQndPNQefdx6IiIicjYODdJfeeUV3H333Zg/fz4AYOnSpfjxxx/xwQcfYPHixZ2237ZtGyZOnIi5c+cCAKKionDrrbdi585uFP8lIrpAMpkMQ/2GYqjfUPxt1N+QWZNpDdhPVJ/A9pLt2F6yHc/teA4jA0YiNTIVKREpCHEPcXTTO1HIZRgX7YPKowLjon0YoHdDq7kV+XX5yKzOtOkdz6vNg0mY7O7jpfGy6RW3ZFb30nr1beOJiIio33BYkN7S0oK9e/fiscces66Ty+VITU3F9u3b7e4zYcIErFy5Ert27UJiYiKys7Px008/Yd68eV3eT3NzM5qbm61/19bWAgCMRiOMRmMPnU3vsLTP2dtJdKmKco/CgiELsGDIAuTX5mND4QZsKNiAQ5WHsK98H/aV78O/dv8L8T7xmBY+DSnhKYj0jHR0s614jbHPLMwoqi9Clj5LWmqkf3Nrc2E023+s3FXuiNXFIkYXgzivOOlfXRx8tD52a43zMadLBa8zRNTb+st15lzaJxNC2B+L18uKi4sRGhqKbdu2Yfz48db1jzzyCDZv3txl7/h///tfPPTQQxBCoLW1Fffeey/eeeedLu/nmWeewZIlSzqtX7VqFVxdOcePiHpejbkGR41HcbjlMPJMeTZDngPkARiiGoJ4dTyC5EF2AzjqG0II6IUeZaYylJvKpX/N5ThlOgUj7H+QqqBCgCIAAYoABMoDpX8VgfCUefK5JCIioi41NjZi7ty50Ov18PT0POO2Dk8cdy42bdqEF154AW+//TbGjRuHzMxM/O1vf8M//vEPPPXUU3b3eeyxx7Bo0SLr37W1tQgPD8cVV1xx1gfH0YxGI9atW4fp06dDpWI5HaL+qLKpEpuKNmFDwQbsLt2NcnM5ypvLsbF5I8Lcw5ASnoJp4dMwxHcI5DJ5n7btUrnGCCFQYaiw9ohbesez9dloaG2wu49arka0LtraI27pIQ92C+7z54moP7tUrjNE5Dj95TpjGdHdHQ4L0v38/KBQKFBWVmazvqysDEFBQXb3eeqppzBv3jwsWLAAADBs2DA0NDRg4cKFeOKJJyCXd/7ipNFooNF0LlGjUqmc+knsqD+1lYhsBamCcIvnLbhl8C3QN+uxpXAL1uWtw7bibSisL8THRz/Gx0c/RqBrIFIiUpAamYpRAaOgkCv6rI0X0zWmylDVXmu8LZFbZk0malvsfzAqZUpE6aI6zRsP8wiDUt6vfscmcmoX03WGiJyTs19nzqVtDvsGolarMXr0aKxfvx6zZ88GAJjNZqxfvx5//vOf7e7T2NjYKRBXKKQvsg4atU9E1G06jQ6zYmdhVuwsNBobkV6UjvV567G5cDPKGsuw6tgqrDq2Cj5aH0wNn4rUyFSMCxoHlcJ5P3AcpbalVkreVn3SpuZ4laHK7vZymRwRHhHWYDzOOw5xujhEekby8SUiIiKn4tBugkWLFuGOO+7AmDFjkJiYiNdeew0NDQ3WbO+33347QkND8c9//hMAMGvWLLzyyisYOXKkdbj7U089hVmzZlmDdSKi/sBV5YoZUTMwI2oGmk3N2F68HWl5adhYsBFVhip8dfIrfHXyK3ioPDA5fDJSI1MxMWQitEqto5vepxqNje094x2W8sbyLvcJdQ9tz6TuLZU4i9ZFQ6PoPKqKiIiIyNk4NEi/+eabcerUKfz9739HaWkpRowYgTVr1iAwMBAAkJ+fb9Nz/uSTT0Imk+HJJ59EUVER/P39MWvWLDz//POOOgUiogumUWgwJXwKpoRPgdFsxJ7SPUjLS8P6/PWoNFTih+wf8EP2D3BRumBS6CRMj5yOpNAkuKvdHd30HmNoNSBHn2MTiGfVZKGovqjLfQJdA6094pZgPEYXA1cVk4ISERFR/+Ww7O6OUltbC51O162seo5mNBrx008/4aqrrnLq+RVE1DtMZhMyTmVgXd46rM9fj5KGEuttKrkKE0ImICUiBVPDp55X3W1HXGOMJiNya3Pbg/HqTGTps1BQVwCzMNvdx1fraw3CLUusVyw81B590mYiOn/8LkNEva2/XGfOJQ5lVhwiIielkCswKnAURgWOwiNjH8GRyiNIy09DWl4acmtzsblwMzYXboZCpsCYoDGYHjEd0yKmwd/V39FNR6u5FQV1BbbBeE0W8mrz0Cpa7e6j0+g6BeJxXnHw1nr3ceuJiIiIHIdBOhFRPyCTyTDEbwiG+A3BX0f+FVk1WViXvw7r89bjePVx7CzZiZ0lO/H8zucxImCENVN8qHuo3eOZzCbsKduDjJYMBJQFIDEk8bwyypuFGUX1RdYecUsit2x9Noxm+7XG3VXu1gDcmlXdewB8tb6sNU5ERESXPAbpRET9jEwmk4Z/e8fhvoT7kF+bj/X565GWl4YDFQewv3w/9pfvx7/3/BuDfQZjeuR0pEamIloXDQBIy0vDi7teRFmjVAJz9frVCHQNxOLExUiNTLV7n0IIlDaUdpoznq3PRlNrk919XJQu1vricV7t88YDXQMZjBMRERF1gUG6szKbIMv7FaFV2yHL8wRikoE+rJtMRP1HhGcE5g+dj/lD56O0odQasO8r34ejVUdxtOoo/rv/v4jVxSLGKwbr8tZ1OkZ5YzkWbVqE/0z+D0YEjLAJxE/WnER2TTbqjfV2718tVyNaF20zbzzWKxah7qGQy+R29yEiIiIi+xikO6Mj3wFrHoWythhjACDvHcAzBJj5EhB/raNbR0ROLMgtCL8f/Hv8fvDvUdlUiY0FG5GWn4adJTuRpc9Clj7L7n4CUg7RBzc/aP3/6ZQyJSI9IxHn3TZEva3MWbhHOJRyfpwQERER9QR+q3I2R74DvrgdOP1Lcm2JtP6m/2OgTkTd4uviizmXzcGcy+agtqUWHx78EO8deu+M+wgIyCBDhGdE+3zxtmA8yjMKKoXzZk0lIiIiuhgwSHcmZhOw5lF0CtCBtnUyYM1iYNDVHPpOROfEU+2JAd4DurXtPyb+A9fFXdfLLSIiIiIiezhZ0JnkbQNqi8+wgQBqi4CsDX3WJCK6eHS3NFuIe0gvt4SIiIiIusKedGdSX9a97T65EQgcCoSNBsLGAqFjAL/LADl/cyGiro0KGIVA10CUN5bbnXcugwyBroEYFTDKAa0jIiIiIoBBunNxD+zmhgIoOygtez+SVmk8gZCRUtAeNkYK3N2712tGRJcGhVyBxYmLsWjTIsggswnUZZBKoj2a+Oh51UsnIiIiop7BIN2ZRE6QsrjXlsD+vHSZdPv8NUDJfqBwN1C4FyjeDzTXAjmbpcXCK6K9pz1sDBA0HFBp++psiMgJpUam4pUpr9jUSQeAQNdAPJr4aJd10omIiIiobzBIdyZyhVRm7YvbAchgG6hLvVyY+SLgHSEt8W2JnUytQPkRoGgPUNi2VBwHavKl5dBXbcdXAUHD2nvaw8YAPjGATNaHJ0lEjpYamYqp4VOxq3gX1m1fh+njpyMxJJE96EREREROgEG6s4m/ViqztuZR2yRyniFSgG6v/JpCCQQPl5Yxd0nrmmqA4n1ST7sleG+skNYV7wOwXNrOxQcIHd0euIeOAlx9evssicjBFHIFxgSOQbm6HGMCxzBAJyIiInISDNKdUfy1wKCr0Zq9Bb+lr8WIpBlQxiSfW9k1Fy8gdpq0AIAQQHUuULRXCtiL9gAlGUBTFZC5TlosfOPae9rDxkhJ6lgbmYiIiIiIqNcxSHdWcgVE5CQUHa5FQuSkC6+LLpMBPtHSMmyOtK61GSg91N7TXrQHqMoGKjOl5cBn0nZKLRCc0Ba4t2WU14VzmDwREREREVEPY5B+KVNq2oLu0cC4e6R1DZVSb3vHwN2gBwp2SouFW0DbEHlLGbhRgMbDMedBRERERER0kWCQTrbcfIHLrpAWADCbgaqs9oC9cDdQdhhoKAeO/yQtAAAZ4D+ofYh86BggYPCFjwAgIiIiIiK6hDBIpzOTywG/AdIy4lZpnbFJms9e2Ba0F+0F9AXAqaPSsn+FtJ3KTeph75iYzjPYcedCRERERETk5Bik07lTuQARl0uLRV1Ze0974R6pdntLPZCbLi0WnmHS8HpLYrrgEYDatc9PgYiIiIiIyBkxSKee4REIDLpaWgDAbAJOHW/rad8jlYI7dRSoLQSOFAJHvpW2kymAwCG2tdt9B0g9+ERERERERJcYBunUO+QKIDBeWkbfIa1rrgOKf2sfIl+4B6gvBUoPSMueD6TtNDppmHzHwN3Nz2GnQkRERERE1FcYpFPf0XgA0UnSAki122uL2ofIF+2VgvhmPZC9UVosvKM61G4fCwQNk7LTExERERERXUQYpJPjyGSALkxahvxOWmcyStnjLUPki/YAFSeA6lxpOfSltJ1CLQXqoW1Be9howDuatduJiIiIiKhfY5BOzkWhAkJGSMvYBdK6pmqgaF/7EPnC3UBTVVs9973ArmXSdq6+Heq2j5YWFy8HnQgREREREdG5Y5BOzs/FG4hLkRZAGiZfndPe0164Gyg9CDRWAid/kRYL3wHtPe2hY6QkdQqVY86DiIiIiIjoLBikU/8jkwE+MdIy/EZpXWuzFKhba7fvkYbHV56UloxV0nZKF6mXvmPtdl0Yh8kTEREREZFTYJBOFwelpi2p3BgA90rrGirahshbEtPtk5LS5W+XFgv3wPYh8mFjgJCRUpI7IiIiIiKiPsYgnS5ebn7AZTOkBQDMZqAys32IfOEeKUldfRlw7AdpAQCZHPAf3D5EPmws4D9QKitHRERERETUixik06VDLgf8L5OWEXOldS2NQMlvbT3tbRnlawuB8sPSsu//pO3U7lIPu6UEXOgYwCPQYadCREREREQXJwbpdGlTuwKRE6TForakLWBvq91etA9oqQdy06XFQhfePkQ+bCwQnACoXPr+HIiIiIiI6KLBIJ3odJ7BgOcsYPAs6W+zCSg/ahu4lx8F9AXScuQbaTu5Usoeb63dPgbwiZV68ImIiIiIiLqBQTrR2cgVQNBQaRl9p7TOUAsU728fIl+4G2goB0oypGXP+9J2Wl2H2u1tie1cfRx2KkRERERE5NwYpBOdD60nEDNZWgCpdru+oL2nvXC3FKwb9EDWBmmx8I5u72kPHQMEDQOUasecBxERERERORUG6UQ9QSYDvCKkZej10jqTESg71Fa7vS0xXWUmUJ0jLQe/kLZTqKX57Jae9tDRgHcUa7cTEREREV2CGKQT9RaFSsoIHzISSLxbWtdYBRTvsw3cm6rbSsLtBna27evq197THjZaCty1OoedChERERER9Q0G6UR9ydUHiEuVFkAaJl+V3aEE3B6g9CDQWAGcWCMtAAAZ4HdZe0972FggIB5Q8C1MRERERHQx4Td8IkeSyQDfWGlJuFlaZzRIgXrh7vbAvSYPqDguLb99Im2ncgWCR0g97ZbEdLpQh50KERERERFdOAbpRM5GpQXCx0qLRf2pDiXg9ki125trgfxt0mLhEXxa7fYRgMa9z0+BiIiIiIjOD4N0ov7A3R8YeKW0AIDZDFScsA3cyw4DdSXAsR+kBQBkcmlYvHV++xjAbyBrtxMREREROSkG6UT9kVwOBAySlpG3SetaGoDi39oD98I9QF2xlGG+7BCw9yNpO7UHEDrKNnB3D3DUmRARERERUQcM0okuFmo3IGqitFjUFtsmpSveD7TUATmbpcXCK6JDCbgxUkk4lbbvz4GIiIiI6BLHIJ3oYuYZAsRfKy0AYGoFTh21LQF36jhQky8th7+WtpMrgaBhtoG7byxrtxMRERER9TIG6USXEkVb8B00DBgzX1pn0Es97IW7gcK9UuDecEpaV7wf2P2utJ2Lt5SUzhq4j5ZKyhERERERUY9hkE50qdPqgJgp0gJItdtr8ttKwO2VetxLMoCmaiAzTVosfGJt57YHDgWUakecBRERERHRRYFBOhHZkskA70hpGTZHWtfaApQdbO9pL9wDVGW1Lwc+l7ZTaKT57GEdhsl7RXCYPBERERFRNzFIJ6KzU6rbhrqPBrBQWtdY1d7TbgncDTVA4S5psXDzb+9pDxsDhIwCtJ6OOAsiIiIiIqfHIJ2Izo+rDzBgurQA0jD5yizb2u2lB6X57Sd+lhYAgAzwH2g7TN5/sDRfnoiIiIjoEsdvxUTUM2QywC9OWhJukdYZm4CSA7a12/X5wKlj0rJ/pbSdyg0IGQmEdUhM5xniuHMhIiIiInIQBulE1HtULkDEOGmxqC/vMER+N1DUVrs971dpsfAIsZ3bHjJCqgVPRERERHQRY5BORH3LPQAYdJW0AIDZBFScaOtpb8soX34EqCsGjn4nLQAgUwCB8R3mt48FfAcAcrnjzoWIiIiIqIcxSCcix5IrgIDB0jJqnrSuuR4o+a2tdvseKXCvK5HmuJceBPZ+KG2n0QGhI9sC97FS8O7m57BTISIiIiK6UAzSicj5aNyBqEnSYqEvautp3yOVgiveDzTrgexN0mLhFdkhKd1YIGgYoNL29RkQEREREZ0XBulE1D/oQqVlyGzpb1OrNCzeMkS+cA9QcRyoyZOWQ19J28lVUqBuGSIfOhrwiWHtdiIiIiJySgzSiah/UiiB4OHSMvYP0rqmGqB4n9TTbklM11gprSveB+xaLm3n4iMF62Fj2zLKjwZcvB12KkREREREFgzSieji4eIFxE6TFkCq3V6d297TXrgbKD0ANFUBmeukxcI3rr2nPWwMEDgUUKgccRZEREREdAljkE5EFy+ZDPCJlpZhc6R1rc1A6aEOtdt3A9U5QGWmtGR8Km2n1ALBI9rmt7cF7rpwDpMnIiIiol7FIJ2ILi1KjTTEPWw0MO4eaV1DpdTbXtShDJxBDxTskBYL98C2hHSjpX9DRwEaD8ecBxERERFdlBikExG5+QKXXSEtAGA2A1VZHWq37wHKDgP1ZcDxH6UFACCTSsdZetrDxgL+g6SyckRERERE54FBOhHR6eRywG+AtIy4VVpnbAJKMmxrt+sLpAzz5UeA/Suk7dTuQMjIDonpxgAeQY47FyIiIiLqVxikExF1h8oFiLhcWizqStsC9rb57cX7gZZ6IDddWiw8w9qG2I+VhskHJwBq174/ByIiIiJyegzSiYjOl0cQMPgaaQEAswk4daxD4L5X6mWvLQSOFAJHvpW2kymAwCHtPe2hY6Ts8nK5486FiIiIiJwCg3Qiop4ibwu+A4cAo++Q1jXXST3sliHyhbulue2lB6Rlz/vSdlqdNEQ+dEx74O7m67hzISIiIiKHYJBORNSbNB5AdLK0AFLtdn1h+xD5or1SEG/QA1kbpMXCO7o9YA8bAwQNk7LTExEREdFFi0E6EVFfkskAr3BpGfI7aZ3JKGWPtwyRL9wNVJ6U6rdX5wAHV0vbKdRA0PAOgftoKZBn7XYiIiKiiwaDdCIiR1OogJAR0jJ2gbSuqRoo2tc+RL5wD9BUJQXyRXva93X17TBEfrS0uHid/T7NJsjyfkVo1XbI8jyBmGSWjiMiIqL+5SL9PsMgnYjIGbl4A3Ep0gJIw+Src9p72ov2ACUHgMZK4ORaabHwu6w9cA8bAwQMARQdLvdHvgPWPAplbTHGAEDeO4BnCDDzJSD+2r48SyIiIqLzcxF/n2GQTkTUH8hkgE+MtAy/UVrX2gyUHuxQu30PUJ0LVJyQloxV0nZKF6mXPnQ0ABmw/U0Awvb4tSXAF7cDN/1fv/9gIyIioovcke+k7y0X6fcZBulERP2VUtPeW27RUGFbu71oH9CsB/K3S0uXBAAZsGYxMOjqi2KoGBEREV2EzCbg50fRKUAHcLF8n2GQTkR0MXHzAwbOlBYAMJuBykypt/3o98CJn8+wswBqi4C3xkmZ5L2jAJ9o6V/vKMAztN9+2BEREVE/01QNVOVIowSrc9sS6uYC5ceAhvIz7Nj2fSZvGxCd1Ddt7WEM0omILmZyOeB/mbQoNWcJ0ttUnpSWTsdSAV4RnYN377b/a9x7tu1ERER08TK1ArWF7UH46QG5QX9hx68vu/A2OgiDdCKiS4V7YPe2m/oEoHKx/dCsyQfMRqAqS1qy7Ozn5t85cLcE9O5B0g8GREREdOkw1Nr2gncMxvUFgLn1zPu7B9l+n/COkoL3nx85+31393uPE2KQTkR0qYicIGU9rS2B/XlcMun2pAc7D2s3m4Da4vYP2dN/7W6qBhpOSUvh7s6HVmgA78j24L1jT7xXJKB27dlzJSIiot5nNgN1xfaHpVfnSlVozsT6/SCq83eErr4fmE3A1tfO/n0mcsKFnJlDMUgnIrpUyBVSWZIvbgcgg+0Hm0z6Z+aL9uedyxWAV7i0RCd3vr2pBqjJs/8hXVMAmJrbs87bY/ml3N4wevcAKbs9ERER9b2Whq6HpNfkA6aWM+/v6mf/8907CvAIPveRdhfyfaafYJBORHQpib9WKkuy5lGpZ9zCM0T6QDvfciUuXtISnND5NlOrNKStq+FuzbVAfam0FOzovL/Kteth9F4R0lx7IiIiOj9mszR/u6vP6TMmaYNtzppOP7hHARqPnm9zb32fcRIM0omILjXx1wKDrkZr9hb8lr4WI5JmQBmT3Hu/OCuU0ge2TzSAqba3CSENlbf3paA6T0ooY2wEyo9ISydtQ9pOD94tAb2rD3vhiYiIjE1Sr7f1M7Zjj3gu0Go48/4u3vZ/LHdk9Ze+/j7ThxikExFdiuQKiMhJKDpci4TISY77QJPJpEDa1ef/27vv+CiqhY3jz2bTKyWNEhKq0juIKEWqIsq9FiwoTa4iKNJUsIBY4IooqFy4Ku1eUbByeRWRoiBNwEKTjkAQSOikt915/1iyZLObsIGELOT39TMfsjNnZs5skjHPnjPnSFWaO2/PybK1wp856PwHxZmDUnaqbZqVpKPS4bXO+/uGXPhDIs65NT4sRvL2LblrAwDgajEM27gwBXVLTz5e+P4msxRWteBu6QHlSrT6l81T/p4pZoR0AIDn8vaVKta0LfkZhpR6yvVANWcO2gayyUqWErfblvxMXrY/SPL/MZL7B0pA+ZK7LgAAiion0zbOS0Hd0rNTC9/fL7SALunVbf8/NPuUbP3hNkI6AODaZDJJwRG2Jaal8/bsDFvXPpcj0h+Sci50/TsXLx38yXl//7CCu9GHVrF14wcAoLjkPgLm0HvsoO3xr7OHpPN/yfVo5rlM+T58jsvz/6/qtg+feQTsmsBfGACA65OPvxRRx7bkZxgXB8lxNSJ9SqJtHtbjW2xLfl7etu7yBXUL9A8tqasCAFzLLNl5BlM95PwBcmZS4fv7BBU8G0q5GAZTvU4Q0gEAZY/JJIVE25ZqNzlvz0q92HKRv0vhucO26WbOXmjpcCWwYsEj0odULvp0MwCAa0f6uYK7pJ//SzIshe8fUrngbulB4bSGlwGEdAAA8vMNkqLq2Zb8rFbbADwuR6Q/JKWdktJO25ajvzrvb/aVysUWPFWNb1CJXRYAoBhYLbYBS131xDp7yNZlvTDe/gWPlF6umuQTULL1h8cjpAMAUBReXlJYFdsSd4vz9owkW2u7qz/ezsXbWuFP77MtrgRFFtyVMSSaFhQAuBoykwseKf3cEcmaXfj+QZEFPxIVHEWPKhSKkA4AQHHyD5WiG9qW/Cw5ttaXgkakzzgnpZ6wLX9tct7fO0AqH+u6BYbWFwBwn71X1CHXPaPSThW+f95eUU5hPJZeUbgihHQAAK4Ws/eFkB0rqb3z9vSzznPB5359/ohtRPqTu22LKzzHCAAXZaU53lPzhvGzhyVLZuH728cXcdEtPaTSdTMnNzwPIR0AAE8RUN62VG7qvC3viMD5u16eOWSbEz75mG2JX++8PyMCA7je5J2pw9W9MSWx8P2dZurIN0YIM3WglBDSAQC4Fph9pAo1bEvNfNsMQ0o7k6el6ODFlqIzB21d7LNTpRN/2BYnzK0LwENlZ9jG8yhosM6c9ML39y9XcA+j0Cq2Hk6Ah+GnEgCAa53JJAVVtC1Vmztvz8m0DXSU+0du/tam7DRbK/35I9KhNc77+4W6CO9xtj9yw6raPkAAgMthGLbZMAoaKT3pmCSj4P1NXnk+ZKzuHMYDypf4JQDFjZAOAMD1zttPCq9lW/IzDCn1pOvwfvaQbWClzCQpYZttyc9ktv2BXNAoxgHlSuyyAFwjcrIuPK5zMN995sKSlVL4/r4hUoU41/eYctX4oBDXHUI6AABlmckkBUfalphWztuz023d5l2NgHzusJSTYfv33GHXxw8o7/yHdW6gD63CwEvA9cAw8gx8mb9b+mEp6S/JsBZyAJPtfmDvrRN34X5x4V4RWIFHblCmENIBAEDBfAKkyBttS35W64VBmwp4VjT1hO0P9/Sz0rHfnff38rG1grl8XjRO8gspscsCUESWnIuDVzqF8UNS5vnC9/cJLHik9LAYyce/RKsPXEsI6QAA4PJ4eUmhlWxL7M3O2zNTbC3sLp81PSxZs6UzB2yLK4HhBXejD6lkOz+A4pNxvuCR0s8dkQxL4fsHR7v+na1QXQqKoDUccBMhHQAAlAy/YCmqvm3Jz2qxDQjlslXuoJR+Rko7ZVv+2uy8v9nvwpzzcc4tc+ViJd/AErww4Bpl/70roPdL+pnC9zf7FTxSerlqZfL3zmKxKDs7u7SrUaZlZ2fL29tbGRkZslgu8UFSCfP19ZVXMXyATEgHAABXn5fZNj97uRip+q3O2/O26OUPEuePSJZM6dRe2+JKcJTrkZ7LV7c9f0+LHq5XmSn5BmbL87tzLl6yZBW+f1BEwd3Sg6PpwXKBYRhKSEjQuXPnSrsqZZ5hGIqOjtaRI0dkKuV7u5eXl6pXry5fX98rOg4hHQAAeB7/MKlSY9uSnyXHNhCVqy65uc/GpiTaliM/O+/vHeA8lVzekaJ5NhaezGqVUhIKnpEh9WTh+3v55OmFEuf4818+ztYDBpeUG9AjIyMVGBhY6uGwLLNarUpJSVFwcHCxtGJfST2OHTum48ePq1q1alf0M3FFIT0jI0P+/vyPDAAAXEVm74uBokYH5+1pZwoe3CrpLyknXTq5y7Y4MUmhlQtuSQysSCs8Sp59VgUX3dJzZ1UoTECFgrulh1ZmVoUrZLFY7AG9YsWKpV2dMs9qtSorK0v+/v6lGtIlKSIiQseOHVNOTo58fC5/asAih3Sr1arXX39dM2fOVGJiovbu3asaNWropZdeUlxcnAYOHHjZlQEAALhigRVsS5Vmztvyztecf5qoswdt8zUnHbUth9c57+8bciHsxDqHn7AYyfvKujiijDAMW4u3vSU8389jSkLh+5suPC7i6oOk8nG2nigoMbnPoAcGlr1n8FG43G7uFovl6ob01157TfPmzdObb76pQYMG2dc3aNBAU6dOJaQDAADP5e0rVaxpW/IzDCntdMHdiJOOSlnJUuJ225KfyUsKrXphjuc4x9b4CtVtc8aj7MjJtD0DXtDPU3Za4fv7hbn+WcqdsszMU6uljS7uyK+4fiaK/Nv9n//8Rx988IE6deqkJ554wr6+cePG2r17d7FUCgAA4KozmaSgcNtStYXz9uyMi6Erb9jKDWA56dL5eNty8Cfn/f3DCu5GH1qV0HWtMYw8j1YcvDgmQu7PR9JRSUbB++d+qJP7fHj+MRICyvNoBVBGFfn/BkePHlWtWrWc1lutVqYfAAAA1y8ffymijm3JzzCklBMFT22VkmAbsf74VtuSn5e3rXXUqevyhX/9Q0vuulAwS7brD2ZyxzjISi58f99gx0HZ7N9bHo+AZLEa2nTwjE4kZygyxF+tqleQ2ev6+2DGZDLp66+/Vq9evYq17JVq166dnnjiCT300ENulX/++eeVmpqq9957r4RrdhkhvV69elqzZo1iY2Md1n/xxRdq2rRpsVUMAADgmmEySSFRtqXaTc7bs9JsA345hPfcfw/bppTLbY11JaCC8zPwuV8zENiVST/r4oOVC/+e/0syrIXvH1LZ9femQnUGGkSBlu44rlf+b6eOn784CGClMH+N61lP3RtUKpFz9uvXT/PmzZMk+fj4qFq1anr00Uc1duxYeXuXXE+e48ePq3x59x73KUrZK7F48WIlJibqgQcesK+Li4vT4cOHJdnGG7jhhhs0ZswY3XfffZKkUaNGqUaNGho+fLhq1KhRovUr8nfj5ZdfVt++fXX06FFZrVZ99dVX2rNnj/7zn//om2++KYk6AgAAXNt8A6XIurYlP6tVSj5eQGvtQSntlJR+Rjp6Rjr6q/P+Zl/b1HH5A2L5OKlcLFNqWXJsXc8L6uWQca7w/XOn7HM1UjpT9uEyLN1xXIM//s3pYYiE8xka/PFvmtGnWYkF9e7du2vOnDnKzMzUkiVLNGTIEPn4+GjMmDFOZbOysq54vm9Jio6OLpGyV+Ldd99V//79nUaDnzBhggYNGqSkpCRNmTJFvXv3VpUqVXTzzTcrPDxc3bp104wZMzR58uQSrV+RQ/rdd9+t//u//9OECRMUFBSkl19+Wc2aNdP//d//qUuXLiVRRwAAgOuXl5cUVsW2xLV13p6ZnCfAH3IMmOfiJUuWdHq/bXElKLLgkBkcZTt/SbBaZDq8VlXObJDpcKhUo13JtfhnJDm+R3nHCzh/RLLmFL5/cFTB4wUER9EajkIZhqH0bItbZS1WQ+MW/+FytAJDkknS+MU71bZWuFtd3wN8zEUarMzPz88ehAcPHqyvv/5aixcv1pgxY9SvXz+dO3dOLVu21PTp0+Xn56eDBw/qyJEjGjlypJYtWyYvLy/deuutmjZtmuLi4uzHnT17tqZMmaL9+/erQoUKuueee/T+++9LcuzCnpWVpREjRujLL7/U2bNnFRUVpSeeeML+IUH+7u7bt2/XsGHDtGHDBgUGBuqee+7R22+/reBg24eP/fr109mzZ9WiRQv961//UlZWlh544AFNnTq1wNHVT548qR9++EHTpk1z2hYSEqLo6GhFR0dr+vTp+vjjj/V///d/uvnmmyVJPXv21AsvvOB5IV2Sbr31Vi1fvry46wIAAID8/EKk6Ia2JT+r5UIr8SHXI4inn5VST9iWvzY57+/tn++Z6bwhPlbyCbi8Ou9cLC19Tt5Jx9RCkg7PsHXL7/5Pqd5dRT+e1SolHyv4OtNOF76/2e/iAG2urtM3qOh1Ai5Iz7ao3svfF8uxDEkJSRlqOH6ZW+V3TuimQN/L76oeEBCg06cv/v6sXLlSoaGh9qyXnZ2tbt26qU2bNlqzZo28vb312muvqXv37tq2bZt8fX01Y8YMjRgxQpMmTdLtt9+u8+fPa906F1NYytaCvXjxYn322WeqVq2ajhw5oiNHjrgsm5qaaj/35s2bdeLECT322GMaOnSo5s6day+3atUqVaxYUStXrtSff/6p3r17q0mTJg4zkeW1du1aBQYGqm5dFz2b8vD29paPj4+ysrLs61q1aqW//vpLhw4dcviQorgxjCgAAMC1ysts63JdrppUvZ3z9vRzBXejP/+XlJMhndxtW1wJqVRwC3NQhOsW5p2Lpc8eldPI5knHbevv/4/roJ6VenG++vy9Bs4dtvUYKExgeME9BkIqlVyPAeAaZBiGVq5cqe+//15PPfWUfX1QUJA++ugjezf3jz/+WFarVR999JG9xX7OnDkqV66cVq1apa5du+q1117TyJEjNWzYMPtxWrZs6fK88fHxql27tm655RaZTCancc7y+uSTT5SRkaH//Oc/CgqyfZD2/vvvq2fPnvrnP/+pqKgoSVL58uU1efJklS9fXvXq1VOPHj20cuXKAkP64cOHFRUV5dTVPa+srCxNmTJF58+f12233WZfX7lyZfsxPCqke3l5FdqlwmJxr6sHAAAASlhAOSmgiVS5ifM2S7YtqBf0rHZmku1Z+eTjUvwG5/19gpxDcViMtGSkXE89dqEz77cjbF34cwfSyz1v6onCr8XL+8Kz9y4+MCgXywj4KDUBPmbtnNDNrbKbDp5RvzmbL1lubv+WalW9glvnLopvvvlGwcHBys7OltVq1UMPPaTx48fbtzds2NDhOfStW7dq//79CgkJcThORkaGDhw4oBMnTujYsWPq1KmTW+fv16+funTpohtuuEHdu3fXnXfeqa5du7osu2vXLjVu3Nge0CWpbdu2slqt2rNnjz2k16tXT2bzxfehUqVK2r59e4F1SE9Pl7+/67EknnvuOb344ovKyMhQcHCwJk2apB49eti3BwTYehelpaW5db2Xq8gh/euvv3Z4nZ2drd9//13z5s3TK6+8UmwVAwAAQAky+9hCboXqztsM48Ko5wfzdS8/dHHU8+xU6cQftsVthpR6Uvrfk643+5creKT00CqMYg+PZDKZ3O5yfmvtCFUK81fC+QyXH2WZJEWH+evW2hElMh1bx44dNWPGDPn6+qpy5cpOo7rnDcSSlJKSoubNm2v+/PlOx4qIiCi0NdqVZs2a6eDBg/ruu++0YsUK3X///ercubO++OKLol/MBfmfPTeZTLJaC56VITw8XGfPnnW5bfTo0erXr5+Cg4MVFRXl1Dh95swZSbZrL0mXNXBcfvfee6/q16+vhQsXauDAgcVSMQAAAJQSk0kKrGBbqjR33p6TKZ074tyN/tgWKemvSx8/oq5UrXW+MB4rBZT81EtAaTJ7mTSuZz0N/vg3meTY5yQ3Do7rWa/E5ksPCgpSrVq13C7frFkzLVy4UJGRkQoNdd1bJS4uTitXrlTHjh3dOmZoaKh69+6t3r17695771X37t115swZVajg2HOgbt26mjt3rlJTU+0fHqxbt05eXl664YYb3L6G/Jo2baqEhASdPXvWabq38PDwQt+fHTt2yMfHR/Xr17/s87uj2B7Ouemmm7Ry5criOhwAAAA8lbefFF5Lqt1ZajVI6va69MB86W8z3dv/jslSz2nSLcOl+n+zdccnoKOM6N6gkmb0aaboMMcu19Fh/iU6/drlePjhhxUeHq67775ba9as0cGDB7Vq1So9/fTT+usv2wdy48eP15QpU/Tuu+9q3759+u233/Tee++5PN7bb7+tTz/9VLt379bevXv1+eefKzo6WuXKlXN5bn9/f/Xt21c7duzQjz/+qKeeekqPPPKIvav75WjatKnCw8MLHNyuMGvWrNGtt95q7/ZeUopl4Lj09HS9++67qlKlSnEcDgAAANei2Jtto7gnHZfr59JNtu2xN1/tmgEepXuDSupSL1qbDp7RieQMRYb4q1X1CiXWgn65AgMD9dNPP+m5557T3//+dyUnJ6tKlSrq1KmTvWW9b9++ysjI0DvvvKNRo0YpPDxc9957r8vjhYSE6M0339S+fftkNpvVsmVLLVmyxGW3+cDAQH3//fcaNmyYWrZs6TAF25Uwm83q37+/5s+frzvvvLNI+y5YsMDhGf6SYjIMw9UdtEDly5d36JtvGIaSk5MVGBiojz/+WHfddRnTalxFSUlJCgsL0/nz5wvssuEpsrOztWTJEt1xxx0FzvMHAJeLewyAEmEf3V1y2Zm3oNHdgWtERkaGDh48qOrVqxc4ABmuHqvVqqSkJIWGhrr9jHxCQoLq16+v3377rdAR5vP67rvvNHLkSG3bts3pWf5chf1sFCWHFrkl/Z133nEI6V5eXoqIiFDr1q2d+vQDAACgjKl3ly2IL31OSjp2cX1oZan7JAI6gFIXHR2tWbNmKT4+3u2Qnpqaqjlz5hQY0ItTkc/Qr1+/EqgGAAAArhv17pJu7KGcP3/SljXfq8mt3eRdox2jswPwGL169SpS+YK68JcEt0L6tm3b3D5go0aNLrsyAAAAuE54mWXE3qKjfySpcewtBHQAcJNbIb1JkyYymUy61OPrJpNJFoulWCoGAAAAAEBZ41ZIP3jwYEnXAwAAAACAMs+t4e9iY2PdXi7H9OnTFRcXJ39/f7Vu3VqbNm0qsGyHDh1kMpmclh49elzWuQEAAAAA8BSXPTTdzp07FR8fr6ysLIf1RZ2CbeHChRoxYoRmzpyp1q1ba+rUqerWrZv27NmjyMhIp/JfffWVwzlPnz6txo0b67777ru8CwEAAAAAwEMUOaT/+eef+tvf/qbt27c7PKeeOy1bUZ9Jf/vttzVo0CD1799fkjRz5kx9++23mj17tp5//nmn8hUqVHB4vWDBAgUGBhLSAQAAAADXvCKH9GHDhql69epauXKlqlevrk2bNun06dMaOXKk3nrrrSIdKysrS7/++qvGjBljX+fl5aXOnTtrw4YNbh1j1qxZeuCBBxQUFORye2ZmpjIzM+2vk5KSJEnZ2dnKzs4uUn2vttz6eXo9AVybuMcAKGncZ3A9ys7OlmEYslqtslqtpV2dMi+30Tj3e1KarFarDMNQdna2zGbHGS2Kch8sckjfsGGDfvjhB4WHh8vLy0teXl665ZZbNHHiRD399NP6/fff3T7WqVOnZLFYFBUV5bA+KipKu3fvvuT+mzZt0o4dOzRr1qwCy0ycOFGvvPKK0/ply5YpMDDQ7bqWpuXLl5d2FQBcx7jHAChp3GdwPfH29lZ0dLRSUlKcHv0tEqtF3kc3yZR6QkZQpHKqtCoTUxWWL19eH3/8sXr06KH4+Hg1btxYP/30kxo2bFjgPvv27dOdd96pX375RSEhIS7LJCcnO60bMGCAmjVrpqFDhxZb/QuTlZWl9PR0/fTTT8rJyXHYlpaW5vZxihzSLRaL/Y0JDw/XsWPHdMMNNyg2NlZ79uwp6uGuyKxZs9SwYUO1atWqwDJjxozRiBEj7K+TkpIUExOjrl27KjQ09GpU87JlZ2dr+fLl6tKli3x8fEq7OgCuM9xjAJQ07jO4HmVkZOjIkSMKDg6Wv7//5R1k1//J9P3zMiUds68yQivL6DZJqtuzmGrqqH///vrPf/4jyfZBQ9WqVXXvvffqlVdeufzruEwBAQEKDQ1VcHCwJCkoKKjQbPbGG2/oqaeeUpUqVSRJq1atUqdOnezbK1asqJYtW2rSpEkOYX/8+PHq0KGDhgwZorCwsBK6mosyMjIUEBCgdu3aOb2nuT263VHkkN6gQQNt3bpV1atXV+vWrfXmm2/K19dXH3zwgWrUqFGkY4WHh8tsNisxMdFhfWJioqKjowvdNzU1VQsWLNCECRMKLefn5yc/Pz+n9T4+PtfM/yyupboCuPZwjwFQ0rjP4HpisVhkMpnsvYqLbOdi6fO+kgyH1aak4zJ93le6/z9SvaINxu0Ok8mk7t27a86cOcrOztavv/6qvn37ysvLS//85z+L/XyFyX3vct+/wt7L+Ph4ffvtt3r//fcdykvSnj17FBwcrH379mnChAnq2bOn9u/fL19fX0lSo0aNVLNmTX3yyScaMmTIVbkuk8nk8p5XlHtgkX+qXnzxRXtf/wkTJujgwYO69dZbtWTJEr377rtFOpavr6+aN2+ulStX2tdZrVatXLlSbdq0KXTfzz//XJmZmerTp09RLwEAAAAAiodhSFmp7i0ZSdJ3zyp/QL9wINs/S5+zlXPneIar4xTMz89P0dHRiomJUa9evdS5c2eHx1GsVqsmTpyo6tWrKyAgQI0bN9YXX3zhcIw//vhDd955p0JDQxUSEqJbb71VBw4ckCRt3rxZXbp0UXh4uMLCwtS+fXv99ttvRapjfp999pkaN25sb0XPKzIyUtHR0WrcuLGefvppHTlyxOmx6Z49e2rBggVXVIerze2W9BYtWuixxx7TQw89ZO+KUKtWLe3evVtnzpxR+fLl7SO8F8WIESPUt29ftWjRQq1atdLUqVOVmppqH+390UcfVZUqVTRx4kSH/WbNmqVevXqpYsWKRT4nAAAAABSL7DTpjcrFdDBDSjomTYpxr/jYY5Kv6wG0L2XHjh1av369YmNj7esmTpyojz/+WDNnzlTt2rX1008/qU+fPoqIiFD79u119OhRtWvXTh06dNAPP/yg0NBQrVu3zv78dXJysvr27av33ntPhmFoypQpuuOOO7Rv374CnyW/lDVr1qhFixaFljl//rwWLlwoSfZW9FytWrXS66+/rszMTJc9rD2R2yG9cePGevbZZzVy5Ejdc889GjBggDp06CDJeVq0oujdu7dOnjypl19+WQkJCWrSpImWLl1qH0wuPj7eqevDnj17tHbtWi1btuyyzwsAAAAAZck333yj4OBg5eTkKDMzU15eXnr//fcl2WbFeuONN7RixQp7r+YaNWpo7dq1+ve//6327dtr+vTpCgsL04IFC+zdt+vUqWM//m233eZwvg8++EDlypXT6tWrdeedd15WnQ8fPlxgSK9ataok26PQknTXXXfpxhtvdChTuXJlZWVlKSEhweEDCU/mdkifNWuW3nvvPX322WeaO3euOnXqpOrVq2vAgAHq27evy+4H7ho6dGiBI+6tWrXKad0NN9xgH2ofAAAAAEqNT6CtRdsdh9dL8++9dLmHv5Bib3bv3EXQsWNHzZgxQ6mpqXrnnXfk7e2te+65R5K0f/9+paWlqUuXLg77ZGVlqWnTppKkLVu26NZbby3w+erExES9+OKLWrVqlU6cOCGLxaK0tDTFx8cXqZ55paenFziw3Zo1a+Tv769Vq1Zp6tSpmjlzplOZgIAASUUbXb20FWnguMDAQPXr10/9+vXTgQMHNGfOHP373//WuHHj1LVrVw0cOFB///vfS6quAAAAAOBZTCb3u5zXvE0KrSwlHZfr59JNtu01byuR6diCgoJUq1YtSdLs2bPVuHFjzZo1SwMHDlRKSook6dtvv3VqgM3tJp4beAvSt29fnT59WtOmTVNsbKz8/PzUpk2bK5qqLjw8XGfPnnW5rXr16goNDVWlSpWUnJys3r1766effnIoc+bMGUlSRETEZdfharuM4Qhtatasqddee02HDh3Sp59+qp9//ln33XdfcdYNAAAAAK4fXmape+5I6vnH87rwuvukqzJfupeXl8aOHasXX3xR6enpqlevnvz8/BQfH69atWo5LDExtmfkGzVqpDVr1ig7O9vlMdetW6enn35ad9xxh+rXry8/Pz+dOnXqiurZtGlT7dy585LlnnzySe3YsUNff/21w/odO3aoatWqCg8Pv6J6XE2XHdIlW1f03JZ1i8WiQYMGFVe9AAAAAOD6U+8u2zRroZUc14dWLrHp1wpy3333yWw2a/r06QoJCdGoUaM0fPhwzZs3TwcOHNBvv/2m9957T/PmzZNke0w5KSlJDzzwgH755Rft27dP//3vf7Vnzx5JUu3atfXf//5Xu3bt0saNG/Xwww9fsvX9Urp166YNGzbIYrEUWi4wMFCDBg3SuHHjHB6NXrNmjbp27XpFdbjaihzS//rrL7322muqVauWbrvtNh06dEj/+te/dPz4cZfPAAAAAAAA8qh3l/TMDqnvN9I9s2z/PrP9qgZ0SfL29tbQoUP15ptvKjU1Va+++qpeeuklTZw4UXXr1lX37t317bffqnr16pKkihUr6ocfflBKSorat2+v5s2b68MPP7Q/oz5r1iydPXtWzZo10yOPPKKnn35akZGRV1TH22+/Xd7e3lqxYsUlyw4dOlS7du3S559/LknKyMjQokWLrrnGZJPh5ghsn332mWbPnq2VK1cqMjJSffv21YABA+zPNFwrkpKSFBYWpvPnz9unkvNU2dnZWrJkie64444CB2cAgMvFPQZASeM+g+tRRkaGDh48qOrVqxc4oBmK1/Tp07V48WJ9//33TtusVquSkpIUGhrqNCvYjBkz9PXXX1+1WcEK+9koSg51e+C4Pn36qEePHvr66691xx13OL0BAAAAAAAUt8cff1znzp1TcnJykeZb9/Hx0XvvvVeCNSsZbof0v/7664q7KgAAAAAAUBTe3t564YUXirzfY489VgK1KXluN4cT0AEAAAAAKFn0WQcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPESRQ/rmzZu1ceNGp/UbN27UL7/8UiyVAgAAAACgLCpySB8yZIiOHDnitP7o0aMaMmRIsVQKAAAAAICyqMghfefOnWrWrJnT+qZNm2rnzp3FUikAAAAAAMqiIod0Pz8/JSYmOq0/fvy4vL3dnnYdAAAAAMosi9WizQmbteTPJdqcsFkWq6W0qwQPUeSQ3rVrV40ZM0bnz5+3rzt37pzGjh2rLl26FGvlAAAAAOB6s+LwCnX7spsGfD9Az615TgO+H6BuX3bTisMrSrtqBerWrZvMZrM2b97stK1fv34ymUwymUzy9fVVrVq1NGHCBOXk5EiSDh06ZN+ed/n5558djvP555/rxhtvlL+/vxo2bKglS5ZclWvzNEUO6W+99ZaOHDmi2NhYdezYUR07dlT16tWVkJCgKVOmlEQdAQAAAOC6sOLwCo1YNUKJaY69k0+kndCIVSM8MqjHx8dr/fr1Gjp0qGbPnu2yTPfu3XX8+HHt27dPI0eO1Pjx4zV58mSHMitWrNDx48ftS/Pmze3b1q9frwcffFADBw7U77//rl69eqlXr17asWNHiV6bJypySK9SpYq2bdumN998U/Xq1VPz5s01bdo0bd++XTExMSVRRwAAAADwSIZhKC07za0lOTNZEzdNlCHD+TgX/pu0aZKSM5PdOp5hOB+nMB06dNBTTz2lZ555RuXLl1dUVJQ+/PBDpaamqn///goJCVGtWrX03XffOew3Z84c3XnnnRo8eLA+/fRTpaenOx3bz89P0dHRio2N1eDBg9W5c2ctXrzYoUzFihUVHR1tX3x8fOzbpk2bpu7du2v06NGqW7euXn31VTVr1kzvv/9+ka7xenBZD5EHBQXpH//4R3HXBQAAAACuKek56Wr9SetiO15iWqJuXnCzW2U3PrRRgT6BRTr+vHnz9Oyzz2rTpk1auHChBg8erK+//lp/+9vfNHbsWL3zzjt65JFHFB8fr8DAQBmGoTlz5mj69Om68cYbVatWLX3xxRd65JFHCj1PQECATp8+7bDurrvuUkZGhurUqaNnn31Wd911l33bhg0bNGLECIfy3bp106JFi4p0fdcDt0L64sWLdfvtt8vHx8fp05D88r7RAAAAAADP0bhxY7344ouSpDFjxmjSpEkKDw/XoEGDJEkvv/yyZsyYoW3btummm27SihUrlJaWpm7dukmS+vTpo1mzZhUY0g3D0MqVK/X999/rqaeekiQFBwdrypQpatu2rby8vPTll1+qV69eWrRokT0/JiQkKCoqyuFYUVFRSkhIKJH3wZO5FdJ79eqlhIQERUZGqlevXgWWM5lMslgYlRAAAABA2RDgHaCND210q+yvib/qyZVPXrLcvzr9S82jml+yXIB3gFvnzatRo0b2r81msypWrKiGDRva1+UG5RMnTkiSZs+erd69e9tn8nrwwQc1evRoHThwQDVr1rTv98033yg4OFjZ2dmyWq166KGHNH78eElSeHi4Qyt5y5YtdezYMU2ePJlGXhfcCulWq9Xl1wAAAABQlplMJre7nN9c+WZFBUbpRNoJl8+lm2RSVGCUbq58s8xe5uKuqiQ5PAcu2eqfd53JZJJky31nzpzR119/rezsbM2YMcNexmKxaPbs2Xr99dft6zp27KgZM2bI19dXlStXvuT03K1bt9by5cvtr6Ojo52m+k5MTFR0dHTRL/IaV6SB47Kzs9WpUyft27evpOoDAAAAANcls5dZz7d6XpItkOeV+/q5Vs+VWEAvqvnz56tq1araunWrtmzZYl+mTJmiuXPnOvSiDgoKUq1atVStWrVLBnRJ2rJliypVqmR/3aZNG61cudKhzPLly9WmTZviu6BrRJEGjvPx8dG2bdtKqi4AAAAAcF3rHNtZb3d4W5M2TXKYhi0qMErPtXpOnWM7l2LtHM2aNUv33nuvGjRo4LA+JiZGY8aM0dKlS9WjR49LHmfevHny9fVV06ZNJUlfffWVZs+erY8++sheZtiwYWrfvr2mTJmiHj16aMGCBfrll1/0wQcfFO9FXQOKPLp77kABkyZNKon6AAAAAMB1rXNsZ3WM6ajfTvymk2knFREYoWaRzTymBV2SDhw4oK1bt+rDDz902hYWFqZOnTpp1qxZboV0SXr11Vd1+PBheXt768Ybb9TChQt177332rfffPPN+uSTT/Tiiy9q7Nixql27thYtWuT0AUFZUOSQnpOTo9mzZ2vFihVq3ry5goKCHLa//fbbxVY5AAAAALgemb3Mahnd8qqec9WqVU7rDh065LQud/71kSNHFnisJUuW2L+eO3duoeft27ev+vbte8n63XfffbrvvvsuWe56V+SQvmPHDjVr1kyStHfv3mKvEAAAAAAAZVWRQ/qPP/5YEvUAAAAAAKDMK9Lo7pI0YMAAJScnO61PTU3VgAEDiqVSAAAAAACURUUO6fPmzVN6errT+vT0dP3nP/8plkoBAAAAAFAWud3dPSkpSYZhyDAMJScny9/f377NYrFoyZIlioyMLJFKAgAAAABQFrgd0suVKyeTySSTyaQ6deo4bTeZTHrllVeKtXIAAAAAAJQlbof0H3/8UYZh6LbbbtOXX36pChUq2Lf5+voqNjZWlStXLpFKAgAAAABQFrgd0tu3by9JOnjwoKpVqyaTyVRilQIAAAAAoCwq8sBxsbGxWrt2rfr06aObb75ZR48elST997//1dq1a4u9ggAAAAAAlBVFDulffvmlunXrpoCAAP3222/KzMyUJJ0/f15vvPFGsVcQAAAAAK43hsWi1I2bdP6bb5W6cZMMi6W0qwQPUeSQ/tprr2nmzJn68MMP5ePjY1/ftm1b/fbbb8VaOQAAAAC43iQtW6b9nTorvm9fHRs1SvF9+2p/p85KWrastKtWoG7duslsNmvz5s1O2/r162cfZNzX11e1atXShAkTlJOTI0k6dOiQfXve5eeff3Y4zueff64bb7xR/v7+atiwoZYsWXLJeh04cEB9+vRRVFSUQkNDdf/99ysxMdGhTFxcnNO5J02adAXvRskqckjfs2eP2rVr57Q+LCxM586dK446AQAAAMB1KWnZMh0d9oxyEhIc1uckJurosGc8MqjHx8dr/fr1Gjp0qGbPnu2yTPfu3XX8+HHt27dPI0eO1Pjx4zV58mSHMitWrNDx48ftS/Pmze3b1q9frwcffFADBw7U77//rl69eqlXr17asWNHgfVKTU1V9+7dZTKZtGLFCq1bt05ZWVnq2bOnrFarQ9kJEyY4nPupp566gnekZBU5pEdHR2v//v1O69euXasaNWoUS6UAAAAA4FpgGIasaWluLZbkZCW+9rpkGK4OJMlQ4utvyJKc7NbxDFfHKUSHDh301FNP6ZlnnlH58uUVFRWlDz/8UKmpqerfv79CQkJUq1Ytfffddw77zZkzR3feeacGDx6sTz/9VOnp6U7H9vPzU3R0tGJjYzV48GB17txZixcvdihTsWJFRUdH25e8PbOnTZum7t27a/To0apbt65effVVNWvWTO+//36B17Nu3TodOnRI06dPV8OGDdWwYUPNmzdPv/zyi3744QeHsiEhIQ7nDgoKKtJ7dzW5Pbp7rkGDBmnYsGGaPXu2TCaTjh07pg0bNmjUqFF66aWXSqKOAAAAAOCRjPR07WnW/NIF3TqYrUV9b8tWbhW/4bdfZQoMLNIp5s2bp2effVabNm3SwoULNXjwYH399df629/+prFjx+qdd97RI488ovj4eAUGBsowDM2ZM0fTp0/XjTfeqFq1aumLL77QI488Uuh5AgICdPr0aYd1d911lzIyMlSnTh09++yzuuuuu+zbNmzYoBEjRjiU79atmxYtWlTgOTIzM2UymeTn52df5+/vLy8vL61du1adO3e2r580aZJeffVVVatWTQ899JCGDx8ub+8ix+Grosgt6c8//7weeughderUSSkpKWrXrp0ee+wxPf744x7dZQAAAAAAyrrGjRvrxRdfVO3atTVmzBj5+/srPDxcgwYNUu3atfXyyy/r9OnT2rZtmyRbF/W0tDR169ZNktSnTx/NmjWrwOMbhqEVK1bo+++/12233SZJCg4O1pQpU/T555/r22+/1S233KJevXo5tLQnJCQoKirK4VhRUVFKyPdYQF433XSTgoKCNH78eKWlpSk1NVWjRo2SxWLR8ePH7eWefvppLViwQD/++KMef/xxvfHGG3r22WeL/uZdJUX+6MBkMumFF17Q6NGjtX//fqWkpKhevXoKDg4uifoBAAAAgMcyBQToht9+dats2i+/6Mg/Hr9kuZgP/q3AFi3cOndRNWrUyP612WxWxYoV1bBhQ/u63KB84sQJSdLs2bPVu3dve6vzgw8+qNGjR+vAgQOqWbOmfb9vvvlGwcHBys7OltVq1UMPPaTx48dLksLDwx1ayVu2bKljx45p8uTJDq3phXnjjTccZhPbuXOnqlWrZu8N8O9//1teXl568MEH1axZM3l5XWyPznvuRo0aydfXV48//rgmTpzo0ArvKS67fd/X11f16tUrzroAAAAAwDXFZDK53eU8qG1beUdHKycx0fVz6SaTvKOiFNS2rUxmczHX1Cbvc+C2U5oc1plMJkmS1WrVmTNn9PXXXys7O1szZsywl7FYLJo9e7Zef/11+7qOHTtqxowZ8vX1VeXKlS/Zlbx169Zavny5/XV0dLTTqOyJiYmKjo6WJD3xxBO6//777dsqV64sSeratat+//13ZWVlydfXV+XKlVN0dHSh46W1bt1aOTk5OnTokG644YZC61ka3A7pAwYMcKtcQaP9AQAAAEBZZjKbFTV2jI4Oe0YymRyD+oVwHDV2TIkF9KKaP3++qlat6vRc+LJlyzRlyhRNmDBB5gt1DQoKUq1atdw+9pYtW1SpUiX76zZt2mjlypV65pln7OuWL1+uNm3aSJIqVKigChUqFHi88PBweXl56YcfftCJEycKbaHfsmWLvLy8FBkZ6XZ9rya3Q/rcuXMVGxurpk2bFnkUQQAAAACAFNq1qzRtqhLfmOgwDZt3VJSixo6xbfcQs2bN0r333qsGDRo4rI+JidGYMWO0dOlS9ejR45LHmTdvnnx9fdW0aVNJ0ldffaXZs2fro48+spcZNmyY2rdvrylTpqhHjx5asGCBfvnlF33wwQeFHnvOnDmqVq2a4uLitHHjRg0bNkzDhw+3t5Bv2LBBGzduVMeOHRUSEqINGzZo+PDh6tOnj8qXL1/Ut+SqcDuk5w63f/DgQfXv3199+vQp9JMMAAAAAICz0K5dFdKpk9J++VU5J0/KOyJCgS2ae0wLuiQdOHBAW7du1Ycffui0LSwsTJ06ddKsWbPcCumS9Oqrr+rw4cPy9vbWjTfeqIULF+ree++1b7/55pv1ySef6MUXX9TYsWNVu3ZtLVq0yOkDgvz27t2rsWPH6uzZs4qLi9MLL7yg4cOH27f7+flpwYIFGj9+vDIzM1W9enUNHz7caSR5T2IyitAsnpmZaf/UY/369erRo4cGDhyorl272p9d8HRJSUkKCwvT+fPnFRoaWtrVKVR2draWLFmiO+64w+nZEQC4UtxjAJQ07jO4HmVkZOjgwYOqXr26/P39S7s6ZZ7ValVSUpJCQ0MdBosrDYX9bBQlhxbpKvz8/PTggw9q+fLl2rlzp+rXr68nn3xScXFxSklJKfpVAAAAAAAAu8v+qMHLy0smk0mGYchisRRnnQAAAAAAKJOKFNIzMzP16aefqkuXLqpTp462b9+u999/X/Hx8cyTDgAAAADAFXJ74Lgnn3xSCxYsUExMjAYMGKBPP/1U4eHhJVk3AAAAAADKFLdD+syZM1WtWjXVqFFDq1ev1urVq12W++qrr4qtcgAAAADgiZiWGvkV18+E2yH90UcfvWZGcAcAAACAkpA7U0FaWpoCAgJKuTbwJFlZWZIk8xVOped2SJ87d+4VnQgAAAAArnVms1nlypXTiRMnJEmBgYE0ZpYiq9WqrKwsZWRklOoUbFarVSdPnlRgYKC8vd2O2S5d2d4AAAAAUMZER0dLkj2oo/QYhqH09HQFBASU+oclXl5eqlat2hXXg5AOAAAAAEVgMplUqVIlRUZGKjs7u7SrU6ZlZ2frp59+Urt27eyPIpQWX1/fYmnNJ6QDAAAAwGUwm81X/PwxrozZbFZOTo78/f1LPaQXl9LrtA8AAAAAABwQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQpR7Sp0+frri4OPn7+6t169batGlToeXPnTunIUOGqFKlSvLz81OdOnW0ZMmSq1RbAAAAAABKjndpnnzhwoUaMWKEZs6cqdatW2vq1Knq1q2b9uzZo8jISKfyWVlZ6tKliyIjI/XFF1+oSpUqOnz4sMqVK3f1Kw8AAAAAQDEr1ZD+9ttva9CgQerfv78kaebMmfr22281e/ZsPf/8807lZ8+erTNnzmj9+vXy8fGRJMXFxRV6jszMTGVmZtpfJyUlSZKys7OVnZ1dTFdSMnLr5+n1BHBt4h4DoKRxnwFQ0q6V+0xR6mcyDMMowboUKCsrS4GBgfriiy/Uq1cv+/q+ffvq3Llz+t///ue0zx133KEKFSooMDBQ//vf/xQREaGHHnpIzz33nMxms8vzjB8/Xq+88orT+k8++USBgYHFdj0AAAAAALiSlpamhx56SOfPn1doaGihZUutJf3UqVOyWCyKiopyWB8VFaXdu3e73OfPP//UDz/8oIcfflhLlizR/v379eSTTyo7O1vjxo1zuc+YMWM0YsQI++ukpCTFxMSoa9eul3xzSlt2draWL1+uLl262HsOAEBx4R4DoKRxnwFQ0q6V+0xuj253lGp396KyWq2KjIzUBx98ILPZrObNm+vo0aOaPHlygSHdz89Pfn5+Tut9fHw8+puY17VUVwDXHu4xAEoa9xkAJc3T7zNFqVuphfTw8HCZzWYlJiY6rE9MTFR0dLTLfSpVqiQfHx+Hru1169ZVQkKCsrKy5OvrW6J1BgAAAACgJJXaFGy+vr5q3ry5Vq5caV9ntVq1cuVKtWnTxuU+bdu21f79+2W1Wu3r9u7dq0qVKhHQAQAAAADXvFKdJ33EiBH68MMPNW/ePO3atUuDBw9WamqqfbT3Rx99VGPGjLGXHzx4sM6cOaNhw4Zp7969+vbbb/XGG29oyJAhpXUJAAAAAAAUm1J9Jr137946efKkXn75ZSUkJKhJkyZaunSpfTC5+Ph4eXld/BwhJiZG33//vYYPH65GjRqpSpUqGjZsmJ577rnSugQAAAAAAIpNqQ8cN3ToUA0dOtTltlWrVjmta9OmjX7++ecSrhUAAAAAAFdfqXZ3BwAAAAAAFxHSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSAQAAAADwEIR0AAAAAAA8BCEdAAAAAAAPQUgHAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD0FIBwAAAADAQxDSPZRhsSht82aFbNmitM2bZVgspV0lAAAAAEAJ8y7tCsBZ0rJlSnxjonISElRJ0rFPF+hEdLSixo5RaNeupV09AAAAAEAJoSXdwyQtW6ajw55RTkKCw/qcxEQdHfaMkpYtK6WaAQAAAABKGiHdgxgWixLfmCgZhouNtnWJb0yk6zsAAAAAXKcI6R4k7ZdfnVrQHRiGchISlPbLr1evUgAAAACAq4aQ7kFyTp50q1zim2/q1AcfKnXjJllTU0u4VgAAAACAq4WB4zyId0SEW+Uy//hDJ//4w/bCy0t+deoooHFj29KksXzj4mTy4vMXAAAAALjWENI9SGCL5vKOjlZOYqLr59JNJpkrlFeF/gOUsX270rduVU5CgjJ371bm7t06t3ChJMkrNFQBjRrZQ3tAw4Yylyt3dS8GAAAAAFBkhHQPYjKbFTV2jI4Oe0YymRyDuskkSYoeN85hGrbshASlb92m9K1blb51qzJ27JA1KUmpa9cqde1aeznf6tUvhvbGjeVXu7ZM3nz7AQAAAMCTkNI8TGjXrtK0qfZ50nN5R0W5nCfdJzpaPtHRCu1mW29kZytjz16lb91iD+7Zh+OVdfCgsg4e1PlFiyRJpoAABTRoYA/tAY0bu93dHgAAAABQMgjpHii0a1eFdOqkpI0b9evy5WrepYtCW7eWyWy+5L4mHx8FNKivgAb1pYcfliTlnDmj9G221vaMrVuVvnWbrKmpStu8WWmbN9v39alc2SG0+9WrJy9f3xK7TgAAAACAI0K6hzKZzQps2VLJJ08qsGVLtwJ6QbwrVFBIhw4K6dBBkm0+9qw//7S3tKdv2arM/fuVfeyYso8dU9KS72x18PGRX726Fwela9xEPlUqy3Sh6z0AAAAAoHgR0ssgk9ksv9q15Ve7tsrde68kyZKSYh+MLn2LLbxbzp5VxtZtyti6TWf1X0mSOTw8T2hvrIAG9eUVFFSalwMAAAAA1w1COiRJ5uBgBbVpo6A2bSRJhmEo+8gRh9CesXu3LKdOKWXlSqWsXGnbkSngAAAAAKDYENLhkslkkm+1avKtVk1hPXtKkqwZGcrYudMe2pkCDgAAAACKFyEdbvPy91dgs2YKbNbMvo4p4AAAAACg+JCScEWYAg4AAAAAio9HhPTp06dr8uTJSkhIUOPGjfXee++pVatWLsvOnTtX/fv3d1jn5+enjIyMq1FVXILLKeDOnr3Y0s4UcAAAAABQoFIP6QsXLtSIESM0c+ZMtW7dWlOnTlW3bt20Z88eRUZGutwnNDRUe/bssb9mSjDP5l2+PFPAAQAAAChWhsWitM2bFbJli9IiIhTauvUVTV3tKUo9pL/99tsaNGiQvXV85syZ+vbbbzV79mw9//zzLvcxmUyKjo6+mtVEMWIKOAAAAABXImnZMiW+MVE5CQmqJOnYpwt0IjpaUWPHKLRr19Ku3hUp1ZCelZWlX3/9VWPGjLGv8/LyUufOnbVhw4YC90tJSVFsbKysVquaNWumN954Q/Xr13dZNjMzU5mZmfbXSUlJkqTs7GxlZ2cX05WUjNz6eXo9i4Wfn3xbtJBvixYKk20KuJy//rKF9G22JXPPHpdTwPnWri3/Ro3si09cLFPAAW4oU/cYAKWC+wyAkpCyYoUSRoyUDMNhfU5ioo4Oe0aWt6couHPnUqqda0W5D5ZqSD916pQsFouioqIc1kdFRWn37t0u97nhhhs0e/ZsNWrUSOfPn9dbb72lm2++WX/88YeqVq3qVH7ixIl65ZVXnNYvW7ZMgYGBxXMhJWz58uWlXYXS42WSmjSWmjSWKTtbfkePKiA+Xv7xR+QfHy+f8+eVtWePsvbsUdLnn0uSLAH+yoippoxqMUqvVk0ZMTGyXiPfa6A0lOl7DICrgvsMgGJjtar6pH/K2zDk9BCsYciQdGT8KzqYkSF5UMNdWlqa22VNhpHv44er6NixY6pSpYrWr1+vNm3a2Nc/++yzWr16tTZu3HjJY2RnZ6tu3bp68MEH9eqrrzptd9WSHhMTo1OnTik0NLR4LqSEZGdna/ny5erSpYt8fHxKuzoeKSchQRnbt19sbd+5S4aLQQR94uJsLe2Nba3tvrVqMQUcyjzuMQBKGvcZAIUxsrNlTUmRNTXVtuR+nZIia0qqrGmptn9TU+z/Zh89pqydOy957MqzZymwZcurcBXuSUpKUnh4uM6fP3/JHFqqKSU8PFxms1mJiYkO6xMTE91+5tzHx0dNmzbV/v37XW738/OTn5+fy/2ulf9ZXEt1vdp8YmIUEBMj3XGHpAtTwO3dq/QtjlPAZR86pOxDh5S8eLEkpoAD8uIeA6CkcZ8Brh+G1SprWvqFYJ1yIVCnyJIbrPOst6/LLZMbui+8NrKySq6iZ8561H2nKHUp1ZDu6+ur5s2ba+XKlerVq5ckyWq1auXKlRo6dKhbx7BYLNq+fbvuuBDSULaZfHwUUL++Auo7TwGXsW2bbVC6bdtkTUlhCjgAAACUGUZWlix5W6zzh+gL4Tp/sLampsqS6lgu/7PgV8oUECCv4CCZA4PkFRxsX8zBQfIKCpZXUO76IOUkJur0Bx9e8pjXcgNcqff3HTFihPr27asWLVqoVatWmjp1qlJTU+2jvT/66KOqUqWKJk6cKEmaMGGCbrrpJtWqVUvnzp3T5MmTdfjwYT322GOleRnwYE5TwFmtF6eAuzCSfOa+fUwBBwAAAI9y2a3W+YN1SbRam822IB0UlCdE24K0OTjYKVybc7dfWG8OvrAtKKhIj6EaFovOL/4/5SQmuv6wwGSSd1SUAls0L8aLvbpKPaT37t1bJ0+e1Msvv6yEhAQ1adJES5cutQ8mFx8fL688D/yfPXtWgwYNUkJCgsqXL6/mzZtr/fr1qlevXmldAq4xJi8v+dWqJb9atVTunnskXZgCbscOe2hP37KFKeAAAABwWQpttbY/e13KrdYOITpPq3Vw7vp8wTo4WF5BgfZ1Jn//Umm8MpnNiho7RkeHPSOZTI7vz4X6RI0dc03Pl16qA8eVhqSkJIWFhbn1wH5py87O1pIlS3THHXd41PMUZYFhGMr+66+LoX3rVmXs2iXl5DgW9PKSX506F0N7k8byjYtjCjhcE7jHAChp3GdwLTEMQ0Zamiwp11mrdXCQbb/LaLX2ZHnnSc/l7cHzpBclh14f3yGgmJlMJvnGxMg3JkZhPe+UJFkzMpSxc5c9tKdv3aqc48eVuXu3Mnfv1rmFCyVJXqGhCmjUyB7aAxo2lLlcuVK8GgAAgOvXZbVaX1h/VVutgy8G6Wul1dqThXbtqpBOnZS0caN+Xb5czbt0UWjr1td0C3ouQjrgJi9/fwU2a6rAZk3t67ITEx1Ce8aOP2RNSlLq2rVKXbvWXs63evWLob1xY/nVrn3dfIoJAABQVIW2Wqem2YN1qbdaB7tooS40XOeWCbquWq09lclsVmDLlko+eVKBLVteFwFdIqQDV8QnKko+Xbvau9TYp4DbulUZFwamyzp8WFkHDyrr4EGdX7RIkvMUcP6NGsknMrIUrwQAAODSCmy1Ts0ztZYnt1rna6HOXW8rE0SrNTwCIR0oRg5TwD30kCTbFHAZ27ZdHE2eKeAAAMBVdFmt1q6C9dVotc7fQm0P10EXRgSn1RrXP36SgRLmXb68gtu3V3D79pKYAg4AALinyK3Wectd7Vbr4DzTauVd5zBoWZ5W69xBzGi1BpwQ0oGrzK0p4LZuleXMGddTwOUOSte4sQIaNmAKOACARzIsFqVt3qyQLVuUFhFx3QzodCkFtlrnC9Ye02qdt4U6T6u1OU93cYdW6+BgeQUG0moNlCB+uwAPYA4OVtBNNynoppskFTwFnOXUKaX88INSfvjBtqOXl/xq13acAq56daaAAwCUqrxTI1WSdOzTBTrhwVMjSddgq3VuC3X+dfbu3/larYODZfLzo9UauAYQ0gEPVKQp4PbsUeaePTr32WeSJK+QkIut7U2bMAUcAOCqSlq2TEeHPeMUVHMSE23rp00ttqBe5Fbr3OevXQRrIzOzWOpkR6s1gMvEbzxwjXB7CrjkZKWuW6fUdevs5Xzj4hyngKtTh//hAwCKnWGxKPGNia5bkg1DMpmU+MZEBd96q6wZGQ6t0dbU1HwjgrtoyabVGkAZwF/pwDXM7SngDh1S1qFDOv+//0m6MAVc/foKaNJY/he6yjMFHADgchiGIWtysnJOnFDKTz8pJyGhsMLKSUjQnqbNircSBbRa5w/RjnNaB9FqDcAjcRcCriNFmgLul1+U9ssv9n29K1fKM5J8Y/nXqycvP7/SuhQAQCkzDEPW1FTlnDhxcTl5UjknTij7xAnlnDhpX2dkZFzWOUyBgbY5q51arfN0/84frgODaLUGcF0jpAPXOXengMs5dlzJx44r+bulth19fORft67DoHQ+VarwRxAAXAesqakXg/aF4J13yT55QjknT8lIS3P7mOawMHkFByn76LFLlq06418KvvVWWq0BwAXujEAZ43oKuFRl7NjuPAXctm3K2LZNZ/97YQq4ihUdWtuZAg4APIs1Pd2h1duhxTtPS7g1NdXtY3qFhso7IkLekRHyiYyUd2SkvCMi5R0ZYfs6MlLeERHy8vOTYbFof6fOyklMdP2suMkk76goBbdrVyamYwOAy0FIByBzcJB7U8CdPs0UcABQCqwZGRdbvPO0fOdvDbcmJ7t9TK+goIshO/JC6I7IE8Rzw3dAgNvHNJnNiho7xjaKu8nkGNQv9MSKGjuGgA4AhSCkA3BSbFPANWmsgEaNmAIOAApgzcq6ELLztXifOGFbd/Kksk+clPX8ebePaQoMlE9EhGMAt7++EMIjIkqsJ1Ro167StKn2edJzeUdFefQ86QDgKQjpANzCFHAA4D4jK0s5p07l6XLuONBabhC3nDvn9jFN/v75gnaeLucRFwO5Obj0H0MK7dpVIZ06KWnjRv26fLmad+mi0NataUEHADfwVzKAy8YUcADKGiM7WzmnT7vocp4bvm3rLWfOuH1Mk6+vi1ZvF93OQ0KuqcE7TWazAlu2VPLJkwps2ZKADgBuIqQDKDZMAQfgWmVYLLbw7arL+YmTttHOT5yU5fRp1wOiueLjc7Hbef7u53m7nYeFXVPhGwBQsgjpAEoUU8ABKE2G1SrLmTOOLd6uph07fVqyWt07qLe3vbXbYaC1iDwDsEVGylyuHPcsAECREdIBXFWXnAJu2zalb9ni1hRw/g0aeMSzlwCuPsNqleXcOce5vfN1Oc85cUI5p05JFot7BzWb5R0e7tDl3DsyMk8IvxC+y5dnFgsAQIkhpAModS6ngDt6lCnggDLIMIwL4fukU5fznJOOU44pJ8e9g3p5ybtiRZddznPX+URGylyhAs9NAwBKHSEdgMcxmUzyrVpVvlWrKuzOHpIka2amMnbudJwC7hhTwAHXCsMwZE1Kcjm3t+Mz4CdlZGe7d1CTSeYKFVyMeJ4bwC98XbECM0oAAK4Z/B8LwDXBy89PgU2bKrBp3ingTih928WR5NN37GAKOOAqMwxD1pQUp6BtD+J5w3dmptvHNZcv79jifaG7ucOI5xUryuTjU4JXBwDA1cdfqQCuWT5RkfLp0kWhXbpIsk2NlLlvn8OgdLnTvzEFHFB0lpRU5y7nF77O2xpupKe7fUxzWFi+LucuphwLD5fJ17cErwwAAM9FSAdw3TD5+Mi/Xj3516un8g8+KOnCFHDbt198vn3bNlmTk5kCDmWaNS2t4IHW7OtOyJqW5vYxvUJD83U5z9Pd3B7Gw/m9AgDgEgjpAK5r3uXLK7hdOwW3ayfpwhRwBw86DErHFHC4XljT0y8+533hX4du57nhOyXF7WN6BQc7DbTm46Il3MvfvwSvDACAsoOQDqBMMXl5ya9mTfnVrKly9/xdUu4UcDsuDkrHFHDwMNbMzDyDrJ3M0/3csTXcmpTk9jFNgYFOU4s5DMCWG74DA0vwygAAQH6EdABlnm0KuNYKuqm1JKaAw9VjZGXZArargdbytHxbzp93+5gmf395R0XKp8Au5xfm+uYDJgAAPBIhHQDyYQo4XCkjO1s5p07l63LuPO2Y5exZt49p8vPL1+od4bIl3Cs4mMcyAAC4hhHSAcANTAEHSTJycpRz+vSFsH2xxTv/AGyWM2ckw3DrmCYfn3zdzV0//+0VGkr4BgCgDOCvRAC4TEwBd/0wLBZZzpxxbPHO090858QJZZ88Icup026Hb3l7O04tFuH6+W9zuXKEbwAAYEdIB4BiwhRwnsewWmU5e9axxdvVtGOnT0sWi3sHNZvlHR7uPNBavtZwc7lyjE8AAACKjJAOACWIKeBKhmEYspw75zjI2oXw7TAA26lTUk6Oewf18pJ3xYouBlmzhe/cbufm8uVlMptL9gIBAECZRUgHgKvIrSngtm6V5fTpMjkFnGEYsp4/7zzSeb5u5zknT0nZ2e4d1GSSuWJFW4u3yy7nF57/rliR8A0AAEodIR0ASllpTAFnWCxK27xZIVu2KC0iQqGtW5doQDUMQ9bk5AIHWssbxo2sLLePa65QwWGQtbwt3vYwXrGiTD4+JXZtAAAAxYmQDgAepjingPNv2FDe5cs7HD9p2TIlvjFROQkJqiTp2KcLdCI6WlFjxyi0a9ci1dUwDFlTU13O7Z2dbwA2IyPD7eOay5Vzmtfbodt5RIS8w8Nl8vUtUn0BAAA8HSEdAK4BxTUFnDU9XScmv+U0QnlOYqKODntGmjbVHtStqalOQTtvGM/tdm6kpbl/HWFh8slt9Y5wNeVYpLwjwhk0DwAAlFmEdAC4RjlNAZeTo8y9ey85BZxLF0L7sVGjdaLyO7KcPClraqrbdfEKCXEYaM2py/mFf738/a/omgEAAK53hHQAuE6YvL0LnQIu5aeflLFjR6HHMLKylH3okP21V1CQ60HWIvIE8YgIeQUGluSlAQAAlBmEdAC4juWdAs63Rg0dGzXqkvtUfOIJhd19l7wjIq+70eMBAAA8HSEdAMoI74gIt8oFtWkjv+rVS7g2AAAAcOXS8/QAAK4LgS2ayzs6WjKZXBcwmeQdHa3AFs2vbsUAAABgR0gHgDLCZDYrauyYCy/yBfULr6PGjinR+dIBAABQOEI6AJQhoV27qsq0qfKOinJY7x0VpSp5pl8DAABA6eCZdAAoY0K7dlVIp05K2rhRvy5fruZduii0dWta0AEAADwAIR0AyiCT2azAli2VfPKkAlu2JKADAAB4CLq7AwAAAADgIQjpAAAAAAB4CEI6AAAAAAAegpAOAAAAAICHIKQDAAAAAOAhCOkAAAAAAHgIQjoAAAAAAB6CkA4AAAAAgIcgpAMAAAAA4CEI6QAAAAAAeAhCOgAAAAAAHoKQDgAAAACAhyCkAwAAAADgIQjpAAAAAAB4CEI6AAAAAAAegpAOAAAAAICHIKQDAAAAAOAhCOkAAAAAAHgIQjoAAAAAAB6CkA4AAAAAgIfwLu0KXG2GYUiSkpKSSrkml5adna20tDQlJSXJx8entKsD4DrDPQZASeM+A6CkXSv3mdz8mZtHC1PmQnpycrIkKSYmppRrAgAAAAAoS5KTkxUWFlZoGZPhTpS/jlitVh07dkwhISEymUylXZ1CJSUlKSYmRkeOHFFoaGhpVwfAdYZ7DICSxn0GQEm7Vu4zhmEoOTlZlStXlpdX4U+dl7mWdC8vL1WtWrW0q1EkoaGhHv0DB+Daxj0GQEnjPgOgpF0L95lLtaDnYuA4AAAAAAA8BCEdAAAAAAAPQUj3YH5+fho3bpz8/PxKuyoArkPcYwCUNO4zAEra9XifKXMDxwEAAAAA4KloSQcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhvRQcOnRIJpNJW7ZscXufuXPnqly5cqVeDwDXnlWrVslkMuncuXOlXRUAAABcAiH9Chw5ckQDBgxQ5cqV5evrq9jYWA0bNkynT58udL+YmBgdP35cDRo0cPtcvXv31t69e6+0ygA8UL9+/WQymfTEE084bRsyZIhMJpP69et39St2GcaPH68mTZqUdjUAXIaTJ09q8ODBqlatmvz8/BQdHa1u3bpp3bp1pV01ANeY3L9t8i/du3d3a/8OHTromWeeKdlKejDv0q7AterPP/9UmzZtVKdOHX366aeqXr26/vjjD40ePVrfffedfv75Z1WoUMFpv6ysLPn6+io6OrpI5wsICFBAQEBxVR+Ah4mJidGCBQv0zjvv2H/XMzIy9Mknn6hatWqlXLuL9y4A16977rlHWVlZmjdvnmrUqKHExEStXLnyko0PJYl7D3Dt6t69u+bMmeOwrjinSTMMQxaLRd7e11+kpSX9Mg0ZMkS+vr5atmyZ2rdvr2rVqun222/XihUrdPToUb3wwguSpLi4OL366qt69NFHFRoaqn/84x8uu5kvXrxYtWvXlr+/vzp27Kh58+Y5dE/N3909t7Xqv//9r+Li4hQWFqYHHnhAycnJ9jJLly7VLbfconLlyqlixYq68847deDAgavx9gAoombNmikmJkZfffWVfd1XX32latWqqWnTpvZ1mZmZevrppxUZGSl/f3/dcsst2rx5s8OxlixZojp16iggIEAdO3bUoUOHnM63du1a3XrrrQoICFBMTIyefvpppaam2re7undJ0nPPPac6deooMDBQNWrU0EsvvaTs7GxJtvvUK6+8oq1bt9o/MZ87d64k6dy5c3rssccUERGh0NBQ3Xbbbdq6dWtxvX0ArtC5c+e0Zs0a/fOf/1THjh0VGxurVq1aacyYMbrrrrvsZQr6Pd67d69MJpN2797tcNx33nlHNWvWtL/esWOHbr/9dgUHBysqKkqPPPKITp06Zd/eoUMHDR06VM8884zCw8PVrVs3t/YD4Hlye+TkXcqXL69Vq1bJ19dXa9assZd98803FRkZqcTERPXr10+rV6/WtGnT7H9PHDp0yP743nfffafmzZvLz89Pa9euldVq1cSJE1W9enUFBASocePG+uKLL+zHzt3v+++/V9OmTRUQEKDbbrtNJ06c0Hfffae6desqNDRUDz30kNLS0uz7Xeq4JYmQfhnOnDmj77//Xk8++aRT63Z0dLQefvhhLVy4ULlT0L/11ltq3Lixfv/9d7300ktOxzt48KDuvfde9erVS1u3btXjjz9uD/mFOXDggBYtWqRvvvlG33zzjVavXq1JkybZt6empmrEiBH65ZdftHLlSnl5eelvf/ubrFbrFb4DAErCgAEDHD5xnj17tvr37+9Q5tlnn9WXX36pefPm6bffflOtWrXUrVs3nTlzRpLtMZy///3v6tmzp7Zs2aLHHntMzz//vMMxDhw4oO7du+uee+7Rtm3btHDhQq1du1ZDhw51KOfq3hUSEqK5c+dq586dmjZtmj788EO98847kmyP5YwcOVL169fX8ePHdfz4cfXu3VuSdN9999n/Z/jrr7+qWbNm6tSpk73eAEpXcHCwgoODtWjRImVmZrosU9jvcZ06ddSiRQvNnz/fYZ/58+froYcekmQL+bfddpuaNm2qX375RUuXLlViYqLuv/9+h33mzZsnX19frVu3TjNnznR7PwDXhtyu7I888ojOnz9v/zvjo48+UlRUlKZNm6Y2bdpo0KBB9r8nYmJi7Ps///zzmjRpknbt2qVGjRpp4sSJ+s9//qOZM2fqjz/+0PDhw9WnTx+tXr3a4bzjx4/X+++/r/Xr1+vIkSO6//77NXXqVH3yySf69ttvtWzZMr333nv28u4et0QYKLKff/7ZkGR8/fXXLre//fbbhiQjMTHRiI2NNXr16uWw/eDBg4Yk4/fffzcMwzCee+45o0GDBg5lXnjhBUOScfbsWcMwDGPOnDlGWFiYffu4ceOMwMBAIykpyb5u9OjRRuvWrQus98mTJw1Jxvbt213WA0Dp6Nu3r3H33XcbJ06cMPz8/IxDhw4Zhw4dMvz9/Y2TJ08ad999t9G3b18jJSXF8PHxMebPn2/fNysry6hcubLx5ptvGoZhGGPGjDHq1avncPznnnvO4X4ycOBA4x//+IdDmTVr1hheXl5Genq6YRiGy3uXK5MnTzaaN29ufz1u3DijcePGTscODQ01MjIyHNbXrFnT+Pe//33JcwC4Or744gujfPnyhr+/v3HzzTcbY8aMMbZu3WoYhnu/x++8845Rs2ZN+7Y9e/YYkoxdu3YZhmEYr776qtG1a1eH/Y8cOWJIMvbs2WMYhmG0b9/eaNq0qUMZd/YD4Fn69u1rmM1mIygoyGF5/fXXDcMwjMzMTKNJkybG/fffb9SrV88YNGiQw/7t27c3hg0b5rDuxx9/NCQZixYtsq/LyMgwAgMDjfXr1zuUHThwoPHggw867LdixQr79okTJxqSjAMHDtjXPf7440a3bt3cPm5Juv468F9FxoWW8ktp0aJFodv37Nmjli1bOqxr1arVJY8bFxenkJAQ++tKlSrpxIkT9tf79u3Tyy+/rI0bN+rUqVP2FvT4+PgiDVoH4OqIiIhQjx49NHfuXBmGoR49eig8PNy+/cCBA8rOzlbbtm3t63x8fNSqVSvt2rVLkrRr1y61bt3a4bht2rRxeL1161Zt27bNocXLMAxZrVYdPHhQdevWleT63rVw4UK9++67OnDggFJSUpSTk6PQ0NBCr2vr1q1KSUlRxYoVHdanp6fzCA7gQe655x716NFDa9as0c8//6zvvvtOb775pj766COlpqZe8vf4gQce0KhRo/Tzzz/rpptu0vz589WsWTPdeOONkmz3gh9//FHBwcFO5z5w4IDq1KkjSWrevLnDNnf3A+BZOnbsqBkzZjisyx2zy9fXV/Pnz1ejRo0UGxtr75Xnjrx/n+zfv19paWnq0qWLQ5msrCyHxwUlqVGjRvavo6Ki7I/u5V23adOmIh+3JBDSL0OtWrVkMpm0a9cu/e1vf3PavmvXLpUvX14RERGSpKCgoBKph4+Pj8Nrk8nk0JW9Z8+eio2N1YcffqjKlSvLarWqQYMGysrKKpH6ALhyAwYMsHc7nz59eomcIyUlRY8//riefvppp215B6nLf+/asGGDHn74Yb3yyivq1q2bwsLCtGDBAk2ZMuWS56tUqZJWrVrltK24p5YEcGX8/f3VpUsXdenSRS+99JIee+wxjRs3Tk8++eQlf4+jo6N122236ZNPPtFNN92kTz75RIMHD7aXS0lJUc+ePfXPf/7T6RiVKlWyf53/3uPufgA8S1BQkGrVqlXg9vXr10uyPUp85swZtzNT3nIpKSmSpG+//VZVqlRxKJd/kLq82clkMhWapYpy3JJASL8MFStWVJcuXfSvf/1Lw4cPd3guPSEhQfPnz9ejjz4qk8nk1vFuuOEGLVmyxGFd/oGgiur06dPas2ePPvzwQ916662SbANFAfBs3bt3V1ZWlkwmk33ApFw1a9a0P6cZGxsrScrOztbmzZvt05TUrVtXixcvdtjv559/dnjdrFkz7dy5s9D/cbqyfv16xcbGOoyZcfjwYYcyvr6+slgsTudLSEiQt7e34uLiinROAKWrXr16WrRokdu/xw8//LCeffZZPfjgg/rzzz/1wAMP2Lc1a9ZMX375peLi4oo0GvPl7gfAcx04cEDDhw/Xhx9+qIULF6pv375asWKFvLxsQ6a5+nvClXr16snPz0/x8fFq3759sdWvpI7rLgaOu0zvv/++MjMz1a1bN/300086cuSIli5dqi5duqhKlSp6/fXX3T7W448/rt27d+u5557T3r179dlnn9lHRHY36OdXvnx5VaxYUR988IH279+vH374QSNGjLisYwG4esxms3bt2qWdO3fKbDY7bAsKCtLgwYM1evRoLV26VDt37tSgQYOUlpamgQMHSpKeeOIJ7du3T6NHj9aePXv0ySef2O8nuZ577jmtX79eQ4cO1ZYtW7Rv3z7973//cxo4Lr/atWsrPj5eCxYs0IEDB/Tuu+/q66+/digTFxengwcPasuWLTp16pQyMzPVuXNntWnTRr169dKyZct06NAhrV+/Xi+88IJ++eWXK3/TAFyx06dP67bbbtPHH3+sbdu26eDBg/r888/15ptv6u6773b79/jvf/+7kpOTNXjwYHXs2FGVK1e2bxsyZIjOnDmjBx98UJs3b9aBAwf0/fffq3///oX+MX65+wEoXZmZmUpISHBYTp06JYvFoj59+qhbt27q37+/5syZo23btjn0zIuLi9PGjRt16NAhh8d28wsJCdGoUaM0fPhwzZs3TwcOHNBvv/2m9957T/PmzbvsupfUcd1FSL9MtWvX1i+//KIaNWro/vvvV82aNfWPf/xDHTt21IYNG1zOkV6Q6tWr64svvtBXX32lRo0aacaMGfaWqsvtTuHl5aUFCxbo119/VYMGDTR8+HBNnjz5so4F4OoKDQ0t8DnvSZMm6Z577tEjjzyiZs2aaf/+/fr+++9Vvnx5Sbbu6l9++aUWLVqkxo0ba+bMmXrjjTccjtGoUSOtXr1ae/fu1a233qqmTZvq5Zdfdvhj2pW77rpLw4cP19ChQ9WkSROtX7/eacaKe+65R927d1fHjh0VERGhTz/9VCaTSUuWLFG7du3Uv39/1alTRw888IAOHz6sqKioK3inABSX4OBgtW7dWu+8847atWunBg0a6KWXXtKgQYP0/vvvu/17HBISop49e2rr1q16+OGHHc5RuXJlrVu3ThaLRV27dlXDhg31zDPPqFy5cvbWM1cudz8ApWvp0qWqVKmSw3LLLbfo9ddf1+HDh/Xvf/9bku2xlQ8++EAvvviifVrHUaNGyWw2q169eoqIiFB8fHyB53n11Vf10ksvaeLEiapbt666d++ub7/9VtWrV7+i+pfUcd1hMtwd/QxX1euvv66ZM2fqyJEjpV0VAAAAAMBVwoM9HuJf//qXWrZsqYoVK2rdunWaPHnyJbueAgAAAACuL4R0D7Fv3z699tprOnPmjKpVq6aRI0dqzJgxpV0tAAAAAMBVRHd3AAAAAAA8BKNtAAAAAADgIQjpAAAAAAB4CEI6AAAAAAAegpAOAAAAAICHIKQDAAAAAOAhCOkAAHiQfv36qVevXkXaJy4uTlOnTi2R+pQlHTp00DPPPGN/7c77On78eDVp0qRE6wUAKFsI6QCA687lBN3iFBcXJ5PJJJPJJLPZrMqVK2vgwIE6e/bsJfedNm2a5s6dW6z1OXTokEwmk7Zs2VKsxy0JCQkJeuqpp1SjRg35+fkpJiZGPXv21MqVK696XTZv3qx//OMf9tcmk0mLFi1yKDNq1KhSqRsA4PpFSAcAoARMmDBBx48fV3x8vObPn6+ffvpJTz/9dIHlLRaLrFarwsLCVK5cuatXUQ9y6NAhNW/eXD/88IMmT56s7du3a+nSperYsaOGDBly1esTERGhwMDAQssEBwerYsWKV6lGAICygJAOAChzVq9erVatWsnPz0+VKlXS888/r5ycHEnSN998o3LlyslisUiStmzZIpPJpOeff96+/2OPPaY+ffoUeo6QkBBFR0erSpUq6tixo/r27avffvvNvn3u3LkqV66cFi9erHr16snPz0/x8fFOvQCSk5P18MMPKygoSJUqVdI777zj1C1bktLS0jRgwACFhISoWrVq+uCDD+zbqlevLklq2rSpTCaTOnToIOlij4O33npLlSpVUsWKFTVkyBBlZ2fb983MzNSoUaNUpUoVBQUFqXXr1lq1apV9++HDh9WzZ0+VL19eQUFBql+/vpYsWSJJOnv2rB5++GFFREQoICBAtWvX1pw5cwp8z5588kmZTCZt2rRJ99xzj+rUqaP69etrxIgR+vnnn+3l4uPjdffddys4OFihoaG6//77lZiYaN+e2wX9v//9r+Li4hQWFqYHHnhAycnJ9jKpqal69NFHFRwcrEqVKmnKlClO9cnb3T0uLk6S9Le//U0mk8n+On93d6vVqgkTJqhq1ary8/NTkyZNtHTpUvv23F4NX331lTp27KjAwEA1btxYGzZsKPB9AQCULYR0AECZcvToUd1xxx1q2bKltm7dqhkzZmjWrFl67bXXJEm33nqrkpOT9fvvv0uyBfrw8HCHYLp69Wp70HX3nP/3f/+n1q1bO6xPS0vTP//5T3300Uf6448/FBkZ6bTviBEjtG7dOi1evFjLly/XmjVrHMJ+rilTpqhFixb6/fff9eSTT2rw4MHas2ePJGnTpk2SpBUrVuj48eP66quv7Pv9+OOPOnDggH788UfNmzdPc+fOdehuP3ToUG3YsEELFizQtm3bdN9996l79+7at2+fJGnIkCHKzMzUTz/9pO3bt+uf//yngoODJUkvvfSSdu7cqe+++067du3SjBkzFB4e7vI9OnPmjJYuXaohQ4YoKCjIaXtu7wKr1aq7775bZ86c0erVq7V8+XL9+eef6t27t0P5AwcOaNGiRfrmm2/0zTffaPXq1Zo0aZJ9++jRo7V69Wr973//07Jly7Rq1SqX72uuzZs3S5LmzJmj48eP21/nN23aNE2ZMkVvvfWWtm3bpm7duumuu+6yv1+5XnjhBY0aNUpbtmxRnTp19OCDD9o/KAIAlHEGAADXmb59+xp33323y21jx441brjhBsNqtdrXTZ8+3QgODjYsFothGIbRrFkzY/LkyYZhGEavXr2M119/3fD19TWSk5ONv/76y5Bk7N27t8Dzx8bGGr6+vkZQUJDh7+9vSDJat25tnD171l5mzpw5hiRjy5YtBdY9KSnJ8PHxMT7//HP79nPnzhmBgYHGsGHDHM7Xp08f+2ur1WpERkYaM2bMMAzDMA4ePGhIMn7//Xenc8XGxho5OTn2dffdd5/Ru3dvwzAM4/Dhw4bZbDaOHj3qsF+nTp2MMWPGGIZhGA0bNjTGjx/v8n3o2bOn0b9//wLfp7w2btxoSDK++uqrQsstW7bMMJvNRnx8vH3dH3/8YUgyNm3aZBiGYYwbN84IDAw0kpKS7GVGjx5ttG7d2jAMw0hOTjZ8fX2Nzz77zL799OnTRkBAgNP7+s4779hfSzK+/vprh/qMGzfOaNy4sf115cqVjddff92hTMuWLY0nn3zSMIyL34uPPvrIqf67du0q9NoBAGUDLekAgDJl165datOmjUwmk31d27ZtlZKSor/++kuS1L59e61atUqGYWjNmjX6+9//rrp162rt2rVavXq1KleurNq1axd6ntGjR2vLli3atm2bfWCxHj162LvRS5Kvr68aNWpU4DH+/PNPZWdnq1WrVvZ1YWFhuuGGG5zK5j2OyWRSdHS0Tpw4cYl3Q6pfv77MZrP9daVKlez7bd++XRaLRXXq1FFwcLB9Wb16tQ4cOCBJevrpp/Xaa6+pbdu2GjdunLZt22Y/1uDBg7VgwQI1adJEzz77rNavX19gPQzDuGRdJdv3LyYmRjExMfZ19erVU7ly5bRr1y77uri4OIWEhLi8rgMHDigrK8uhZ0OFChVcvq9FkZSUpGPHjqlt27YO69u2betQN8nx+1WpUiVJcuv7BQC4/hHSAQDIp0OHDlq7dq22bt0qHx8f3XjjjerQoYNWrVql1atXq3379pc8Rnh4uGrVqqXatWvrtttu09SpU7V+/Xr9+OOP9jIBAQEOHxZcCR8fH4fXJpNJVqv1ivZLSUmR2WzWr7/+qi1bttiXXbt2adq0aZJsz+f/+eefeuSRR7R9+3a1aNFC7733niTp9ttv1+HDhzV8+HAdO3ZMnTp10qhRo1zWo3bt2jKZTNq9e3eRr72o1+UJ8tYv92fAk+oHACg9hHQAQJlSt25dbdiwwaHldt26dQoJCVHVqlUlXXwu/Z133rEH8tyQvmrVqiI9j54rt7U6PT3d7X1q1KghHx8fh+efz58/r7179xbp3L6+vpLk0IrvjqZNm8pisejEiROqVauWwxIdHW0vFxMToyeeeEJfffWVRo4cqQ8//NC+LSIiQn379tXHH3+sqVOnOgxol1eFChXUrVs3TZ8+XampqU7bz507J8n2/Tty5IiOHDli37Zz506dO3dO9erVc+u6atasKR8fH23cuNG+7uzZs5d8X318fAp9D0NDQ1W5cmWtW7fOYf26devcrhsAAN6lXQEAAErC+fPnneYFr1ixop588klNnTpVTz31lIYOHao9e/Zo3LhxGjFihLy8bJ9dly9fXo0aNdL8+fP1/vvvS5LatWun+++/X9nZ2W61pCcnJyshIUGGYejIkSN69tlnFRERoZtvvtntawgJCVHfvn01evRoVahQQZGRkRo3bpy8vLyK1AIfGRmpgIAALV26VFWrVpW/v7/CwsIuuV+dOnX08MMP69FHH9WUKVPUtGlTnTx5UitXrlSjRo3Uo0cPPfPMM7r99ttVp04dnT17Vj/++KPq1q0rSXr55ZfVvHlz1a9fX5mZmfrmm2/s21yZPn262rZtq1atWmnChAlq1KiRcnJytHz5cs2YMUO7du1S586d1bBhQz388MOaOnWqcnJy9OSTT6p9+/Zq0aKFW+9HcHCwBg4cqNGjR6tixYqKjIzUCy+8YP/+FyQuLk4rV65U27Zt5efnp/LlyzuVGT16tMaNG6eaNWuqSZMmmjNnjrZs2aL58+e7VTcAAGhJBwBcl1atWqWmTZs6LK+88oqqVKmiJUuWaNOmTWrcuLGeeOIJDRw4UC+++KLD/u3bt5fFYrG3mleoUEH16tVTdHS0W88uv/zyy6pUqZIqV66sO++8U0FBQVq2bFmR59R+++231aZNG915553q3Lmz2rZtq7p168rf39/tY3h7e+vdd9/Vv//9b1WuXFl333232/vOmTNHjz76qEaOHKkbbrhBvXr10ubNm1WtWjVJttb5IUOGqG7duurevbvq1Kmjf/3rX5JsLfhjxoxRo0aN1K5dO5nNZi1YsKDAc9WoUUO//fabOnbsqJEjR6pBgwbq0qWLVq5cqRkzZkiydQ3/3//+p/Lly6tdu3bq3LmzatSooYULF7p9TZI0efJk3XrrrerZs6c6d+6sW265Rc2bNy90nylTpmj58uWKiYlR06ZNXZZ5+umnNWLECI0cOVINGzbU0qVLtXjx4kuOYQAAQC6T4e5ILQAAoNSlpqaqSpUqmjJligYOHFja1QEAAMWM7u4AAHiw33//Xbt371arVq10/vx5TZgwQZKK1BoOAACuHYR0AAA83FtvvaU9e/bI19dXzZs315o1axQeHl7a1QIAACWA7u4AAAAAAHgIBo4DAAAAAMBDENIBAAAAAPAQhHQAAAAAADwEIR0AAAAAAA9BSAcAAAAAwEMQ0gEAAAAA8BCEdAAAAAAAPAQhHQAAAAAAD/H/wV8Wd0e+2IUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# YOLO 평가 결과에서 메트릭을 추출합니다.\n",
        "def extract_metrics(result):\n",
        "    metrics = {\n",
        "        \"Precision (P)\": result.box.p,  # 단일 값으로 사용\n",
        "        \"Recall (R)\": result.box.r,     # 단일 값으로 사용\n",
        "        \"mAP50\": result.box.map50,      # 단일 값으로 사용\n",
        "        \"mAP50-95\": result.box.map      # 단일 값으로 사용\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# 각 결과로부터 메트릭을 추출합니다.\n",
        "metrics_original = extract_metrics(results_original)\n",
        "metrics_moderate = extract_metrics(results_moderate)\n",
        "metrics_severe = extract_metrics(results_severe)\n",
        "metrics_extreme = extract_metrics(results_extreme)\n",
        "\n",
        "# 결과를 데이터프레임에 저장합니다.\n",
        "data = {\n",
        "    \"Condition\": [\"Original\", \"Moderate\", \"Severe\", \"Extreme\"],\n",
        "    \"Precision (P)\": [metrics_original[\"Precision (P)\"], metrics_moderate[\"Precision (P)\"], metrics_severe[\"Precision (P)\"], metrics_extreme[\"Precision (P)\"]],\n",
        "    \"Recall (R)\": [metrics_original[\"Recall (R)\"], metrics_moderate[\"Recall (R)\"], metrics_severe[\"Recall (R)\"], metrics_extreme[\"Recall (R)\"]],\n",
        "    \"mAP50\": [metrics_original[\"mAP50\"], metrics_moderate[\"mAP50\"], metrics_severe[\"mAP50\"], metrics_extreme[\"mAP50\"]],\n",
        "    \"mAP50-95\": [metrics_original[\"mAP50-95\"], metrics_moderate[\"mAP50-95\"], metrics_severe[\"mAP50-95\"], metrics_extreme[\"mAP50-95\"]],\n",
        "}\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 결과 출력 (확인용)\n",
        "print(df)\n",
        "\n",
        "# 메트릭 비교를 위한 시각화\n",
        "metrics = [\"Precision (P)\", \"Recall (R)\", \"mAP50\", \"mAP50-95\"]\n",
        "x = df[\"Condition\"]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# 각 메트릭을 플롯으로 그립니다.\n",
        "for metric in metrics:\n",
        "    plt.plot(x, df[metric], marker='o', label=metric)\n",
        "\n",
        "# 라벨 및 제목 설정\n",
        "plt.xlabel(\"Low Brightness Condition\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Comparison of Evaluation Metrics Across Different Low Brightness Conditions\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ]
}