{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **yaml 작성**\n",
        "\n",
        "*   data_origin.yaml\n",
        "*   data_moderate.yaml\n",
        "*   data_severe.yaml\n",
        "*   data_extreme.yaml\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jvEvHmAHs3wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRVAj-8AqGdu",
        "outputId": "b62b2019-ec58-45f1-9ea5-99de61c69c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_origin.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/images\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OGd9gShs98l",
        "outputId": "482d5606-30dd-4e52-90eb-e4f26dc1d5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/images\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_moderate.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_Nkgm65tcjF",
        "outputId": "4c4128b1-f667-4f2b-e199-21c954dbee0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_severe.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaGKZ_-tuuze",
        "outputId": "f2f5fb2d-b5c1-432a-c243-59f305c13933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_extreme.yaml 파일 작성\n",
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme\n",
        "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Human pose estimation']\n",
        "\n",
        "roboflow:\n",
        "  workspace: project-wk4fq\n",
        "  project: cctv-people\n",
        "  version: 1\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "with open('/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 저장된 파일 확인\n",
        "!cat /content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9wLWLkMu51h",
        "outputId": "6b7ed0c4-9a88-497e-fa03-e4309bb821cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme\n",
            "val: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Human pose estimation']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project-wk4fq\n",
            "  project: cctv-people\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/project-wk4fq/cctv-people/dataset/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **yolo**"
      ],
      "metadata": {
        "id": "7eXyR016vE7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train**"
      ],
      "metadata": {
        "id": "jO0OY24x7sBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4peng09RqOvL",
        "outputId": "899b4a38-3a45-4f2b-cd97-abef64059591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.39 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.6/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2JLqNPOBKjI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 원본 라벨 폴더\n",
        "labels_folder = \"/content/drive/MyDrive/CCTV-People-Dataset/train/labels\"\n",
        "\n",
        "# 저조도 이미지 폴더들\n",
        "low_brightness_folders = [\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme\",\n",
        "]\n",
        "\n",
        "# 각 저조도 폴더에 라벨 복사\n",
        "for folder in low_brightness_folders:\n",
        "    images_folder = os.path.join(folder, \"images\")\n",
        "    labels_output_folder = os.path.join(folder, \"labels\")\n",
        "\n",
        "    # 라벨 저장 폴더가 없으면 생성\n",
        "    os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일 이름에 맞는 라벨 복사\n",
        "    for image_file in os.listdir(images_folder):\n",
        "        if image_file.endswith(\".jpg\"):  # 이미지 파일만 처리\n",
        "            label_file = image_file.replace(\".jpg\", \".txt\")  # 라벨 파일 이름\n",
        "            src_label_path = os.path.join(labels_folder, label_file)\n",
        "            dst_label_path = os.path.join(labels_output_folder, label_file)\n",
        "\n",
        "            # 라벨 파일 복사\n",
        "            if os.path.exists(src_label_path):\n",
        "                shutil.copy(src_label_path, dst_label_path)\n",
        "            else:\n",
        "                print(f\"Label not found for {image_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 원본 라벨 폴더\n",
        "labels_folder = \"/content/drive/MyDrive/CCTV-People-Dataset/valid/labels\"\n",
        "\n",
        "# 저조도 이미지 폴더들\n",
        "low_brightness_folders = [\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe\",\n",
        "    \"/content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme\",\n",
        "]\n",
        "\n",
        "# 각 저조도 폴더에 라벨 복사\n",
        "for folder in low_brightness_folders:\n",
        "    images_folder = os.path.join(folder, \"images\")\n",
        "    labels_output_folder = os.path.join(folder, \"labels\")\n",
        "\n",
        "    # 라벨 저장 폴더가 없으면 생성\n",
        "    os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일 이름에 맞는 라벨 복사\n",
        "    for image_file in os.listdir(images_folder):\n",
        "        if image_file.endswith(\".jpg\"):  # 이미지 파일만 처리\n",
        "            label_file = image_file.replace(\".jpg\", \".txt\")  # 라벨 파일 이름\n",
        "            src_label_path = os.path.join(labels_folder, label_file)\n",
        "            dst_label_path = os.path.join(labels_output_folder, label_file)\n",
        "\n",
        "            # 라벨 파일 복사\n",
        "            if os.path.exists(src_label_path):\n",
        "                shutil.copy(src_label_path, dst_label_path)\n",
        "            else:\n",
        "                print(f\"Label not found for {image_file}\")"
      ],
      "metadata": {
        "id": "8zH0Uzu_0Q_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw94xq1_Ccju",
        "outputId": "26c1a953-74de-4545-8499-c29c1b394343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 273MB/s]\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=original, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 114MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/labels... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:09<00:00, 57.64it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/train/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:04<00:00, 36.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.58G      2.043      3.027      1.674         26        640: 100% 33/33 [00:20<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.18it/s]\n",
            "                   all        175        227    0.00356      0.824      0.148     0.0581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      1.856      2.518       1.55         21        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.155     0.0132     0.0465     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G       1.94      2.453      1.601         30        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.52it/s]\n",
            "                   all        175        227      0.578      0.145       0.19     0.0684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      1.964      2.291      1.646         29        640: 100% 33/33 [00:17<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.46it/s]\n",
            "                   all        175        227      0.464      0.374      0.335      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      1.946      2.282      1.632         20        640: 100% 33/33 [00:16<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.66it/s]\n",
            "                   all        175        227      0.193      0.163     0.0861     0.0366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.38G      1.907      2.057      1.616         27        640: 100% 33/33 [00:16<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.31it/s]\n",
            "                   all        175        227      0.409      0.379      0.312      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.37G       1.88      1.947      1.593         32        640: 100% 33/33 [00:16<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.16it/s]\n",
            "                   all        175        227       0.51      0.405      0.408      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.37G      1.902      1.945      1.642         22        640: 100% 33/33 [00:15<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.30it/s]\n",
            "                   all        175        227      0.623      0.515      0.563      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.37G      1.838      1.821      1.609         27        640: 100% 33/33 [00:15<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.83it/s]\n",
            "                   all        175        227      0.688      0.515      0.588      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.874      1.836      1.618         29        640: 100% 33/33 [00:19<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.26it/s]\n",
            "                   all        175        227      0.591      0.529      0.544      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.37G      1.787      1.717      1.556         30        640: 100% 33/33 [00:13<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.40it/s]\n",
            "                   all        175        227      0.679      0.559      0.617      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.36G      1.729      1.663      1.527         24        640: 100% 33/33 [00:17<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.43it/s]\n",
            "                   all        175        227      0.744      0.577      0.654      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.804      1.728      1.541         21        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.721       0.58      0.618      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.737      1.573      1.527         27        640: 100% 33/33 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.54it/s]\n",
            "                   all        175        227      0.781      0.661      0.725      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.683      1.513      1.483         20        640: 100% 33/33 [00:17<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "                   all        175        227      0.746      0.582      0.645      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G      1.702      1.543      1.525         24        640: 100% 33/33 [00:17<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.783      0.573      0.679      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G      1.664      1.499      1.472         39        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.97it/s]\n",
            "                   all        175        227      0.708      0.653      0.693      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.39G      1.573      1.393      1.421         36        640: 100% 33/33 [00:15<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.17it/s]\n",
            "                   all        175        227      0.816      0.612      0.692      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.612      1.446      1.417         27        640: 100% 33/33 [00:13<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.83it/s]\n",
            "                   all        175        227      0.738      0.545      0.617      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.37G      1.624       1.41      1.445         22        640: 100% 33/33 [00:14<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "                   all        175        227      0.776      0.639      0.721      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.586      1.369       1.41         26        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.84it/s]\n",
            "                   all        175        227      0.659      0.652      0.684      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.541      1.329      1.428         27        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                   all        175        227      0.754      0.674      0.717      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.583      1.355      1.435         24        640: 100% 33/33 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.68it/s]\n",
            "                   all        175        227      0.775       0.67       0.74      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.555      1.291      1.433         32        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.95it/s]\n",
            "                   all        175        227      0.856      0.628      0.753      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G      1.507      1.261      1.379         25        640: 100% 33/33 [00:18<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227      0.858      0.674      0.775      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.579      1.313      1.418         32        640: 100% 33/33 [00:11<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.37it/s]\n",
            "                   all        175        227      0.793      0.692      0.746      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.481      1.212      1.349         25        640: 100% 33/33 [00:11<00:00,  2.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.91it/s]\n",
            "                   all        175        227       0.85      0.699      0.778      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.464      1.212      1.371         22        640: 100% 33/33 [00:11<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                   all        175        227       0.84      0.665      0.771       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.491      1.199      1.387         25        640: 100% 33/33 [00:12<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.99it/s]\n",
            "                   all        175        227      0.835      0.714      0.791      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.455      1.195      1.369         24        640: 100% 33/33 [00:13<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.91it/s]\n",
            "                   all        175        227      0.824      0.696      0.792      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.458      1.198      1.351         27        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.26it/s]\n",
            "                   all        175        227      0.804      0.705      0.778      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.429      1.138      1.345         30        640: 100% 33/33 [00:14<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.86it/s]\n",
            "                   all        175        227      0.822      0.722       0.79      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.444      1.144      1.336         26        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                   all        175        227      0.796      0.683      0.771      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.433      1.107      1.315         33        640: 100% 33/33 [00:13<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                   all        175        227       0.87       0.71      0.825      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.408      1.095      1.303         39        640: 100% 33/33 [00:13<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.50it/s]\n",
            "                   all        175        227      0.879      0.704      0.819      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.359      1.064      1.303         28        640: 100% 33/33 [00:13<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "                   all        175        227      0.791      0.767      0.825      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.393      1.052      1.285         24        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                   all        175        227      0.774      0.714      0.795      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G       1.34      1.046      1.272         24        640: 100% 33/33 [00:13<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "                   all        175        227      0.836      0.749      0.829      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.279      1.006      1.252         31        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.25it/s]\n",
            "                   all        175        227      0.809      0.748      0.813      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G       1.29      1.014      1.254         22        640: 100% 33/33 [00:13<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.12it/s]\n",
            "                   all        175        227      0.919      0.727      0.841      0.488\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.54G      1.187     0.9048      1.209         16        640: 100% 33/33 [00:23<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.46it/s]\n",
            "                   all        175        227      0.884      0.674       0.79      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G      1.203     0.8535      1.228         17        640: 100% 33/33 [00:16<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.49it/s]\n",
            "                   all        175        227      0.916      0.717      0.844      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.171     0.8304      1.195         14        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.60it/s]\n",
            "                   all        175        227      0.891      0.727       0.85      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.141     0.8231       1.19         17        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.07it/s]\n",
            "                   all        175        227      0.886      0.749       0.85      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G       1.11     0.7853      1.167         18        640: 100% 33/33 [00:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.73it/s]\n",
            "                   all        175        227      0.855      0.777      0.852      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G      1.115     0.7643      1.175         17        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.71it/s]\n",
            "                   all        175        227       0.86      0.787      0.857      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G        1.1     0.7644      1.159         16        640: 100% 33/33 [00:16<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.41it/s]\n",
            "                   all        175        227       0.85      0.784       0.86      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.073     0.7458      1.129         17        640: 100% 33/33 [00:14<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.95it/s]\n",
            "                   all        175        227       0.87      0.797      0.866      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.063     0.7363      1.144         18        640: 100% 33/33 [00:11<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "                   all        175        227       0.85      0.789      0.862      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.067     0.7138      1.139         14        640: 100% 33/33 [00:10<00:00,  3.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.86it/s]\n",
            "                   all        175        227      0.857      0.811      0.865      0.511\n",
            "\n",
            "50 epochs completed in 0.279 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.852      0.789      0.862      0.514\n",
            "Speed: 0.4ms preprocess, 4.0ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간 저조도 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=moderate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbBgguDJ8h37",
        "outputId": "5fe0fae5-9c5f-487b-f0e6-6969f90342fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=moderate, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Moderate/labels.cache... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:52<00:00,  3.31it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.56G      2.124       3.22      1.728         26        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.54it/s]\n",
            "                   all        175        227    0.00383      0.885      0.339      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      1.987       2.66      1.612         21        640: 100% 33/33 [00:16<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.59it/s]\n",
            "                   all        175        227       0.36      0.123      0.142     0.0435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G      2.042      2.607      1.698         30        640: 100% 33/33 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.37it/s]\n",
            "                   all        175        227      0.129      0.225     0.0889     0.0272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      2.031      2.494      1.749         29        640: 100% 33/33 [00:19<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.272      0.177       0.13     0.0486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      2.016      2.369      1.732         20        640: 100% 33/33 [00:17<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.29it/s]\n",
            "                   all        175        227       0.21      0.185      0.135     0.0388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.38G      2.003      2.187      1.721         27        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.90it/s]\n",
            "                   all        175        227       0.51      0.463      0.446      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.36G      1.952      2.091      1.665         32        640: 100% 33/33 [00:13<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                   all        175        227      0.571       0.37      0.403      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.36G      1.954      2.062      1.722         22        640: 100% 33/33 [00:11<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.07it/s]\n",
            "                   all        175        227      0.585      0.454      0.486      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      1.976      1.931      1.746         27        640: 100% 33/33 [00:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.739      0.536      0.601      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.942      1.948      1.679         29        640: 100% 33/33 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.79it/s]\n",
            "                   all        175        227      0.599      0.559      0.576      0.266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.37G      1.856      1.845      1.621         30        640: 100% 33/33 [00:16<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.658      0.524      0.585      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.36G      1.831      1.744      1.621         24        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.46it/s]\n",
            "                   all        175        227      0.641      0.535      0.569      0.273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.887      1.818      1.614         21        640: 100% 33/33 [00:12<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "                   all        175        227      0.596      0.511      0.539       0.23\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.812      1.675       1.57         27        640: 100% 33/33 [00:12<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.01it/s]\n",
            "                   all        175        227      0.666      0.596      0.644      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.795      1.662      1.566         20        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.18it/s]\n",
            "                   all        175        227      0.723      0.546      0.614      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G       1.79      1.681      1.605         24        640: 100% 33/33 [00:15<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.98it/s]\n",
            "                   all        175        227      0.771      0.401      0.513      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G       1.73      1.628      1.542         39        640: 100% 33/33 [00:15<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.22it/s]\n",
            "                   all        175        227      0.815      0.502      0.581      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.38G      1.691      1.512      1.511         36        640: 100% 33/33 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.45it/s]\n",
            "                   all        175        227       0.75      0.604      0.662      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G        1.7      1.558      1.496         27        640: 100% 33/33 [00:11<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.06it/s]\n",
            "                   all        175        227      0.809      0.678       0.73      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G      1.702      1.498      1.515         22        640: 100% 33/33 [00:13<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.58it/s]\n",
            "                   all        175        227      0.786      0.577      0.682       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.671      1.465      1.483         26        640: 100% 33/33 [00:20<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.22it/s]\n",
            "                   all        175        227       0.81      0.604      0.697      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.625      1.453      1.504         27        640: 100% 33/33 [00:20<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.757      0.529      0.622      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.37G      1.625      1.496      1.502         24        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                   all        175        227      0.828      0.604      0.717      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.639      1.408      1.483         32        640: 100% 33/33 [00:11<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "                   all        175        227      0.734      0.608      0.683       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G      1.576      1.359      1.462         25        640: 100% 33/33 [00:18<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                   all        175        227      0.796      0.643      0.724      0.392\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.659      1.425      1.506         32        640: 100% 33/33 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227      0.786      0.656       0.73      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.554       1.34      1.416         25        640: 100% 33/33 [00:15<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.94it/s]\n",
            "                   all        175        227      0.818      0.674      0.773      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.522      1.302      1.429         22        640: 100% 33/33 [00:16<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.04it/s]\n",
            "                   all        175        227      0.775      0.692       0.76      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.558        1.3      1.451         25        640: 100% 33/33 [00:15<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.04it/s]\n",
            "                   all        175        227      0.794       0.63      0.714      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G       1.47      1.258      1.386         24        640: 100% 33/33 [00:13<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.31it/s]\n",
            "                   all        175        227       0.84      0.656       0.76      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.526      1.291      1.412         27        640: 100% 33/33 [00:11<00:00,  2.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                   all        175        227      0.845      0.656      0.752        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.473      1.223      1.377         30        640: 100% 33/33 [00:14<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.07it/s]\n",
            "                   all        175        227      0.844      0.718      0.779      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.492      1.231      1.381         26        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.08it/s]\n",
            "                   all        175        227      0.852      0.692      0.766      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.495      1.233       1.38         33        640: 100% 33/33 [00:16<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.51it/s]\n",
            "                   all        175        227      0.812      0.722      0.791       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.463      1.186      1.354         39        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                   all        175        227      0.831      0.749      0.806      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.448      1.175      1.364         28        640: 100% 33/33 [00:12<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.45it/s]\n",
            "                   all        175        227      0.802      0.696      0.765      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.464      1.154      1.359         24        640: 100% 33/33 [00:12<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "                   all        175        227      0.791      0.749      0.809      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G      1.436      1.158       1.34         24        640: 100% 33/33 [00:18<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "                   all        175        227      0.844      0.737      0.809      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.397      1.144      1.341         31        640: 100% 33/33 [00:18<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227      0.876      0.749      0.826      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G      1.396      1.117      1.326         22        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.02it/s]\n",
            "                   all        175        227      0.837      0.722      0.784      0.446\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.54G      1.317      1.017        1.3         16        640: 100% 33/33 [00:19<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.36it/s]\n",
            "                   all        175        227      0.762      0.736      0.781      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G      1.272     0.9772      1.284         17        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "                   all        175        227      0.806      0.749      0.817      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.232     0.9304      1.265         14        640: 100% 33/33 [00:11<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                   all        175        227      0.816      0.764      0.824      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.206     0.9134      1.272         17        640: 100% 33/33 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.24it/s]\n",
            "                   all        175        227      0.867      0.767      0.821      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G      1.219     0.8863      1.248         18        640: 100% 33/33 [00:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.70it/s]\n",
            "                   all        175        227      0.858       0.74      0.825      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G      1.195     0.8535      1.236         17        640: 100% 33/33 [00:16<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.95it/s]\n",
            "                   all        175        227      0.845      0.744      0.815      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G      1.202     0.8549       1.24         16        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "                   all        175        227      0.849      0.753      0.824      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.183     0.8454      1.215         17        640: 100% 33/33 [00:11<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                   all        175        227      0.867      0.744      0.815      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.162     0.8421      1.223         18        640: 100% 33/33 [00:12<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.97it/s]\n",
            "                   all        175        227      0.863      0.779      0.833      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G       1.13     0.8179      1.186         14        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.65it/s]\n",
            "                   all        175        227      0.877       0.78      0.838       0.48\n",
            "\n",
            "50 epochs completed in 0.275 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.13it/s]\n",
            "                   all        175        227      0.877       0.78      0.837       0.48\n",
            "Speed: 0.6ms preprocess, 3.6ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 심한 저조도 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=severe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNvjRlGB8lvm",
        "outputId": "9d46f5e0-c77b-4c26-9b45-87dd18ffc565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=severe2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Severe/labels.cache... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:00<?, ?it/s]\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.56G      2.226      3.418      1.853         26        640: 100% 33/33 [00:17<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.83it/s]\n",
            "                   all        175        227      0.691     0.0787      0.181     0.0641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      2.065      2.823      1.732         21        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.21it/s]\n",
            "                   all        175        227      0.423     0.0352     0.0762     0.0266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G      2.099      2.726      1.787         30        640: 100% 33/33 [00:21<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                   all        175        227       0.48      0.181      0.213     0.0823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      2.067      2.522      1.792         29        640: 100% 33/33 [00:12<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:06<00:00,  1.09s/it]\n",
            "                   all        175        227      0.346      0.313      0.247     0.0841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G       2.08        2.5      1.807         20        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.84it/s]\n",
            "                   all        175        227      0.392      0.137      0.116     0.0393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.39G      2.038      2.281      1.753         27        640: 100% 33/33 [00:14<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.57it/s]\n",
            "                   all        175        227      0.574      0.233      0.267      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.37G      2.018      2.161      1.764         32        640: 100% 33/33 [00:18<00:00,  1.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.78it/s]\n",
            "                   all        175        227      0.453      0.405      0.386      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.37G      2.006      2.164        1.8         22        640: 100% 33/33 [00:15<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.49it/s]\n",
            "                   all        175        227      0.524      0.401      0.428      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      1.992      2.039      1.768         27        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.36it/s]\n",
            "                   all        175        227      0.612      0.493       0.54      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.988      2.049      1.739         29        640: 100% 33/33 [00:14<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.78it/s]\n",
            "                   all        175        227      0.462      0.449      0.442      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.37G      1.891      1.897      1.677         30        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.44it/s]\n",
            "                   all        175        227      0.614      0.524      0.565       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.37G      1.864      1.818      1.663         24        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.59it/s]\n",
            "                   all        175        227      0.664      0.497      0.551      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.949      1.888      1.694         21        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.37it/s]\n",
            "                   all        175        227       0.68      0.579      0.624       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.841      1.737      1.639         27        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.82it/s]\n",
            "                   all        175        227      0.681      0.568       0.63      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.37G      1.824      1.672      1.642         20        640: 100% 33/33 [00:14<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227      0.679      0.507      0.585      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G      1.809      1.687      1.679         24        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.50it/s]\n",
            "                   all        175        227      0.671      0.586      0.609        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G      1.761      1.603      1.612         39        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.60it/s]\n",
            "                   all        175        227      0.622      0.535      0.598      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.38G      1.675      1.555      1.549         36        640: 100% 33/33 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.66it/s]\n",
            "                   all        175        227       0.71      0.529      0.591      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.731      1.588      1.566         27        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  3.00it/s]\n",
            "                   all        175        227      0.709      0.595      0.643      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G      1.727      1.576      1.569         22        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.61it/s]\n",
            "                   all        175        227      0.693      0.564      0.606      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G      1.691      1.509      1.537         26        640: 100% 33/33 [00:14<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.90it/s]\n",
            "                   all        175        227      0.654      0.515      0.619      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.662      1.479      1.558         27        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.74it/s]\n",
            "                   all        175        227      0.727      0.609      0.652      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.668      1.557      1.563         24        640: 100% 33/33 [00:16<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.38it/s]\n",
            "                   all        175        227      0.731      0.643      0.695      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.676      1.519      1.563         32        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.74it/s]\n",
            "                   all        175        227      0.696      0.617      0.682      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G       1.61      1.437        1.5         25        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.72it/s]\n",
            "                   all        175        227      0.793      0.639      0.706      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.682       1.51      1.546         32        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.44it/s]\n",
            "                   all        175        227      0.746      0.639      0.686      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.595      1.394      1.469         25        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.53it/s]\n",
            "                   all        175        227      0.758      0.665       0.71      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.36G      1.574      1.372      1.489         22        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.58it/s]\n",
            "                   all        175        227      0.762      0.634      0.719      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G      1.561      1.334       1.48         25        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.41it/s]\n",
            "                   all        175        227      0.699      0.639      0.705      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.531       1.32      1.454         24        640: 100% 33/33 [00:15<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.44it/s]\n",
            "                   all        175        227      0.701      0.639      0.698      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.37G      1.563      1.344      1.478         27        640: 100% 33/33 [00:14<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.58it/s]\n",
            "                   all        175        227      0.832      0.632      0.749      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.37G      1.519      1.296       1.44         30        640: 100% 33/33 [00:15<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.74it/s]\n",
            "                   all        175        227      0.853      0.626      0.735      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.525      1.292      1.441         26        640: 100% 33/33 [00:14<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.94it/s]\n",
            "                   all        175        227       0.78      0.674      0.735      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.544      1.261      1.445         33        640: 100% 33/33 [00:17<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.96it/s]\n",
            "                   all        175        227      0.831      0.649       0.74       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.36G      1.495      1.237      1.418         39        640: 100% 33/33 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.14it/s]\n",
            "                   all        175        227       0.87      0.647      0.755        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.476      1.229      1.428         28        640: 100% 33/33 [00:12<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.70it/s]\n",
            "                   all        175        227      0.808      0.683      0.761      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.497      1.194      1.407         24        640: 100% 33/33 [00:12<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "                   all        175        227      0.761      0.692      0.751      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G      1.487      1.205      1.402         24        640: 100% 33/33 [00:12<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "                   all        175        227      0.848      0.665      0.756       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G        1.4      1.186      1.379         31        640: 100% 33/33 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.97it/s]\n",
            "                   all        175        227      0.789       0.74      0.787      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G      1.407      1.162      1.386         22        640: 100% 33/33 [00:16<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.49it/s]\n",
            "                   all        175        227      0.847      0.674      0.761      0.402\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.54G      1.375      1.089      1.386         16        640: 100% 33/33 [00:14<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.77it/s]\n",
            "                   all        175        227      0.742      0.692      0.746      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.36G      1.328      1.034      1.362         17        640: 100% 33/33 [00:11<00:00,  2.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                   all        175        227      0.849      0.709      0.785      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.283     0.9659      1.342         14        640: 100% 33/33 [00:12<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.96it/s]\n",
            "                   all        175        227      0.825      0.696      0.781      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.282     0.9799      1.349         17        640: 100% 33/33 [00:13<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.47it/s]\n",
            "                   all        175        227      0.777      0.736      0.788      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G      1.264     0.9342      1.326         18        640: 100% 33/33 [00:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227      0.828      0.696      0.786      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G       1.26      0.912      1.317         17        640: 100% 33/33 [00:14<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.24it/s]\n",
            "                   all        175        227      0.782      0.727       0.78      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G      1.225     0.9167        1.3         16        640: 100% 33/33 [00:14<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.66it/s]\n",
            "                   all        175        227      0.768      0.731      0.778      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.212     0.8777       1.28         17        640: 100% 33/33 [00:14<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.88it/s]\n",
            "                   all        175        227      0.774      0.753      0.794      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.213     0.9002      1.292         18        640: 100% 33/33 [00:13<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.81it/s]\n",
            "                   all        175        227      0.794      0.749      0.804      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.195      0.864      1.263         14        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.23it/s]\n",
            "                   all        175        227      0.847        0.7      0.805      0.449\n",
            "\n",
            "50 epochs completed in 0.266 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:06<00:00,  1.14s/it]\n",
            "                   all        175        227      0.795      0.749      0.804      0.452\n",
            "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlJVgG11Bsy6",
        "outputId": "808d9bc8-f190-4aa9-c192-dc59a8aa67f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train, name=extreme, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme/labels... 525 images, 0 backgrounds, 0 corrupt: 100% 525/525 [02:33<00:00,  3.42it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/train/Low_Brightness_Extreme/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/labels... 175 images, 0 backgrounds, 0 corrupt: 100% 175/175 [00:50<00:00,  3.47it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.48G      2.461      3.713      1.986         26        640: 100% 33/33 [00:18<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227     0.0037      0.855      0.278      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.36G      2.249      3.187      1.883         21        640: 100% 33/33 [00:16<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.95it/s]\n",
            "                   all        175        227       0.31     0.0199     0.0292     0.0128\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.36G      2.218      2.943      1.865         30        640: 100% 33/33 [00:14<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.70it/s]\n",
            "                   all        175        227    0.00265      0.612     0.0335    0.00779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.38G      2.204      2.727      1.884         29        640: 100% 33/33 [00:12<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "                   all        175        227       0.11      0.115     0.0429     0.0178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.36G      2.159      2.613      1.902         20        640: 100% 33/33 [00:12<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.43it/s]\n",
            "                   all        175        227      0.322      0.379      0.286      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.39G      2.147       2.43      1.916         27        640: 100% 33/33 [00:15<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.79it/s]\n",
            "                   all        175        227      0.467      0.317      0.309      0.128\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.37G      2.074      2.347      1.837         32        640: 100% 33/33 [00:16<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.74it/s]\n",
            "                   all        175        227      0.343      0.313      0.252     0.0864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.36G      2.085      2.333      1.854         22        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.94it/s]\n",
            "                   all        175        227      0.461      0.282      0.299      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      2.081      2.182      1.846         27        640: 100% 33/33 [00:12<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                   all        175        227      0.624      0.405      0.446      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G       2.08      2.239      1.831         29        640: 100% 33/33 [00:11<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.14it/s]\n",
            "                   all        175        227      0.654      0.436      0.481      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.37G      2.002      2.072       1.78         30        640: 100% 33/33 [00:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.54it/s]\n",
            "                   all        175        227       0.64      0.361      0.398      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.36G      2.004      2.003       1.81         24        640: 100% 33/33 [00:20<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "                   all        175        227      0.561      0.458      0.489      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.36G      1.993      2.095      1.778         21        640: 100% 33/33 [00:17<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.95it/s]\n",
            "                   all        175        227      0.691      0.441      0.512      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.37G      1.928       1.96      1.732         27        640: 100% 33/33 [00:14<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                   all        175        227      0.535      0.441       0.49      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.36G      1.935       1.94      1.735         20        640: 100% 33/33 [00:11<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227      0.562      0.471      0.491      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.36G      1.876      1.926      1.733         24        640: 100% 33/33 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.03it/s]\n",
            "                   all        175        227      0.648      0.485      0.519      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.36G       1.88      1.847      1.717         39        640: 100% 33/33 [00:14<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.64it/s]\n",
            "                   all        175        227      0.754       0.52      0.636      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.38G       1.77      1.736      1.637         36        640: 100% 33/33 [00:16<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.08it/s]\n",
            "                   all        175        227      0.722      0.476      0.579        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.36G      1.825      1.782      1.652         27        640: 100% 33/33 [00:14<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.99it/s]\n",
            "                   all        175        227      0.605      0.533      0.558      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G      1.788       1.73      1.641         22        640: 100% 33/33 [00:12<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.45it/s]\n",
            "                   all        175        227      0.741      0.471      0.541      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.36G       1.81      1.682      1.637         26        640: 100% 33/33 [00:12<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.50it/s]\n",
            "                   all        175        227      0.693      0.536      0.583      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.37G      1.744      1.684      1.645         27        640: 100% 33/33 [00:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.94it/s]\n",
            "                   all        175        227      0.637      0.573      0.631      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.804      1.728      1.642         24        640: 100% 33/33 [00:16<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.77it/s]\n",
            "                   all        175        227      0.672      0.568       0.61      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.38G      1.781      1.667      1.632         32        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "                   all        175        227      0.719      0.604      0.669      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G       1.77      1.621       1.64         25        640: 100% 33/33 [00:11<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                   all        175        227      0.785      0.529       0.65      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.37G      1.773      1.692      1.632         32        640: 100% 33/33 [00:12<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.01it/s]\n",
            "                   all        175        227      0.558      0.608      0.602      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.38G      1.673      1.549      1.536         25        640: 100% 33/33 [00:14<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.29it/s]\n",
            "                   all        175        227      0.667      0.546      0.595      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.37G      1.678      1.559      1.567         22        640: 100% 33/33 [00:16<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.80it/s]\n",
            "                   all        175        227      0.644      0.559      0.616      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G       1.67      1.507      1.569         25        640: 100% 33/33 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.73it/s]\n",
            "                   all        175        227      0.822       0.59      0.673       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G       1.63      1.483      1.536         24        640: 100% 33/33 [00:13<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "                   all        175        227      0.784      0.608      0.714      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G      1.674      1.509      1.568         27        640: 100% 33/33 [00:20<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.43it/s]\n",
            "                   all        175        227      0.761      0.589      0.664      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.36G      1.621      1.463      1.546         30        640: 100% 33/33 [00:14<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.86it/s]\n",
            "                   all        175        227      0.738      0.634      0.676       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G      1.645      1.476      1.552         26        640: 100% 33/33 [00:16<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.42it/s]\n",
            "                   all        175        227      0.759       0.64      0.709      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.37G      1.674      1.445      1.546         33        640: 100% 33/33 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.15it/s]\n",
            "                   all        175        227      0.711      0.612      0.682      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.37G      1.618      1.436      1.512         39        640: 100% 33/33 [00:12<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        175        227       0.67      0.598      0.629      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.36G      1.576      1.422      1.511         28        640: 100% 33/33 [00:11<00:00,  2.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.38it/s]\n",
            "                   all        175        227       0.77      0.639      0.704      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.38G      1.619      1.357      1.499         24        640: 100% 33/33 [00:13<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.72it/s]\n",
            "                   all        175        227      0.738      0.648      0.696      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.37G      1.598      1.404      1.485         24        640: 100% 33/33 [00:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.72it/s]\n",
            "                   all        175        227      0.777       0.63        0.7      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.552      1.369      1.481         31        640: 100% 33/33 [00:15<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.90it/s]\n",
            "                   all        175        227      0.782      0.632      0.703      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.36G      1.553       1.35      1.482         22        640: 100% 33/33 [00:14<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.29it/s]\n",
            "                   all        175        227      0.768      0.671      0.723      0.383\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.43G       1.49      1.271      1.478         16        640: 100% 33/33 [00:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.31it/s]\n",
            "                   all        175        227      0.806       0.63      0.698      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G       1.45      1.208      1.456         17        640: 100% 33/33 [00:11<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.69it/s]\n",
            "                   all        175        227       0.83      0.645      0.749      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G      1.415      1.133      1.441         14        640: 100% 33/33 [00:14<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.66it/s]\n",
            "                   all        175        227      0.746      0.686      0.735      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G      1.397      1.138      1.444         17        640: 100% 33/33 [00:17<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "                   all        175        227      0.763      0.656      0.726      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G      1.409      1.113      1.422         18        640: 100% 33/33 [00:19<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                   all        175        227      0.731      0.696      0.738      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.37G      1.382      1.073      1.416         17        640: 100% 33/33 [00:11<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.69it/s]\n",
            "                   all        175        227      0.793      0.665      0.757      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G      1.371      1.054      1.418         16        640: 100% 33/33 [00:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.82it/s]\n",
            "                   all        175        227      0.779      0.661      0.732        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G      1.369      1.059      1.414         17        640: 100% 33/33 [00:16<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.39it/s]\n",
            "                   all        175        227      0.814      0.665      0.747      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      1.358      1.056      1.409         18        640: 100% 33/33 [00:13<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.40it/s]\n",
            "                   all        175        227      0.794      0.678      0.737      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.37G      1.321      1.028      1.369         14        640: 100% 33/33 [00:10<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                   all        175        227        0.8      0.683      0.739      0.403\n",
            "\n",
            "50 epochs completed in 0.283 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.04it/s]\n",
            "                   all        175        227      0.795      0.678      0.737      0.406\n",
            "Speed: 0.4ms preprocess, 4.3ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "# 매우 심한 저조도 데이터로 학습\n",
        "!yolo train model=yolo11n.pt \\\n",
        "          data=/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml \\\n",
        "          epochs=50 \\\n",
        "          save_period=5 \\\n",
        "          imgsz=640 \\\n",
        "          project=/content/drive/MyDrive/CCTV-People-Dataset/runs/train \\\n",
        "          name=extreme"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**valid**"
      ],
      "metadata": {
        "id": "ym6XsoM27vGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# 원본 데이터로 훈련된 모델 평가\n",
        "model_original = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/original/weights/best.pt')\n",
        "results_original = model_original.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_origin.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHd9NtgV4bjV",
        "outputId": "cf9ee569-67ef-4805-98a8-77ff093a3093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:04<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227      0.853      0.789      0.862      0.513\n",
            "Speed: 3.2ms preprocess, 5.1ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 확인\n",
        "print(\"Classes 적용 여부 확인:\")\n",
        "print(\"Classes:\", results_original.names)  # 모델이 사용 중인 클래스 이름 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D-Iiu2Y2kHI",
        "outputId": "155e7982-6121-4efc-ff50-939352763317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes 적용 여부 확인:\n",
            "Classes: {0: 'Human pose estimation'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYdZzs8v0T9s",
        "outputId": "266f056f-4f87-4614-c700-b72f6c941f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Moderate/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:04<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227       0.88       0.78      0.839      0.481\n",
            "Speed: 4.5ms preprocess, 4.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Severe/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:15<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227      0.788      0.744        0.8      0.448\n",
            "Speed: 0.3ms preprocess, 5.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CCTV-People-Dataset/valid/Low_Brightness_Extreme/labels.cache... 175 images, 0 backgrounds, 0 corrupt: 100%|██████████| 175/175 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        227      0.799      0.678      0.737      0.406\n",
            "Speed: 4.4ms preprocess, 5.3ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 중간 저조도\n",
        "model_moderate = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/moderate/weights/best.pt')\n",
        "results_moderate = model_moderate.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_moderate.yaml')\n",
        "\n",
        "# 심한 저조도\n",
        "model_severe = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/severe2/weights/best.pt')\n",
        "results_severe = model_severe.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_severe.yaml')\n",
        "\n",
        "# 매우 심한 저조도\n",
        "model_extreme = YOLO('/content/drive/MyDrive/CCTV-People-Dataset/runs/train/extreme/weights/best.pt')\n",
        "results_extreme = model_extreme.val(data='/content/drive/MyDrive/CCTV-People-Dataset/data_extreme.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ehlpfDJKHYpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**평가 지표**\n",
        "\n",
        "현재 데이터셋에 클래스가 하나('person')만 존재하므로, mAP 값과 AP 값은 동일하게 나타남."
      ],
      "metadata": {
        "id": "4PJoIvBIt30D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "816945cf-f588-4391-c7a3-4984fd388a6c",
        "id": "dN1ZJFoDH-cm"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Condition         Precision (P)            Recall (R)     mAP50  mAP50-95\n",
            "0  Original  [0.8534768876303868]   [0.788546255506608]  0.862485  0.512603\n",
            "1  Moderate  [0.8796485420582885]  [0.7797356828193832]  0.838800  0.480805\n",
            "2    Severe  [0.7884827991459387]  [0.7444933920704846]  0.800398  0.447859\n",
            "3   Extreme  [0.7985124085506964]  [0.6784140969162996]  0.737462  0.406143\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# YOLO 평가 결과에서 메트릭을 추출합니다.\n",
        "def extract_metrics(result):\n",
        "    metrics = {\n",
        "        \"Precision (P)\": result.box.p,  # 단일 값으로 사용\n",
        "        \"Recall (R)\": result.box.r,     # 단일 값으로 사용\n",
        "        \"mAP50\": result.box.map50,      # 단일 값으로 사용\n",
        "        \"mAP50-95\": result.box.map      # 단일 값으로 사용\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# 각 결과로부터 메트릭을 추출합니다.\n",
        "metrics_original = extract_metrics(results_original)\n",
        "metrics_moderate = extract_metrics(results_moderate)\n",
        "metrics_severe = extract_metrics(results_severe)\n",
        "metrics_extreme = extract_metrics(results_extreme)\n",
        "\n",
        "# 결과를 데이터프레임에 저장합니다.\n",
        "data = {\n",
        "    \"Condition\": [\"Original\", \"Moderate\", \"Severe\", \"Extreme\"],\n",
        "    \"Precision (P)\": [metrics_original[\"Precision (P)\"], metrics_moderate[\"Precision (P)\"], metrics_severe[\"Precision (P)\"], metrics_extreme[\"Precision (P)\"]],\n",
        "    \"Recall (R)\": [metrics_original[\"Recall (R)\"], metrics_moderate[\"Recall (R)\"], metrics_severe[\"Recall (R)\"], metrics_extreme[\"Recall (R)\"]],\n",
        "    \"mAP50\": [metrics_original[\"mAP50\"], metrics_moderate[\"mAP50\"], metrics_severe[\"mAP50\"], metrics_extreme[\"mAP50\"]],\n",
        "    \"mAP50-95\": [metrics_original[\"mAP50-95\"], metrics_moderate[\"mAP50-95\"], metrics_severe[\"mAP50-95\"], metrics_extreme[\"mAP50-95\"]],\n",
        "}\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 결과 출력 (확인용)\n",
        "print(df)\n",
        "\n",
        "# 메트릭 비교를 위한 시각화\n",
        "metrics = [\"Precision (P)\", \"Recall (R)\", \"mAP50\", \"mAP50-95\"]\n",
        "x = df[\"Condition\"]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for metric in metrics:\n",
        "    plt.plot(x, df[metric], marker='o', label=metric)\n",
        "\n",
        "plt.xlabel(\"Low Brightness Condition\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Comparison of Evaluation Metrics Across Different Low Brightness Conditions\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ]
}